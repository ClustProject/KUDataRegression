{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95790ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import setting\n",
    "\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import setting\n",
    "import pathSetting\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from KETIToolDL.CLUSTTool.common import p1_integratedDataSaving as p1\n",
    "from KETIToolDL.CLUSTTool.common import p2_dataSelection as p2\n",
    "from KETIToolDL.CLUSTTool.common import p3_training as p3\n",
    "\n",
    "import torch\n",
    "\n",
    "#import main_regression as mr\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf28a6",
   "metadata": {},
   "source": [
    "# 2. Training \n",
    "\n",
    "## 2-1. Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0b7a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRoot = 'ml_data_integration'\n",
    "# 1 (p2부분 1. Data Selection)\n",
    "DataMeta = p1.readJsonData(pathSetting.DataMetaPath)\n",
    "dataList =  list(DataMeta.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcec8e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keti/CLUST_KETI/Clust/KETIAppTestCode/JWTest/KUDataRegressionJWTest\n",
      "/home/keti/CLUST_KETI/Clust/KETIAppTestCode/JWTest/KUDataRegressionJWTest\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "# dataX\n",
    "dataName_X = dataList[0]\n",
    "dataSaveMode_X = DataMeta[dataName_X][\"integrationInfo\"][\"DataSaveMode\"]\n",
    "\n",
    "# datay\n",
    "dataName_y = dataList[1]\n",
    "dataSaveMode_y = DataMeta[dataName_y][\"integrationInfo\"][\"DataSaveMode\"]\n",
    "\n",
    "#3\n",
    "dataX = p2.getSavedIntegratedData(dataSaveMode_X, dataName_X, dataRoot)\n",
    "datay = p2.getSavedIntegratedData(dataSaveMode_y, dataName_y, dataRoot)\n",
    "integration_freq_sec = DataMeta[dataName_X][\"integrationInfo\"][\"integration_freq_sec\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e052db",
   "metadata": {},
   "source": [
    "## 2-2. Training Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b755d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7', 'RH_8', 'RH_9', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'Press_mm_hg', 'RH_out', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
      "Make New scaler File\n",
      "['value']\n",
      "Make New scaler File\n"
     ]
    }
   ],
   "source": [
    "# 2 Training Data Preparation\n",
    "# 2-1\n",
    "featureListX= list(dataX.columns)\n",
    "featureListy= list(datay.columns)\n",
    "target_col = 'value'\n",
    "\n",
    "# 2-2\n",
    "cleanTrainDataParam = 'NoClean'#  Classification, Regression과 같이 X, y가 분리된 경우에는 현재 고정해서 사용해야함\n",
    "\n",
    "# 2-2-1 cleanTrainDataParam == Clean 일 경우\n",
    "NaNProcessingParam ={\n",
    "    \"feature_cycle\":'Day',\n",
    "    \"feature_cycle_times\":1,\n",
    "    \"NanInfoForCleanData\":{'type':'num', 'ConsecutiveNanLimit':3, 'totalNaNLimit':30000}\n",
    "}\n",
    "# 2-3\n",
    "scalerParam='scale'\n",
    "\n",
    "# 2-4\n",
    "splitRatio = 0.8\n",
    "\n",
    "# 2-5\n",
    "scalerRootPath_X = os.path.join(pathSetting.scalerRootDir, dataName_X, cleanTrainDataParam)\n",
    "scalerRootPath_y = os.path.join(pathSetting.scalerRootDir, dataName_X, cleanTrainDataParam)\n",
    "train_x, val_x, X_scalerFilePath = p3.getTrainValData(dataX, featureListX, scalerRootPath_X, splitRatio, scalerParam)\n",
    "train_y, val_y, y_scalerFilePath = p3.getTrainValData(datay, featureListy, scalerRootPath_y, splitRatio, scalerParam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b9d01",
   "metadata": {},
   "source": [
    "## 2-3 Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f8d6236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keti/CLUST_KETI/Clust/KETIAppTestCode/JWTest/KUDataRegressionJWTest/../../../KETIPreDataTransformation/dataFormatTransformation/DFToNPArray.py:31: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version. Use a timezone-aware object instead.\n",
      "  dfX_partial = dfX[startDate:endDate]\n",
      "/home/keti/CLUST_KETI/Clust/KETIAppTestCode/JWTest/KUDataRegressionJWTest/../../../KETIPreDataTransformation/dataFormatTransformation/DFToNPArray.py:32: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version. Use a timezone-aware object instead.\n",
      "  dfy_partial = dfy[startDate:endDate]\n",
      "/home/keti/CLUST_KETI/Clust/KETIAppTestCode/JWTest/KUDataRegressionJWTest/../../../KETIPreDataTransformation/dataFormatTransformation/DFToNPArray.py:31: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version. Use a timezone-aware object instead.\n",
      "  dfX_partial = dfX[startDate:endDate]\n",
      "/home/keti/CLUST_KETI/Clust/KETIAppTestCode/JWTest/KUDataRegressionJWTest/../../../KETIPreDataTransformation/dataFormatTransformation/DFToNPArray.py:32: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version. Use a timezone-aware object instead.\n",
      "  dfy_partial = dfy[startDate:endDate]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 0.2104\n",
      "val Loss: 0.1532\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 0.0747\n",
      "val Loss: 0.0405\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 0.0424\n",
      "val Loss: 0.0314\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 0.0415\n",
      "val Loss: 0.0325\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 0.0407\n",
      "val Loss: 0.0323\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 0.0397\n",
      "val Loss: 0.0327\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 0.0383\n",
      "val Loss: 0.0329\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 0.0363\n",
      "val Loss: 0.0337\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 0.0340\n",
      "val Loss: 0.0370\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 0.0306\n",
      "val Loss: 0.0337\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 0.0282\n",
      "val Loss: 0.0375\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 0.0291\n",
      "val Loss: 0.0329\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 0.0243\n",
      "val Loss: 0.0375\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 0.0217\n",
      "val Loss: 0.0395\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 0.0221\n",
      "val Loss: 0.0368\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 0.0157\n",
      "val Loss: 0.0327\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 0.0149\n",
      "val Loss: 0.0298\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 0.0134\n",
      "val Loss: 0.0299\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 0.0127\n",
      "val Loss: 0.0275\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 0.0125\n",
      "val Loss: 0.0269\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 0.0130\n",
      "val Loss: 0.0263\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 0.0109\n",
      "val Loss: 0.0256\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 0.0112\n",
      "val Loss: 0.0251\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 0.0101\n",
      "val Loss: 0.0265\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 0.0097\n",
      "val Loss: 0.0286\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 0.0094\n",
      "val Loss: 0.0245\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 0.0092\n",
      "val Loss: 0.0268\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 0.0110\n",
      "val Loss: 0.0229\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 0.0091\n",
      "val Loss: 0.0236\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 0.0091\n",
      "val Loss: 0.0232\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 0.0093\n",
      "val Loss: 0.0242\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 0.0080\n",
      "val Loss: 0.0230\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 0.0079\n",
      "val Loss: 0.0248\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 0.0072\n",
      "val Loss: 0.0238\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 0.0063\n",
      "val Loss: 0.0243\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 0.0061\n",
      "val Loss: 0.0224\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 0.0056\n",
      "val Loss: 0.0228\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 0.0053\n",
      "val Loss: 0.0226\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 0.0050\n",
      "val Loss: 0.0217\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 0.0064\n",
      "val Loss: 0.0208\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 0.0045\n",
      "val Loss: 0.0216\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 0.0050\n",
      "val Loss: 0.0219\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 0.0044\n",
      "val Loss: 0.0244\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 0.0041\n",
      "val Loss: 0.0229\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 0.0039\n",
      "val Loss: 0.0229\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 0.0052\n",
      "val Loss: 0.0216\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 0.0035\n",
      "val Loss: 0.0240\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 0.0038\n",
      "val Loss: 0.0231\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 0.0035\n",
      "val Loss: 0.0233\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 0.0033\n",
      "val Loss: 0.0231\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.0238\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.0235\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 0.0034\n",
      "val Loss: 0.0215\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.0222\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.0233\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 0.0027\n",
      "val Loss: 0.0237\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 0.0027\n",
      "val Loss: 0.0231\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.0233\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.0229\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.0243\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 0.0027\n",
      "val Loss: 0.0232\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.0234\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0236\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 0.0036\n",
      "val Loss: 0.0263\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 0.0037\n",
      "val Loss: 0.0222\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 0.0023\n",
      "val Loss: 0.0231\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0236\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.0237\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 0.0024\n",
      "val Loss: 0.0226\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.0235\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 0.0019\n",
      "val Loss: 0.0233\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.0232\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0232\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0241\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0247\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0241\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0255\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0252\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0256\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0250\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0234\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0234\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0242\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0253\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.0272\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0255\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0272\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0251\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0240\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0251\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0258\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0249\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0256\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0283\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0235\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0244\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0315\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0236\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0241\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0243\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0235\n",
      "\n",
      "Training complete in 8m 4s\n",
      "Best val MSE: 0.018778\n"
     ]
    }
   ],
   "source": [
    "# 3-1.\n",
    "model_list = [\"LSTM_rg\",\"GRU_rg\", \"CNN_1D_rg\",\"LSTM_FCNs_rg\"]\n",
    "model_method = model_list[0]\n",
    "\n",
    "#import main_regression as mr\n",
    "\n",
    "n_epochs = 1000 # 학습 epoch 횟수, int(default: 1000, 범위: 1 이상)\n",
    "batch_size = 16  # batch 크기, int(default: 16, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "\n",
    "trainParameter = setting.modelTestconfig[model_method]\n",
    "trainParameter['device']  = device\n",
    "\n",
    "modelTags =[\"energy\", \"appliances\", \"regression\"]\n",
    "trainDataType = \"timeseries\"\n",
    "modelPurpose = \"regression\"\n",
    "\n",
    "# 2\n",
    "trainDataInfo = DataMeta[dataName_X]['integrationInfo']\n",
    "\n",
    "# 3. 모델을 저장할 파일 패스를 생성한다.\n",
    "from KETIPreDataTransformation.general_transformation.dataScaler import encodeHashStyle\n",
    "trainParameter_encode =  encodeHashStyle(str(trainParameter))\n",
    "trainDataPathList = [\"CLUST\", \"Electronics\", dataName_X, trainParameter_encode]\n",
    "modelFilePath = p3.getModelFilePath(trainDataPathList, model_method)\n",
    "\n",
    "# 4. Training\n",
    "from KETIToolDL.TrainTool.Regression.trainer import RegressionML as RML\n",
    "rml = RML(model_method, trainParameter)\n",
    "rml.processInputData(train_x, train_y, val_x, val_y, batch_size)\n",
    "model = rml.getModel()\n",
    "best_model = rml.trainModel(model, modelFilePath, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bca73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. update MetaFile\n",
    "ModelName = encodeHashStyle(p1.getListMerge ([trainParameter_encode, dataName_X, dataName_y] ))\n",
    "modelInfoMeta ={\n",
    "    \"trainDataInfo\":trainDataInfo,\n",
    "    \"featureList\":featureListX,\n",
    "    \"target\":featureListy,\n",
    "    \"trainDataType\":trainDataType,\n",
    "    \"modelPurpose\":modelPurpose,\n",
    "    \"model_method\":model_method,\n",
    "    \"modelTags\":modelTags,\n",
    "    \"cleanTrainDataParam\":cleanTrainDataParam,\n",
    "    \"cleanTrainDataParam\":NaNProcessingParam,\n",
    "    \"trainDataName\":[dataName_X,dataName_y],\n",
    "    \"trainParameter\":rml.parameter,\n",
    "    \"scalerParam\":scalerParam,\n",
    "    \"X_scalerFilePath\":X_scalerFilePath,\n",
    "    \"y_scalerFilePath\":y_scalerFilePath,\n",
    "    \"modelFilePath\":modelFilePath,\n",
    "    \"trainParameter\":trainParameter\n",
    "}\n",
    "modelInfoMeta = p3.updateModelMetaData(ModelName, modelInfoMeta, pathSetting.trainModelMetaFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55d787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1ef7e1f828dbb4e75f421045d2c565197efaf8469a0be4a314c6ea8378b5cb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
