{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ee0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import main_regression as mr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f1420",
   "metadata": {},
   "source": [
    "# Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2671e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a339ffef",
   "metadata": {},
   "source": [
    "# Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2449b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config1 = {\n",
    "        'model': 'LSTM', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 144, # timestep = window_size\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 2000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0003,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 2. GRU model (w/o data representation)\n",
    "config2 = {\n",
    "        'model': 'GRU', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'with_representation' : False, # representation 유무, bool (defeault: False)\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 144, # timestep = window_size\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 2000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0003,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 3. CNN_1D model (w/o data representation)\n",
    "config3 = {\n",
    "        'model': 'CNN_1D', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/cnn_1d.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 144, # timestep = window_size\n",
    "            'seq_len': 144,  # 데이터의 시간 길이, int\n",
    "            'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "            'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "            'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "            'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 2000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0003,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택4\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 4. LSTM_FCNs model (w/o data representation)\n",
    "config4 = {\n",
    "        'model': 'LSTM_FCNs', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm_fcn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 144, # timestep = window_size\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "            'lstm_drop_out': 0.001, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "            'fc_drop_out': 0.001, # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 2000, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0003,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 5. DARNN model (w/o data representation)\n",
    "config5 = {\n",
    "        'model': 'DARNN', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/darnn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'encoder_hidden_size': 64, # Encoder hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'decoder_hidden_size': 64, # Decoder hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'timestep': 144, # timestep의 크기, int(default: 16, 범위: 1이상)\n",
    "            'encoder_stateful': False, # Encoder의 Stateful 사용여부, bool(default: False)\n",
    "            'decoder_stateful': False, # Decoder의 Stateful 사용여부, bool(default: False)\n",
    "            'num_epochs': 1500,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0003,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist': True\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 6. fully-connected layers (w/ data representation)\n",
    "config6 = {\n",
    "        'model': 'FC', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/fc.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 64,  # 데이터의 변수 개수(representation 차원), int\n",
    "            'timestep' : 1, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bias': True, # bias 사용 여부, bool(default: True)\n",
    "            'num_epochs': 2000, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 32,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0003,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dda35a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "442273ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 24, 144)\n",
      "(95,)\n",
      "(42, 24, 144)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "# raw time series data\n",
    "train_x = pickle.load(open('./data/x_train_new_energy.pkl', 'rb'))\n",
    "train_y = pickle.load(open('./data/y_train_new_energy.pkl', 'rb'))\n",
    "test_x = pickle.load(open('./data/x_test_new_energy.pkl', 'rb'))\n",
    "test_y = pickle.load(open('./data/y_test_new_energy.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (95, 24, 144)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (95,)\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (42, 24, 144)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (42,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c8980",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f513ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/2000\n",
      "train Loss: 211.3343\n",
      "val Loss: 241.2221\n",
      "\n",
      "Epoch 10/2000\n",
      "train Loss: 196.1204\n",
      "val Loss: 224.6028\n",
      "\n",
      "Epoch 20/2000\n",
      "train Loss: 169.6117\n",
      "val Loss: 194.2914\n",
      "\n",
      "Epoch 30/2000\n",
      "train Loss: 135.3743\n",
      "val Loss: 157.2957\n",
      "\n",
      "Epoch 40/2000\n",
      "train Loss: 107.5801\n",
      "val Loss: 127.0598\n",
      "\n",
      "Epoch 50/2000\n",
      "train Loss: 85.5347\n",
      "val Loss: 102.8723\n",
      "\n",
      "Epoch 60/2000\n",
      "train Loss: 68.7810\n",
      "val Loss: 84.1853\n",
      "\n",
      "Epoch 70/2000\n",
      "train Loss: 55.7026\n",
      "val Loss: 69.3272\n",
      "\n",
      "Epoch 80/2000\n",
      "train Loss: 45.7779\n",
      "val Loss: 57.8176\n",
      "\n",
      "Epoch 90/2000\n",
      "train Loss: 38.4944\n",
      "val Loss: 49.1586\n",
      "\n",
      "Epoch 100/2000\n",
      "train Loss: 32.9524\n",
      "val Loss: 42.3158\n",
      "\n",
      "Epoch 110/2000\n",
      "train Loss: 28.4964\n",
      "val Loss: 36.6120\n",
      "\n",
      "Epoch 120/2000\n",
      "train Loss: 25.3236\n",
      "val Loss: 32.3999\n",
      "\n",
      "Epoch 130/2000\n",
      "train Loss: 23.0006\n",
      "val Loss: 29.1571\n",
      "\n",
      "Epoch 140/2000\n",
      "train Loss: 21.4504\n",
      "val Loss: 26.8423\n",
      "\n",
      "Epoch 150/2000\n",
      "train Loss: 20.3267\n",
      "val Loss: 25.0473\n",
      "\n",
      "Epoch 160/2000\n",
      "train Loss: 19.5836\n",
      "val Loss: 23.7225\n",
      "\n",
      "Epoch 170/2000\n",
      "train Loss: 19.0509\n",
      "val Loss: 22.7036\n",
      "\n",
      "Epoch 180/2000\n",
      "train Loss: 18.7120\n",
      "val Loss: 21.9657\n",
      "\n",
      "Epoch 190/2000\n",
      "train Loss: 18.4899\n",
      "val Loss: 21.4120\n",
      "\n",
      "Epoch 200/2000\n",
      "train Loss: 18.3601\n",
      "val Loss: 21.0336\n",
      "\n",
      "Epoch 210/2000\n",
      "train Loss: 18.2396\n",
      "val Loss: 20.6050\n",
      "\n",
      "Epoch 220/2000\n",
      "train Loss: 18.1718\n",
      "val Loss: 20.2937\n",
      "\n",
      "Epoch 230/2000\n",
      "train Loss: 18.1585\n",
      "val Loss: 20.2296\n",
      "\n",
      "Epoch 240/2000\n",
      "train Loss: 18.1384\n",
      "val Loss: 20.0763\n",
      "\n",
      "Epoch 250/2000\n",
      "train Loss: 18.1248\n",
      "val Loss: 19.9240\n",
      "\n",
      "Epoch 260/2000\n",
      "train Loss: 18.1208\n",
      "val Loss: 19.9024\n",
      "\n",
      "Epoch 270/2000\n",
      "train Loss: 18.0924\n",
      "val Loss: 19.8750\n",
      "\n",
      "Epoch 280/2000\n",
      "train Loss: 18.1044\n",
      "val Loss: 19.9964\n",
      "\n",
      "Epoch 290/2000\n",
      "train Loss: 18.0717\n",
      "val Loss: 19.8587\n",
      "\n",
      "Epoch 300/2000\n",
      "train Loss: 18.0613\n",
      "val Loss: 19.7995\n",
      "\n",
      "Epoch 310/2000\n",
      "train Loss: 18.0572\n",
      "val Loss: 19.7973\n",
      "\n",
      "Epoch 320/2000\n",
      "train Loss: 18.0602\n",
      "val Loss: 19.8754\n",
      "\n",
      "Epoch 330/2000\n",
      "train Loss: 18.0566\n",
      "val Loss: 19.8944\n",
      "\n",
      "Epoch 340/2000\n",
      "train Loss: 18.0622\n",
      "val Loss: 19.7971\n",
      "\n",
      "Epoch 350/2000\n",
      "train Loss: 18.0557\n",
      "val Loss: 19.8268\n",
      "\n",
      "Epoch 360/2000\n",
      "train Loss: 18.0398\n",
      "val Loss: 19.9011\n",
      "\n",
      "Epoch 370/2000\n",
      "train Loss: 18.0529\n",
      "val Loss: 19.8026\n",
      "\n",
      "Epoch 380/2000\n",
      "train Loss: 18.0244\n",
      "val Loss: 19.8360\n",
      "\n",
      "Epoch 390/2000\n",
      "train Loss: 18.0240\n",
      "val Loss: 19.8778\n",
      "\n",
      "Epoch 400/2000\n",
      "train Loss: 18.0299\n",
      "val Loss: 19.7979\n",
      "\n",
      "Epoch 410/2000\n",
      "train Loss: 17.9751\n",
      "val Loss: 19.9446\n",
      "\n",
      "Epoch 420/2000\n",
      "train Loss: 17.9781\n",
      "val Loss: 20.0006\n",
      "\n",
      "Epoch 430/2000\n",
      "train Loss: 17.9820\n",
      "val Loss: 19.9628\n",
      "\n",
      "Epoch 440/2000\n",
      "train Loss: 17.9489\n",
      "val Loss: 19.8859\n",
      "\n",
      "Epoch 450/2000\n",
      "train Loss: 17.6965\n",
      "val Loss: 20.3928\n",
      "\n",
      "Epoch 460/2000\n",
      "train Loss: 18.0127\n",
      "val Loss: 19.6294\n",
      "\n",
      "Epoch 470/2000\n",
      "train Loss: 18.0274\n",
      "val Loss: 19.6122\n",
      "\n",
      "Epoch 480/2000\n",
      "train Loss: 17.9910\n",
      "val Loss: 19.7283\n",
      "\n",
      "Epoch 490/2000\n",
      "train Loss: 17.8855\n",
      "val Loss: 20.1192\n",
      "\n",
      "Epoch 500/2000\n",
      "train Loss: 17.8718\n",
      "val Loss: 19.9026\n",
      "\n",
      "Epoch 510/2000\n",
      "train Loss: 17.6949\n",
      "val Loss: 20.5289\n",
      "\n",
      "Epoch 520/2000\n",
      "train Loss: 17.5721\n",
      "val Loss: 20.2931\n",
      "\n",
      "Epoch 530/2000\n",
      "train Loss: 17.7320\n",
      "val Loss: 20.7592\n",
      "\n",
      "Epoch 540/2000\n",
      "train Loss: 18.0572\n",
      "val Loss: 19.3850\n",
      "\n",
      "Epoch 550/2000\n",
      "train Loss: 17.9852\n",
      "val Loss: 20.5714\n",
      "\n",
      "Epoch 560/2000\n",
      "train Loss: 17.9250\n",
      "val Loss: 19.8915\n",
      "\n",
      "Epoch 570/2000\n",
      "train Loss: 17.8476\n",
      "val Loss: 20.2990\n",
      "\n",
      "Epoch 580/2000\n",
      "train Loss: 17.8276\n",
      "val Loss: 20.8280\n",
      "\n",
      "Epoch 590/2000\n",
      "train Loss: 17.7500\n",
      "val Loss: 20.4698\n",
      "\n",
      "Epoch 600/2000\n",
      "train Loss: 17.6172\n",
      "val Loss: 20.1278\n",
      "\n",
      "Epoch 610/2000\n",
      "train Loss: 17.6881\n",
      "val Loss: 20.7788\n",
      "\n",
      "Epoch 620/2000\n",
      "train Loss: 17.4879\n",
      "val Loss: 20.4625\n",
      "\n",
      "Epoch 630/2000\n",
      "train Loss: 17.4116\n",
      "val Loss: 21.0701\n",
      "\n",
      "Epoch 640/2000\n",
      "train Loss: 16.7645\n",
      "val Loss: 19.7389\n",
      "\n",
      "Epoch 650/2000\n",
      "train Loss: 17.8252\n",
      "val Loss: 21.2664\n",
      "\n",
      "Epoch 660/2000\n",
      "train Loss: 17.6254\n",
      "val Loss: 19.5827\n",
      "\n",
      "Epoch 670/2000\n",
      "train Loss: 17.6491\n",
      "val Loss: 19.1666\n",
      "\n",
      "Epoch 680/2000\n",
      "train Loss: 17.5456\n",
      "val Loss: 20.1526\n",
      "\n",
      "Epoch 690/2000\n",
      "train Loss: 17.1848\n",
      "val Loss: 21.0062\n",
      "\n",
      "Epoch 700/2000\n",
      "train Loss: 17.7271\n",
      "val Loss: 19.5314\n",
      "\n",
      "Epoch 710/2000\n",
      "train Loss: 17.7059\n",
      "val Loss: 21.3079\n",
      "\n",
      "Epoch 720/2000\n",
      "train Loss: 17.4217\n",
      "val Loss: 20.8899\n",
      "\n",
      "Epoch 730/2000\n",
      "train Loss: 17.2303\n",
      "val Loss: 20.8709\n",
      "\n",
      "Epoch 740/2000\n",
      "train Loss: 17.4526\n",
      "val Loss: 19.6250\n",
      "\n",
      "Epoch 750/2000\n",
      "train Loss: 17.2467\n",
      "val Loss: 19.6556\n",
      "\n",
      "Epoch 760/2000\n",
      "train Loss: 16.2612\n",
      "val Loss: 21.2769\n",
      "\n",
      "Epoch 770/2000\n",
      "train Loss: 17.5027\n",
      "val Loss: 19.9799\n",
      "\n",
      "Epoch 780/2000\n",
      "train Loss: 17.0566\n",
      "val Loss: 20.5543\n",
      "\n",
      "Epoch 790/2000\n",
      "train Loss: 15.8675\n",
      "val Loss: 21.9740\n",
      "\n",
      "Epoch 800/2000\n",
      "train Loss: 16.7886\n",
      "val Loss: 19.3317\n",
      "\n",
      "Epoch 810/2000\n",
      "train Loss: 15.9118\n",
      "val Loss: 20.1139\n",
      "\n",
      "Epoch 820/2000\n",
      "train Loss: 17.6408\n",
      "val Loss: 19.8878\n",
      "\n",
      "Epoch 830/2000\n",
      "train Loss: 16.5851\n",
      "val Loss: 20.8334\n",
      "\n",
      "Epoch 840/2000\n",
      "train Loss: 15.3581\n",
      "val Loss: 21.9556\n",
      "\n",
      "Epoch 850/2000\n",
      "train Loss: 16.3849\n",
      "val Loss: 20.2201\n",
      "\n",
      "Epoch 860/2000\n",
      "train Loss: 15.3830\n",
      "val Loss: 22.8942\n",
      "\n",
      "Epoch 870/2000\n",
      "train Loss: 17.9375\n",
      "val Loss: 19.3497\n",
      "\n",
      "Epoch 880/2000\n",
      "train Loss: 17.4116\n",
      "val Loss: 20.7230\n",
      "\n",
      "Epoch 890/2000\n",
      "train Loss: 17.1227\n",
      "val Loss: 20.8495\n",
      "\n",
      "Epoch 900/2000\n",
      "train Loss: 17.0541\n",
      "val Loss: 21.9928\n",
      "\n",
      "Epoch 910/2000\n",
      "train Loss: 16.4526\n",
      "val Loss: 22.1744\n",
      "\n",
      "Epoch 920/2000\n",
      "train Loss: 16.4259\n",
      "val Loss: 20.4417\n",
      "\n",
      "Epoch 930/2000\n",
      "train Loss: 18.4905\n",
      "val Loss: 19.0794\n",
      "\n",
      "Epoch 940/2000\n",
      "train Loss: 17.1737\n",
      "val Loss: 21.1368\n",
      "\n",
      "Epoch 950/2000\n",
      "train Loss: 16.5345\n",
      "val Loss: 23.1135\n",
      "\n",
      "Epoch 960/2000\n",
      "train Loss: 16.3886\n",
      "val Loss: 21.9961\n",
      "\n",
      "Epoch 970/2000\n",
      "train Loss: 15.8670\n",
      "val Loss: 21.9864\n",
      "\n",
      "Epoch 980/2000\n",
      "train Loss: 15.3644\n",
      "val Loss: 23.3016\n",
      "\n",
      "Epoch 990/2000\n",
      "train Loss: 16.2547\n",
      "val Loss: 24.9008\n",
      "\n",
      "Epoch 1000/2000\n",
      "train Loss: 15.5989\n",
      "val Loss: 22.6998\n",
      "\n",
      "Epoch 1010/2000\n",
      "train Loss: 15.2375\n",
      "val Loss: 23.9187\n",
      "\n",
      "Epoch 1020/2000\n",
      "train Loss: 18.1839\n",
      "val Loss: 19.9024\n",
      "\n",
      "Epoch 1030/2000\n",
      "train Loss: 15.7649\n",
      "val Loss: 26.6648\n",
      "\n",
      "Epoch 1040/2000\n",
      "train Loss: 15.8620\n",
      "val Loss: 24.8769\n",
      "\n",
      "Epoch 1050/2000\n",
      "train Loss: 14.8225\n",
      "val Loss: 21.6631\n",
      "\n",
      "Epoch 1060/2000\n",
      "train Loss: 13.7967\n",
      "val Loss: 20.0825\n",
      "\n",
      "Epoch 1070/2000\n",
      "train Loss: 16.2941\n",
      "val Loss: 23.1200\n",
      "\n",
      "Epoch 1080/2000\n",
      "train Loss: 16.1011\n",
      "val Loss: 21.3378\n",
      "\n",
      "Epoch 1090/2000\n",
      "train Loss: 16.1954\n",
      "val Loss: 25.0547\n",
      "\n",
      "Epoch 1100/2000\n",
      "train Loss: 14.5137\n",
      "val Loss: 21.4834\n",
      "\n",
      "Epoch 1110/2000\n",
      "train Loss: 14.0765\n",
      "val Loss: 24.3187\n",
      "\n",
      "Epoch 1120/2000\n",
      "train Loss: 17.2649\n",
      "val Loss: 20.0856\n",
      "\n",
      "Epoch 1130/2000\n",
      "train Loss: 17.0286\n",
      "val Loss: 20.2042\n",
      "\n",
      "Epoch 1140/2000\n",
      "train Loss: 16.6942\n",
      "val Loss: 20.7956\n",
      "\n",
      "Epoch 1150/2000\n",
      "train Loss: 16.5343\n",
      "val Loss: 21.6865\n",
      "\n",
      "Epoch 1160/2000\n",
      "train Loss: 16.3650\n",
      "val Loss: 21.8130\n",
      "\n",
      "Epoch 1170/2000\n",
      "train Loss: 16.4262\n",
      "val Loss: 21.3786\n",
      "\n",
      "Epoch 1180/2000\n",
      "train Loss: 16.5319\n",
      "val Loss: 22.5196\n",
      "\n",
      "Epoch 1190/2000\n",
      "train Loss: 15.6422\n",
      "val Loss: 21.3623\n",
      "\n",
      "Epoch 1200/2000\n",
      "train Loss: 15.9206\n",
      "val Loss: 22.3034\n",
      "\n",
      "Epoch 1210/2000\n",
      "train Loss: 15.7762\n",
      "val Loss: 21.5822\n",
      "\n",
      "Epoch 1220/2000\n",
      "train Loss: 16.2312\n",
      "val Loss: 19.1875\n",
      "\n",
      "Epoch 1230/2000\n",
      "train Loss: 16.8564\n",
      "val Loss: 21.3974\n",
      "\n",
      "Epoch 1240/2000\n",
      "train Loss: 16.6448\n",
      "val Loss: 21.0650\n",
      "\n",
      "Epoch 1250/2000\n",
      "train Loss: 16.6347\n",
      "val Loss: 21.3130\n",
      "\n",
      "Epoch 1260/2000\n",
      "train Loss: 16.4438\n",
      "val Loss: 21.3969\n",
      "\n",
      "Epoch 1270/2000\n",
      "train Loss: 16.3107\n",
      "val Loss: 21.4827\n",
      "\n",
      "Epoch 1280/2000\n",
      "train Loss: 16.3169\n",
      "val Loss: 21.4440\n",
      "\n",
      "Epoch 1290/2000\n",
      "train Loss: 16.2180\n",
      "val Loss: 21.3926\n",
      "\n",
      "Epoch 1300/2000\n",
      "train Loss: 16.1159\n",
      "val Loss: 21.3902\n",
      "\n",
      "Epoch 1310/2000\n",
      "train Loss: 16.1085\n",
      "val Loss: 21.4755\n",
      "\n",
      "Epoch 1320/2000\n",
      "train Loss: 15.8835\n",
      "val Loss: 21.5987\n",
      "\n",
      "Epoch 1330/2000\n",
      "train Loss: 15.9052\n",
      "val Loss: 22.1648\n",
      "\n",
      "Epoch 1340/2000\n",
      "train Loss: 15.8735\n",
      "val Loss: 21.0241\n",
      "\n",
      "Epoch 1350/2000\n",
      "train Loss: 15.8812\n",
      "val Loss: 22.2028\n",
      "\n",
      "Epoch 1360/2000\n",
      "train Loss: 15.6581\n",
      "val Loss: 21.8005\n",
      "\n",
      "Epoch 1370/2000\n",
      "train Loss: 15.4376\n",
      "val Loss: 22.9602\n",
      "\n",
      "Epoch 1380/2000\n",
      "train Loss: 15.1371\n",
      "val Loss: 21.8419\n",
      "\n",
      "Epoch 1390/2000\n",
      "train Loss: 15.0048\n",
      "val Loss: 22.3666\n",
      "\n",
      "Epoch 1400/2000\n",
      "train Loss: 15.6035\n",
      "val Loss: 21.3904\n",
      "\n",
      "Epoch 1410/2000\n",
      "train Loss: 14.5794\n",
      "val Loss: 26.0874\n",
      "\n",
      "Epoch 1420/2000\n",
      "train Loss: 14.1769\n",
      "val Loss: 23.3031\n",
      "\n",
      "Epoch 1430/2000\n",
      "train Loss: 15.0722\n",
      "val Loss: 22.2214\n",
      "\n",
      "Epoch 1440/2000\n",
      "train Loss: 15.0675\n",
      "val Loss: 23.2053\n",
      "\n",
      "Epoch 1450/2000\n",
      "train Loss: 14.4427\n",
      "val Loss: 22.9213\n",
      "\n",
      "Epoch 1460/2000\n",
      "train Loss: 14.8911\n",
      "val Loss: 20.0427\n",
      "\n",
      "Epoch 1470/2000\n",
      "train Loss: 14.6101\n",
      "val Loss: 21.9517\n",
      "\n",
      "Epoch 1480/2000\n",
      "train Loss: 12.9293\n",
      "val Loss: 26.4534\n",
      "\n",
      "Epoch 1490/2000\n",
      "train Loss: 14.1842\n",
      "val Loss: 24.2942\n",
      "\n",
      "Epoch 1500/2000\n",
      "train Loss: 14.2093\n",
      "val Loss: 25.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1510/2000\n",
      "train Loss: 13.2540\n",
      "val Loss: 24.9225\n",
      "\n",
      "Epoch 1520/2000\n",
      "train Loss: 13.3709\n",
      "val Loss: 26.7087\n",
      "\n",
      "Epoch 1530/2000\n",
      "train Loss: 15.1164\n",
      "val Loss: 25.4137\n",
      "\n",
      "Epoch 1540/2000\n",
      "train Loss: 13.6996\n",
      "val Loss: 22.5507\n",
      "\n",
      "Epoch 1550/2000\n",
      "train Loss: 13.4229\n",
      "val Loss: 22.4404\n",
      "\n",
      "Epoch 1560/2000\n",
      "train Loss: 14.2166\n",
      "val Loss: 27.2753\n",
      "\n",
      "Epoch 1570/2000\n",
      "train Loss: 13.7789\n",
      "val Loss: 25.5240\n",
      "\n",
      "Epoch 1580/2000\n",
      "train Loss: 13.4308\n",
      "val Loss: 26.1428\n",
      "\n",
      "Epoch 1590/2000\n",
      "train Loss: 12.9704\n",
      "val Loss: 22.0881\n",
      "\n",
      "Epoch 1600/2000\n",
      "train Loss: 12.8358\n",
      "val Loss: 25.5736\n",
      "\n",
      "Epoch 1610/2000\n",
      "train Loss: 12.3687\n",
      "val Loss: 24.7315\n",
      "\n",
      "Epoch 1620/2000\n",
      "train Loss: 12.2048\n",
      "val Loss: 22.9926\n",
      "\n",
      "Epoch 1630/2000\n",
      "train Loss: 22.6707\n",
      "val Loss: 20.7764\n",
      "\n",
      "Epoch 1640/2000\n",
      "train Loss: 17.1057\n",
      "val Loss: 23.9407\n",
      "\n",
      "Epoch 1650/2000\n",
      "train Loss: 15.8879\n",
      "val Loss: 21.1435\n",
      "\n",
      "Epoch 1660/2000\n",
      "train Loss: 15.7790\n",
      "val Loss: 21.2319\n",
      "\n",
      "Epoch 1670/2000\n",
      "train Loss: 15.7663\n",
      "val Loss: 22.3303\n",
      "\n",
      "Epoch 1680/2000\n",
      "train Loss: 15.6554\n",
      "val Loss: 21.2483\n",
      "\n",
      "Epoch 1690/2000\n",
      "train Loss: 15.6257\n",
      "val Loss: 21.4659\n",
      "\n",
      "Epoch 1700/2000\n",
      "train Loss: 15.5255\n",
      "val Loss: 21.4932\n",
      "\n",
      "Epoch 1710/2000\n",
      "train Loss: 15.5557\n",
      "val Loss: 21.4171\n",
      "\n",
      "Epoch 1720/2000\n",
      "train Loss: 15.4097\n",
      "val Loss: 21.9839\n",
      "\n",
      "Epoch 1730/2000\n",
      "train Loss: 15.5068\n",
      "val Loss: 21.2393\n",
      "\n",
      "Epoch 1740/2000\n",
      "train Loss: 15.2228\n",
      "val Loss: 22.2798\n",
      "\n",
      "Epoch 1750/2000\n",
      "train Loss: 15.1567\n",
      "val Loss: 23.5939\n",
      "\n",
      "Epoch 1760/2000\n",
      "train Loss: 15.4106\n",
      "val Loss: 22.2852\n",
      "\n",
      "Epoch 1770/2000\n",
      "train Loss: 15.3850\n",
      "val Loss: 21.6492\n",
      "\n",
      "Epoch 1780/2000\n",
      "train Loss: 15.3238\n",
      "val Loss: 21.7571\n",
      "\n",
      "Epoch 1790/2000\n",
      "train Loss: 15.3132\n",
      "val Loss: 22.4029\n",
      "\n",
      "Epoch 1800/2000\n",
      "train Loss: 15.2393\n",
      "val Loss: 22.7689\n",
      "\n",
      "Epoch 1810/2000\n",
      "train Loss: 14.9889\n",
      "val Loss: 22.9250\n",
      "\n",
      "Epoch 1820/2000\n",
      "train Loss: 15.0615\n",
      "val Loss: 22.5448\n",
      "\n",
      "Epoch 1830/2000\n",
      "train Loss: 14.3005\n",
      "val Loss: 24.6356\n",
      "\n",
      "Epoch 1840/2000\n",
      "train Loss: 15.0118\n",
      "val Loss: 20.8501\n",
      "\n",
      "Epoch 1850/2000\n",
      "train Loss: 15.5302\n",
      "val Loss: 23.3294\n",
      "\n",
      "Epoch 1860/2000\n",
      "train Loss: 15.0352\n",
      "val Loss: 23.0652\n",
      "\n",
      "Epoch 1870/2000\n",
      "train Loss: 14.9711\n",
      "val Loss: 23.3194\n",
      "\n",
      "Epoch 1880/2000\n",
      "train Loss: 14.8908\n",
      "val Loss: 22.1696\n",
      "\n",
      "Epoch 1890/2000\n",
      "train Loss: 15.1230\n",
      "val Loss: 21.7005\n",
      "\n",
      "Epoch 1900/2000\n",
      "train Loss: 15.1033\n",
      "val Loss: 21.4907\n",
      "\n",
      "Epoch 1910/2000\n",
      "train Loss: 15.1265\n",
      "val Loss: 22.4655\n",
      "\n",
      "Epoch 1920/2000\n",
      "train Loss: 14.9756\n",
      "val Loss: 22.0523\n",
      "\n",
      "Epoch 1930/2000\n",
      "train Loss: 15.2604\n",
      "val Loss: 21.1704\n",
      "\n",
      "Epoch 1940/2000\n",
      "train Loss: 14.9007\n",
      "val Loss: 22.4291\n",
      "\n",
      "Epoch 1950/2000\n",
      "train Loss: 14.8538\n",
      "val Loss: 21.7451\n",
      "\n",
      "Epoch 1960/2000\n",
      "train Loss: 15.1499\n",
      "val Loss: 23.1283\n",
      "\n",
      "Epoch 1970/2000\n",
      "train Loss: 15.0576\n",
      "val Loss: 24.8966\n",
      "\n",
      "Epoch 1980/2000\n",
      "train Loss: 14.7198\n",
      "val Loss: 23.4450\n",
      "\n",
      "Epoch 1990/2000\n",
      "train Loss: 14.5931\n",
      "val Loss: 23.2135\n",
      "\n",
      "Epoch 2000/2000\n",
      "train Loss: 14.7367\n",
      "val Loss: 21.1145\n",
      "\n",
      "Training complete in 1m 5s\n",
      "Best val Loss: 18.659857\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 13.60519 and R2: -456.79497\n",
      "test RMSE: 3.6885\n"
     ]
    }
   ],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config = config1\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4929f8ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/2000\n",
      "train Loss: 213.1694\n",
      "val Loss: 239.2076\n",
      "\n",
      "Epoch 10/2000\n",
      "train Loss: 165.9689\n",
      "val Loss: 189.1914\n",
      "\n",
      "Epoch 20/2000\n",
      "train Loss: 120.9827\n",
      "val Loss: 140.4195\n",
      "\n",
      "Epoch 30/2000\n",
      "train Loss: 89.0985\n",
      "val Loss: 106.3132\n",
      "\n",
      "Epoch 40/2000\n",
      "train Loss: 68.7730\n",
      "val Loss: 83.9854\n",
      "\n",
      "Epoch 50/2000\n",
      "train Loss: 54.6515\n",
      "val Loss: 68.0372\n",
      "\n",
      "Epoch 60/2000\n",
      "train Loss: 44.2332\n",
      "val Loss: 55.8891\n",
      "\n",
      "Epoch 70/2000\n",
      "train Loss: 36.4557\n",
      "val Loss: 46.6094\n",
      "\n",
      "Epoch 80/2000\n",
      "train Loss: 31.1764\n",
      "val Loss: 40.0572\n",
      "\n",
      "Epoch 90/2000\n",
      "train Loss: 27.2754\n",
      "val Loss: 35.0266\n",
      "\n",
      "Epoch 100/2000\n",
      "train Loss: 24.4592\n",
      "val Loss: 31.2498\n",
      "\n",
      "Epoch 110/2000\n",
      "train Loss: 22.4738\n",
      "val Loss: 28.3591\n",
      "\n",
      "Epoch 120/2000\n",
      "train Loss: 20.9493\n",
      "val Loss: 26.0320\n",
      "\n",
      "Epoch 130/2000\n",
      "train Loss: 19.9967\n",
      "val Loss: 24.4686\n",
      "\n",
      "Epoch 140/2000\n",
      "train Loss: 19.3658\n",
      "val Loss: 23.3105\n",
      "\n",
      "Epoch 150/2000\n",
      "train Loss: 18.8648\n",
      "val Loss: 22.2941\n",
      "\n",
      "Epoch 160/2000\n",
      "train Loss: 18.5701\n",
      "val Loss: 21.6161\n",
      "\n",
      "Epoch 170/2000\n",
      "train Loss: 18.3796\n",
      "val Loss: 21.0975\n",
      "\n",
      "Epoch 180/2000\n",
      "train Loss: 18.2728\n",
      "val Loss: 20.7535\n",
      "\n",
      "Epoch 190/2000\n",
      "train Loss: 18.2343\n",
      "val Loss: 20.6079\n",
      "\n",
      "Epoch 200/2000\n",
      "train Loss: 18.2179\n",
      "val Loss: 20.5443\n",
      "\n",
      "Epoch 210/2000\n",
      "train Loss: 18.1845\n",
      "val Loss: 20.3777\n",
      "\n",
      "Epoch 220/2000\n",
      "train Loss: 18.1551\n",
      "val Loss: 20.2054\n",
      "\n",
      "Epoch 230/2000\n",
      "train Loss: 18.1450\n",
      "val Loss: 20.1256\n",
      "\n",
      "Epoch 240/2000\n",
      "train Loss: 18.1310\n",
      "val Loss: 20.0094\n",
      "\n",
      "Epoch 250/2000\n",
      "train Loss: 18.1239\n",
      "val Loss: 19.9145\n",
      "\n",
      "Epoch 260/2000\n",
      "train Loss: 18.1195\n",
      "val Loss: 19.8040\n",
      "\n",
      "Epoch 270/2000\n",
      "train Loss: 18.1197\n",
      "val Loss: 19.7796\n",
      "\n",
      "Epoch 280/2000\n",
      "train Loss: 18.1200\n",
      "val Loss: 19.7173\n",
      "\n",
      "Epoch 290/2000\n",
      "train Loss: 18.1196\n",
      "val Loss: 19.7269\n",
      "\n",
      "Epoch 300/2000\n",
      "train Loss: 18.1210\n",
      "val Loss: 19.6998\n",
      "\n",
      "Epoch 310/2000\n",
      "train Loss: 18.1192\n",
      "val Loss: 19.7699\n",
      "\n",
      "Epoch 320/2000\n",
      "train Loss: 18.1197\n",
      "val Loss: 19.7389\n",
      "\n",
      "Epoch 330/2000\n",
      "train Loss: 18.1192\n",
      "val Loss: 19.8056\n",
      "\n",
      "Epoch 340/2000\n",
      "train Loss: 18.1193\n",
      "val Loss: 19.7821\n",
      "\n",
      "Epoch 350/2000\n",
      "train Loss: 18.1201\n",
      "val Loss: 19.6828\n",
      "\n",
      "Epoch 360/2000\n",
      "train Loss: 18.1265\n",
      "val Loss: 19.5996\n",
      "\n",
      "Epoch 370/2000\n",
      "train Loss: 18.1256\n",
      "val Loss: 19.6000\n",
      "\n",
      "Epoch 380/2000\n",
      "train Loss: 18.1238\n",
      "val Loss: 19.6357\n",
      "\n",
      "Epoch 390/2000\n",
      "train Loss: 18.1231\n",
      "val Loss: 19.6461\n",
      "\n",
      "Epoch 400/2000\n",
      "train Loss: 18.1240\n",
      "val Loss: 19.6171\n",
      "\n",
      "Epoch 410/2000\n",
      "train Loss: 18.0932\n",
      "val Loss: 19.7871\n",
      "\n",
      "Epoch 420/2000\n",
      "train Loss: 18.0896\n",
      "val Loss: 19.8701\n",
      "\n",
      "Epoch 430/2000\n",
      "train Loss: 18.0897\n",
      "val Loss: 19.9038\n",
      "\n",
      "Epoch 440/2000\n",
      "train Loss: 18.0841\n",
      "val Loss: 19.8305\n",
      "\n",
      "Epoch 450/2000\n",
      "train Loss: 18.0861\n",
      "val Loss: 19.8913\n",
      "\n",
      "Epoch 460/2000\n",
      "train Loss: 18.0750\n",
      "val Loss: 19.7440\n",
      "\n",
      "Epoch 470/2000\n",
      "train Loss: 18.0854\n",
      "val Loss: 19.5918\n",
      "\n",
      "Epoch 480/2000\n",
      "train Loss: 18.0831\n",
      "val Loss: 19.5851\n",
      "\n",
      "Epoch 490/2000\n",
      "train Loss: 18.0728\n",
      "val Loss: 19.6291\n",
      "\n",
      "Epoch 500/2000\n",
      "train Loss: 18.0791\n",
      "val Loss: 19.6833\n",
      "\n",
      "Epoch 510/2000\n",
      "train Loss: 18.0571\n",
      "val Loss: 19.8136\n",
      "\n",
      "Epoch 520/2000\n",
      "train Loss: 18.0604\n",
      "val Loss: 20.0044\n",
      "\n",
      "Epoch 530/2000\n",
      "train Loss: 18.0443\n",
      "val Loss: 19.9256\n",
      "\n",
      "Epoch 540/2000\n",
      "train Loss: 18.0365\n",
      "val Loss: 19.9248\n",
      "\n",
      "Epoch 550/2000\n",
      "train Loss: 18.0355\n",
      "val Loss: 20.0020\n",
      "\n",
      "Epoch 560/2000\n",
      "train Loss: 18.0428\n",
      "val Loss: 20.1568\n",
      "\n",
      "Epoch 570/2000\n",
      "train Loss: 18.0265\n",
      "val Loss: 20.1543\n",
      "\n",
      "Epoch 580/2000\n",
      "train Loss: 17.9958\n",
      "val Loss: 19.8767\n",
      "\n",
      "Epoch 590/2000\n",
      "train Loss: 17.9990\n",
      "val Loss: 19.7728\n",
      "\n",
      "Epoch 600/2000\n",
      "train Loss: 17.9814\n",
      "val Loss: 19.6491\n",
      "\n",
      "Epoch 610/2000\n",
      "train Loss: 17.9742\n",
      "val Loss: 19.7684\n",
      "\n",
      "Epoch 620/2000\n",
      "train Loss: 17.9615\n",
      "val Loss: 19.8658\n",
      "\n",
      "Epoch 630/2000\n",
      "train Loss: 17.9764\n",
      "val Loss: 20.0111\n",
      "\n",
      "Epoch 640/2000\n",
      "train Loss: 17.9324\n",
      "val Loss: 20.0926\n",
      "\n",
      "Epoch 650/2000\n",
      "train Loss: 17.9076\n",
      "val Loss: 20.1665\n",
      "\n",
      "Epoch 660/2000\n",
      "train Loss: 17.8655\n",
      "val Loss: 20.0467\n",
      "\n",
      "Epoch 670/2000\n",
      "train Loss: 17.8050\n",
      "val Loss: 19.9124\n",
      "\n",
      "Epoch 680/2000\n",
      "train Loss: 17.7824\n",
      "val Loss: 19.7898\n",
      "\n",
      "Epoch 690/2000\n",
      "train Loss: 17.6420\n",
      "val Loss: 20.1543\n",
      "\n",
      "Epoch 700/2000\n",
      "train Loss: 17.5683\n",
      "val Loss: 20.1364\n",
      "\n",
      "Epoch 710/2000\n",
      "train Loss: 17.5371\n",
      "val Loss: 20.2774\n",
      "\n",
      "Epoch 720/2000\n",
      "train Loss: 17.4403\n",
      "val Loss: 19.8129\n",
      "\n",
      "Epoch 730/2000\n",
      "train Loss: 17.2886\n",
      "val Loss: 20.0595\n",
      "\n",
      "Epoch 740/2000\n",
      "train Loss: 17.3125\n",
      "val Loss: 20.5344\n",
      "\n",
      "Epoch 750/2000\n",
      "train Loss: 17.1088\n",
      "val Loss: 20.0284\n",
      "\n",
      "Epoch 760/2000\n",
      "train Loss: 17.0953\n",
      "val Loss: 20.1991\n",
      "\n",
      "Epoch 770/2000\n",
      "train Loss: 16.9278\n",
      "val Loss: 20.2487\n",
      "\n",
      "Epoch 780/2000\n",
      "train Loss: 17.0419\n",
      "val Loss: 20.5176\n",
      "\n",
      "Epoch 790/2000\n",
      "train Loss: 16.7280\n",
      "val Loss: 20.0414\n",
      "\n",
      "Epoch 800/2000\n",
      "train Loss: 16.5733\n",
      "val Loss: 20.5286\n",
      "\n",
      "Epoch 810/2000\n",
      "train Loss: 16.5253\n",
      "val Loss: 20.5374\n",
      "\n",
      "Epoch 820/2000\n",
      "train Loss: 16.3325\n",
      "val Loss: 20.0214\n",
      "\n",
      "Epoch 830/2000\n",
      "train Loss: 16.1600\n",
      "val Loss: 20.9454\n",
      "\n",
      "Epoch 840/2000\n",
      "train Loss: 15.9602\n",
      "val Loss: 20.3394\n",
      "\n",
      "Epoch 850/2000\n",
      "train Loss: 15.8933\n",
      "val Loss: 21.6603\n",
      "\n",
      "Epoch 860/2000\n",
      "train Loss: 15.8890\n",
      "val Loss: 21.2810\n",
      "\n",
      "Epoch 870/2000\n",
      "train Loss: 16.0858\n",
      "val Loss: 22.7251\n",
      "\n",
      "Epoch 880/2000\n",
      "train Loss: 14.9623\n",
      "val Loss: 19.9141\n",
      "\n",
      "Epoch 890/2000\n",
      "train Loss: 16.0772\n",
      "val Loss: 19.4306\n",
      "\n",
      "Epoch 900/2000\n",
      "train Loss: 14.5687\n",
      "val Loss: 23.1886\n",
      "\n",
      "Epoch 910/2000\n",
      "train Loss: 14.2914\n",
      "val Loss: 21.0466\n",
      "\n",
      "Epoch 920/2000\n",
      "train Loss: 13.8408\n",
      "val Loss: 20.1744\n",
      "\n",
      "Epoch 930/2000\n",
      "train Loss: 14.2202\n",
      "val Loss: 24.8416\n",
      "\n",
      "Epoch 940/2000\n",
      "train Loss: 16.3148\n",
      "val Loss: 24.0953\n",
      "\n",
      "Epoch 950/2000\n",
      "train Loss: 13.0888\n",
      "val Loss: 21.5687\n",
      "\n",
      "Epoch 960/2000\n",
      "train Loss: 12.3300\n",
      "val Loss: 24.9841\n",
      "\n",
      "Epoch 970/2000\n",
      "train Loss: 11.7612\n",
      "val Loss: 24.0559\n",
      "\n",
      "Epoch 980/2000\n",
      "train Loss: 11.9375\n",
      "val Loss: 20.6106\n",
      "\n",
      "Epoch 990/2000\n",
      "train Loss: 11.7930\n",
      "val Loss: 19.3533\n",
      "\n",
      "Epoch 1000/2000\n",
      "train Loss: 12.2699\n",
      "val Loss: 25.8059\n",
      "\n",
      "Epoch 1010/2000\n",
      "train Loss: 11.3486\n",
      "val Loss: 26.3913\n",
      "\n",
      "Epoch 1020/2000\n",
      "train Loss: 11.2388\n",
      "val Loss: 24.8750\n",
      "\n",
      "Epoch 1030/2000\n",
      "train Loss: 11.0047\n",
      "val Loss: 21.0426\n",
      "\n",
      "Epoch 1040/2000\n",
      "train Loss: 11.4893\n",
      "val Loss: 20.9924\n",
      "\n",
      "Epoch 1050/2000\n",
      "train Loss: 11.1540\n",
      "val Loss: 26.7608\n",
      "\n",
      "Epoch 1060/2000\n",
      "train Loss: 10.8889\n",
      "val Loss: 26.5744\n",
      "\n",
      "Epoch 1070/2000\n",
      "train Loss: 17.7884\n",
      "val Loss: 20.9617\n",
      "\n",
      "Epoch 1080/2000\n",
      "train Loss: 14.3653\n",
      "val Loss: 23.3816\n",
      "\n",
      "Epoch 1090/2000\n",
      "train Loss: 11.8691\n",
      "val Loss: 25.0304\n",
      "\n",
      "Epoch 1100/2000\n",
      "train Loss: 10.8106\n",
      "val Loss: 24.8841\n",
      "\n",
      "Epoch 1110/2000\n",
      "train Loss: 10.6445\n",
      "val Loss: 25.1632\n",
      "\n",
      "Epoch 1120/2000\n",
      "train Loss: 11.5486\n",
      "val Loss: 25.6971\n",
      "\n",
      "Epoch 1130/2000\n",
      "train Loss: 10.5742\n",
      "val Loss: 27.8850\n",
      "\n",
      "Epoch 1140/2000\n",
      "train Loss: 11.7658\n",
      "val Loss: 20.5184\n",
      "\n",
      "Epoch 1150/2000\n",
      "train Loss: 10.2806\n",
      "val Loss: 27.3996\n",
      "\n",
      "Epoch 1160/2000\n",
      "train Loss: 11.4541\n",
      "val Loss: 23.8802\n",
      "\n",
      "Epoch 1170/2000\n",
      "train Loss: 10.4072\n",
      "val Loss: 27.3330\n",
      "\n",
      "Epoch 1180/2000\n",
      "train Loss: 10.3990\n",
      "val Loss: 25.8318\n",
      "\n",
      "Epoch 1190/2000\n",
      "train Loss: 10.9811\n",
      "val Loss: 27.3764\n",
      "\n",
      "Epoch 1200/2000\n",
      "train Loss: 10.1219\n",
      "val Loss: 25.3770\n",
      "\n",
      "Epoch 1210/2000\n",
      "train Loss: 10.2552\n",
      "val Loss: 27.0351\n",
      "\n",
      "Epoch 1220/2000\n",
      "train Loss: 10.0146\n",
      "val Loss: 24.6761\n",
      "\n",
      "Epoch 1230/2000\n",
      "train Loss: 11.6106\n",
      "val Loss: 22.8614\n",
      "\n",
      "Epoch 1240/2000\n",
      "train Loss: 10.3099\n",
      "val Loss: 25.2721\n",
      "\n",
      "Epoch 1250/2000\n",
      "train Loss: 9.9544\n",
      "val Loss: 23.9949\n",
      "\n",
      "Epoch 1260/2000\n",
      "train Loss: 9.9712\n",
      "val Loss: 22.7337\n",
      "\n",
      "Epoch 1270/2000\n",
      "train Loss: 9.9444\n",
      "val Loss: 22.8598\n",
      "\n",
      "Epoch 1280/2000\n",
      "train Loss: 9.6480\n",
      "val Loss: 23.4129\n",
      "\n",
      "Epoch 1290/2000\n",
      "train Loss: 27.0135\n",
      "val Loss: 21.3653\n",
      "\n",
      "Epoch 1300/2000\n",
      "train Loss: 17.7415\n",
      "val Loss: 23.2617\n",
      "\n",
      "Epoch 1310/2000\n",
      "train Loss: 16.8997\n",
      "val Loss: 19.6023\n",
      "\n",
      "Epoch 1320/2000\n",
      "train Loss: 16.6662\n",
      "val Loss: 19.3492\n",
      "\n",
      "Epoch 1330/2000\n",
      "train Loss: 16.4718\n",
      "val Loss: 19.6502\n",
      "\n",
      "Epoch 1340/2000\n",
      "train Loss: 16.4026\n",
      "val Loss: 20.7345\n",
      "\n",
      "Epoch 1350/2000\n",
      "train Loss: 16.1870\n",
      "val Loss: 19.7772\n",
      "\n",
      "Epoch 1360/2000\n",
      "train Loss: 16.1962\n",
      "val Loss: 19.4400\n",
      "\n",
      "Epoch 1370/2000\n",
      "train Loss: 16.0369\n",
      "val Loss: 21.0146\n",
      "\n",
      "Epoch 1380/2000\n",
      "train Loss: 16.1795\n",
      "val Loss: 19.0079\n",
      "\n",
      "Epoch 1390/2000\n",
      "train Loss: 15.7710\n",
      "val Loss: 19.4159\n",
      "\n",
      "Epoch 1400/2000\n",
      "train Loss: 15.5981\n",
      "val Loss: 20.4759\n",
      "\n",
      "Epoch 1410/2000\n",
      "train Loss: 15.4190\n",
      "val Loss: 20.0629\n",
      "\n",
      "Epoch 1420/2000\n",
      "train Loss: 15.2547\n",
      "val Loss: 20.5366\n",
      "\n",
      "Epoch 1430/2000\n",
      "train Loss: 15.1443\n",
      "val Loss: 19.8880\n",
      "\n",
      "Epoch 1440/2000\n",
      "train Loss: 14.9465\n",
      "val Loss: 20.2878\n",
      "\n",
      "Epoch 1450/2000\n",
      "train Loss: 14.7312\n",
      "val Loss: 20.8336\n",
      "\n",
      "Epoch 1460/2000\n",
      "train Loss: 14.7572\n",
      "val Loss: 19.1632\n",
      "\n",
      "Epoch 1470/2000\n",
      "train Loss: 14.5837\n",
      "val Loss: 19.4287\n",
      "\n",
      "Epoch 1480/2000\n",
      "train Loss: 14.2625\n",
      "val Loss: 20.9305\n",
      "\n",
      "Epoch 1490/2000\n",
      "train Loss: 14.0232\n",
      "val Loss: 20.2105\n",
      "\n",
      "Epoch 1500/2000\n",
      "train Loss: 13.7992\n",
      "val Loss: 20.2515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1510/2000\n",
      "train Loss: 13.6305\n",
      "val Loss: 22.6995\n",
      "\n",
      "Epoch 1520/2000\n",
      "train Loss: 13.2463\n",
      "val Loss: 21.6716\n",
      "\n",
      "Epoch 1530/2000\n",
      "train Loss: 13.2165\n",
      "val Loss: 23.2589\n",
      "\n",
      "Epoch 1540/2000\n",
      "train Loss: 12.6946\n",
      "val Loss: 23.1882\n",
      "\n",
      "Epoch 1550/2000\n",
      "train Loss: 12.6467\n",
      "val Loss: 24.3126\n",
      "\n",
      "Epoch 1560/2000\n",
      "train Loss: 14.1852\n",
      "val Loss: 21.2180\n",
      "\n",
      "Epoch 1570/2000\n",
      "train Loss: 12.4202\n",
      "val Loss: 22.4764\n",
      "\n",
      "Epoch 1580/2000\n",
      "train Loss: 12.7161\n",
      "val Loss: 27.9974\n",
      "\n",
      "Epoch 1590/2000\n",
      "train Loss: 11.7886\n",
      "val Loss: 24.5786\n",
      "\n",
      "Epoch 1600/2000\n",
      "train Loss: 12.0838\n",
      "val Loss: 22.5590\n",
      "\n",
      "Epoch 1610/2000\n",
      "train Loss: 12.3468\n",
      "val Loss: 22.3414\n",
      "\n",
      "Epoch 1620/2000\n",
      "train Loss: 11.1514\n",
      "val Loss: 27.1706\n",
      "\n",
      "Epoch 1630/2000\n",
      "train Loss: 11.7463\n",
      "val Loss: 24.9906\n",
      "\n",
      "Epoch 1640/2000\n",
      "train Loss: 11.3121\n",
      "val Loss: 23.3708\n",
      "\n",
      "Epoch 1650/2000\n",
      "train Loss: 12.8897\n",
      "val Loss: 27.7300\n",
      "\n",
      "Epoch 1660/2000\n",
      "train Loss: 11.5212\n",
      "val Loss: 22.2421\n",
      "\n",
      "Epoch 1670/2000\n",
      "train Loss: 10.4326\n",
      "val Loss: 25.3108\n",
      "\n",
      "Epoch 1680/2000\n",
      "train Loss: 10.1438\n",
      "val Loss: 29.7218\n",
      "\n",
      "Epoch 1690/2000\n",
      "train Loss: 10.5348\n",
      "val Loss: 22.5391\n",
      "\n",
      "Epoch 1700/2000\n",
      "train Loss: 9.8628\n",
      "val Loss: 27.2276\n",
      "\n",
      "Epoch 1710/2000\n",
      "train Loss: 10.5077\n",
      "val Loss: 25.4861\n",
      "\n",
      "Epoch 1720/2000\n",
      "train Loss: 9.6802\n",
      "val Loss: 26.2829\n",
      "\n",
      "Epoch 1730/2000\n",
      "train Loss: 9.0100\n",
      "val Loss: 27.8916\n",
      "\n",
      "Epoch 1740/2000\n",
      "train Loss: 9.1927\n",
      "val Loss: 28.0038\n",
      "\n",
      "Epoch 1750/2000\n",
      "train Loss: 8.9389\n",
      "val Loss: 29.0859\n",
      "\n",
      "Epoch 1760/2000\n",
      "train Loss: 8.5847\n",
      "val Loss: 33.8141\n",
      "\n",
      "Epoch 1770/2000\n",
      "train Loss: 8.8670\n",
      "val Loss: 28.7415\n",
      "\n",
      "Epoch 1780/2000\n",
      "train Loss: 8.7758\n",
      "val Loss: 28.7466\n",
      "\n",
      "Epoch 1790/2000\n",
      "train Loss: 10.1463\n",
      "val Loss: 28.1330\n",
      "\n",
      "Epoch 1800/2000\n",
      "train Loss: 8.9456\n",
      "val Loss: 32.1155\n",
      "\n",
      "Epoch 1810/2000\n",
      "train Loss: 8.1087\n",
      "val Loss: 29.0998\n",
      "\n",
      "Epoch 1820/2000\n",
      "train Loss: 8.1340\n",
      "val Loss: 28.3816\n",
      "\n",
      "Epoch 1830/2000\n",
      "train Loss: 8.4060\n",
      "val Loss: 29.3916\n",
      "\n",
      "Epoch 1840/2000\n",
      "train Loss: 10.3337\n",
      "val Loss: 23.4133\n",
      "\n",
      "Epoch 1850/2000\n",
      "train Loss: 7.9876\n",
      "val Loss: 29.7980\n",
      "\n",
      "Epoch 1860/2000\n",
      "train Loss: 8.0592\n",
      "val Loss: 26.5925\n",
      "\n",
      "Epoch 1870/2000\n",
      "train Loss: 7.5881\n",
      "val Loss: 31.4752\n",
      "\n",
      "Epoch 1880/2000\n",
      "train Loss: 7.2145\n",
      "val Loss: 30.4216\n",
      "\n",
      "Epoch 1890/2000\n",
      "train Loss: 7.7201\n",
      "val Loss: 29.5647\n",
      "\n",
      "Epoch 1900/2000\n",
      "train Loss: 7.8266\n",
      "val Loss: 29.9311\n",
      "\n",
      "Epoch 1910/2000\n",
      "train Loss: 7.7231\n",
      "val Loss: 27.6647\n",
      "\n",
      "Epoch 1920/2000\n",
      "train Loss: 7.5531\n",
      "val Loss: 28.8163\n",
      "\n",
      "Epoch 1930/2000\n",
      "train Loss: 7.4124\n",
      "val Loss: 28.3095\n",
      "\n",
      "Epoch 1940/2000\n",
      "train Loss: 7.0475\n",
      "val Loss: 31.8578\n",
      "\n",
      "Epoch 1950/2000\n",
      "train Loss: 6.9685\n",
      "val Loss: 28.6992\n",
      "\n",
      "Epoch 1960/2000\n",
      "train Loss: 6.8791\n",
      "val Loss: 32.9981\n",
      "\n",
      "Epoch 1970/2000\n",
      "train Loss: 6.7743\n",
      "val Loss: 30.3941\n",
      "\n",
      "Epoch 1980/2000\n",
      "train Loss: 9.9494\n",
      "val Loss: 26.7877\n",
      "\n",
      "Epoch 1990/2000\n",
      "train Loss: 7.2317\n",
      "val Loss: 31.1220\n",
      "\n",
      "Epoch 2000/2000\n",
      "train Loss: 6.8410\n",
      "val Loss: 32.4520\n",
      "\n",
      "Training complete in 1m 3s\n",
      "Best val Loss: 16.731924\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 19.17499 and R2: -3.5619\n",
      "test RMSE: 4.3789\n"
     ]
    }
   ],
   "source": [
    "# Case 2. GRU (w/o data representation)\n",
    "config = config2\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "917f5a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/2000\n",
      "train Loss: 126.0176\n",
      "val Loss: 31.5952\n",
      "\n",
      "Epoch 10/2000\n",
      "train Loss: 28.8105\n",
      "val Loss: 27.8481\n",
      "\n",
      "Epoch 20/2000\n",
      "train Loss: 24.7747\n",
      "val Loss: 21.8527\n",
      "\n",
      "Epoch 30/2000\n",
      "train Loss: 25.0509\n",
      "val Loss: 20.0571\n",
      "\n",
      "Epoch 40/2000\n",
      "train Loss: 26.8283\n",
      "val Loss: 20.2179\n",
      "\n",
      "Epoch 50/2000\n",
      "train Loss: 20.5226\n",
      "val Loss: 23.6409\n",
      "\n",
      "Epoch 60/2000\n",
      "train Loss: 20.8485\n",
      "val Loss: 23.3904\n",
      "\n",
      "Epoch 70/2000\n",
      "train Loss: 18.9526\n",
      "val Loss: 20.7253\n",
      "\n",
      "Epoch 80/2000\n",
      "train Loss: 19.2484\n",
      "val Loss: 21.5913\n",
      "\n",
      "Epoch 90/2000\n",
      "train Loss: 17.6067\n",
      "val Loss: 21.7909\n",
      "\n",
      "Epoch 100/2000\n",
      "train Loss: 18.6615\n",
      "val Loss: 21.3158\n",
      "\n",
      "Epoch 110/2000\n",
      "train Loss: 19.9427\n",
      "val Loss: 20.6759\n",
      "\n",
      "Epoch 120/2000\n",
      "train Loss: 18.2787\n",
      "val Loss: 24.5962\n",
      "\n",
      "Epoch 130/2000\n",
      "train Loss: 17.1683\n",
      "val Loss: 23.8187\n",
      "\n",
      "Epoch 140/2000\n",
      "train Loss: 17.6127\n",
      "val Loss: 21.2991\n",
      "\n",
      "Epoch 150/2000\n",
      "train Loss: 15.5843\n",
      "val Loss: 21.1685\n",
      "\n",
      "Epoch 160/2000\n",
      "train Loss: 18.9864\n",
      "val Loss: 21.7208\n",
      "\n",
      "Epoch 170/2000\n",
      "train Loss: 14.8610\n",
      "val Loss: 25.8490\n",
      "\n",
      "Epoch 180/2000\n",
      "train Loss: 16.0135\n",
      "val Loss: 21.3702\n",
      "\n",
      "Epoch 190/2000\n",
      "train Loss: 14.6455\n",
      "val Loss: 24.3031\n",
      "\n",
      "Epoch 200/2000\n",
      "train Loss: 15.9505\n",
      "val Loss: 22.4897\n",
      "\n",
      "Epoch 210/2000\n",
      "train Loss: 14.9928\n",
      "val Loss: 24.0399\n",
      "\n",
      "Epoch 220/2000\n",
      "train Loss: 15.2451\n",
      "val Loss: 24.6077\n",
      "\n",
      "Epoch 230/2000\n",
      "train Loss: 16.0670\n",
      "val Loss: 27.2771\n",
      "\n",
      "Epoch 240/2000\n",
      "train Loss: 14.9736\n",
      "val Loss: 25.0774\n",
      "\n",
      "Epoch 250/2000\n",
      "train Loss: 13.5921\n",
      "val Loss: 23.0793\n",
      "\n",
      "Epoch 260/2000\n",
      "train Loss: 13.5268\n",
      "val Loss: 23.7063\n",
      "\n",
      "Epoch 270/2000\n",
      "train Loss: 15.4092\n",
      "val Loss: 24.1365\n",
      "\n",
      "Epoch 280/2000\n",
      "train Loss: 13.3932\n",
      "val Loss: 23.9303\n",
      "\n",
      "Epoch 290/2000\n",
      "train Loss: 13.6702\n",
      "val Loss: 23.1885\n",
      "\n",
      "Epoch 300/2000\n",
      "train Loss: 12.9609\n",
      "val Loss: 23.4547\n",
      "\n",
      "Epoch 310/2000\n",
      "train Loss: 15.3708\n",
      "val Loss: 28.2962\n",
      "\n",
      "Epoch 320/2000\n",
      "train Loss: 12.9181\n",
      "val Loss: 25.9980\n",
      "\n",
      "Epoch 330/2000\n",
      "train Loss: 13.2142\n",
      "val Loss: 25.1499\n",
      "\n",
      "Epoch 340/2000\n",
      "train Loss: 13.7134\n",
      "val Loss: 29.9700\n",
      "\n",
      "Epoch 350/2000\n",
      "train Loss: 11.7735\n",
      "val Loss: 26.6257\n",
      "\n",
      "Epoch 360/2000\n",
      "train Loss: 12.3036\n",
      "val Loss: 31.2140\n",
      "\n",
      "Epoch 370/2000\n",
      "train Loss: 11.8232\n",
      "val Loss: 26.0758\n",
      "\n",
      "Epoch 380/2000\n",
      "train Loss: 13.3624\n",
      "val Loss: 28.5894\n",
      "\n",
      "Epoch 390/2000\n",
      "train Loss: 12.2571\n",
      "val Loss: 28.2242\n",
      "\n",
      "Epoch 400/2000\n",
      "train Loss: 13.9360\n",
      "val Loss: 27.0025\n",
      "\n",
      "Epoch 410/2000\n",
      "train Loss: 13.5730\n",
      "val Loss: 25.4762\n",
      "\n",
      "Epoch 420/2000\n",
      "train Loss: 11.8218\n",
      "val Loss: 26.9566\n",
      "\n",
      "Epoch 430/2000\n",
      "train Loss: 12.6910\n",
      "val Loss: 27.3111\n",
      "\n",
      "Epoch 440/2000\n",
      "train Loss: 10.8577\n",
      "val Loss: 26.8239\n",
      "\n",
      "Epoch 450/2000\n",
      "train Loss: 11.4045\n",
      "val Loss: 27.1655\n",
      "\n",
      "Epoch 460/2000\n",
      "train Loss: 12.5604\n",
      "val Loss: 29.8342\n",
      "\n",
      "Epoch 470/2000\n",
      "train Loss: 11.0669\n",
      "val Loss: 27.6543\n",
      "\n",
      "Epoch 480/2000\n",
      "train Loss: 11.7870\n",
      "val Loss: 27.1390\n",
      "\n",
      "Epoch 490/2000\n",
      "train Loss: 10.6603\n",
      "val Loss: 28.1680\n",
      "\n",
      "Epoch 500/2000\n",
      "train Loss: 10.6435\n",
      "val Loss: 29.0207\n",
      "\n",
      "Epoch 510/2000\n",
      "train Loss: 10.6572\n",
      "val Loss: 28.6067\n",
      "\n",
      "Epoch 520/2000\n",
      "train Loss: 9.7652\n",
      "val Loss: 27.6950\n",
      "\n",
      "Epoch 530/2000\n",
      "train Loss: 9.2036\n",
      "val Loss: 27.7640\n",
      "\n",
      "Epoch 540/2000\n",
      "train Loss: 9.3094\n",
      "val Loss: 28.1893\n",
      "\n",
      "Epoch 550/2000\n",
      "train Loss: 11.2913\n",
      "val Loss: 27.9871\n",
      "\n",
      "Epoch 560/2000\n",
      "train Loss: 11.9476\n",
      "val Loss: 30.0272\n",
      "\n",
      "Epoch 570/2000\n",
      "train Loss: 10.4439\n",
      "val Loss: 30.6940\n",
      "\n",
      "Epoch 580/2000\n",
      "train Loss: 9.8045\n",
      "val Loss: 28.7516\n",
      "\n",
      "Epoch 590/2000\n",
      "train Loss: 9.4216\n",
      "val Loss: 29.8797\n",
      "\n",
      "Epoch 600/2000\n",
      "train Loss: 9.9577\n",
      "val Loss: 28.8418\n",
      "\n",
      "Epoch 610/2000\n",
      "train Loss: 8.4650\n",
      "val Loss: 28.8896\n",
      "\n",
      "Epoch 620/2000\n",
      "train Loss: 9.3669\n",
      "val Loss: 28.7177\n",
      "\n",
      "Epoch 630/2000\n",
      "train Loss: 8.0086\n",
      "val Loss: 29.3983\n",
      "\n",
      "Epoch 640/2000\n",
      "train Loss: 8.1158\n",
      "val Loss: 29.4367\n",
      "\n",
      "Epoch 650/2000\n",
      "train Loss: 9.4474\n",
      "val Loss: 30.2157\n",
      "\n",
      "Epoch 660/2000\n",
      "train Loss: 9.0283\n",
      "val Loss: 29.1632\n",
      "\n",
      "Epoch 670/2000\n",
      "train Loss: 8.1175\n",
      "val Loss: 28.4228\n",
      "\n",
      "Epoch 680/2000\n",
      "train Loss: 7.3307\n",
      "val Loss: 29.0121\n",
      "\n",
      "Epoch 690/2000\n",
      "train Loss: 9.9336\n",
      "val Loss: 29.7215\n",
      "\n",
      "Epoch 700/2000\n",
      "train Loss: 8.7909\n",
      "val Loss: 31.5688\n",
      "\n",
      "Epoch 710/2000\n",
      "train Loss: 6.6821\n",
      "val Loss: 30.7189\n",
      "\n",
      "Epoch 720/2000\n",
      "train Loss: 7.5469\n",
      "val Loss: 31.7347\n",
      "\n",
      "Epoch 730/2000\n",
      "train Loss: 8.9741\n",
      "val Loss: 30.9459\n",
      "\n",
      "Epoch 740/2000\n",
      "train Loss: 7.0719\n",
      "val Loss: 31.1407\n",
      "\n",
      "Epoch 750/2000\n",
      "train Loss: 7.5539\n",
      "val Loss: 30.7049\n",
      "\n",
      "Epoch 760/2000\n",
      "train Loss: 7.8432\n",
      "val Loss: 30.3379\n",
      "\n",
      "Epoch 770/2000\n",
      "train Loss: 6.6648\n",
      "val Loss: 31.1935\n",
      "\n",
      "Epoch 780/2000\n",
      "train Loss: 6.2840\n",
      "val Loss: 31.7481\n",
      "\n",
      "Epoch 790/2000\n",
      "train Loss: 8.2413\n",
      "val Loss: 29.5132\n",
      "\n",
      "Epoch 800/2000\n",
      "train Loss: 6.6442\n",
      "val Loss: 31.3649\n",
      "\n",
      "Epoch 810/2000\n",
      "train Loss: 7.0400\n",
      "val Loss: 31.4154\n",
      "\n",
      "Epoch 820/2000\n",
      "train Loss: 6.7424\n",
      "val Loss: 31.5156\n",
      "\n",
      "Epoch 830/2000\n",
      "train Loss: 6.3044\n",
      "val Loss: 29.8971\n",
      "\n",
      "Epoch 840/2000\n",
      "train Loss: 5.6154\n",
      "val Loss: 31.4166\n",
      "\n",
      "Epoch 850/2000\n",
      "train Loss: 6.4532\n",
      "val Loss: 30.6678\n",
      "\n",
      "Epoch 860/2000\n",
      "train Loss: 6.3851\n",
      "val Loss: 31.8651\n",
      "\n",
      "Epoch 870/2000\n",
      "train Loss: 6.3216\n",
      "val Loss: 33.9897\n",
      "\n",
      "Epoch 880/2000\n",
      "train Loss: 8.7591\n",
      "val Loss: 30.9371\n",
      "\n",
      "Epoch 890/2000\n",
      "train Loss: 9.4715\n",
      "val Loss: 32.8799\n",
      "\n",
      "Epoch 900/2000\n",
      "train Loss: 5.1142\n",
      "val Loss: 32.9907\n",
      "\n",
      "Epoch 910/2000\n",
      "train Loss: 5.0909\n",
      "val Loss: 32.0609\n",
      "\n",
      "Epoch 920/2000\n",
      "train Loss: 5.7607\n",
      "val Loss: 32.4107\n",
      "\n",
      "Epoch 930/2000\n",
      "train Loss: 6.2621\n",
      "val Loss: 33.6434\n",
      "\n",
      "Epoch 940/2000\n",
      "train Loss: 4.9841\n",
      "val Loss: 33.8029\n",
      "\n",
      "Epoch 950/2000\n",
      "train Loss: 4.6107\n",
      "val Loss: 33.7206\n",
      "\n",
      "Epoch 960/2000\n",
      "train Loss: 5.0287\n",
      "val Loss: 34.7663\n",
      "\n",
      "Epoch 970/2000\n",
      "train Loss: 5.2119\n",
      "val Loss: 34.2253\n",
      "\n",
      "Epoch 980/2000\n",
      "train Loss: 6.4532\n",
      "val Loss: 33.2410\n",
      "\n",
      "Epoch 990/2000\n",
      "train Loss: 4.2130\n",
      "val Loss: 35.0635\n",
      "\n",
      "Epoch 1000/2000\n",
      "train Loss: 6.0861\n",
      "val Loss: 35.6700\n",
      "\n",
      "Epoch 1010/2000\n",
      "train Loss: 4.9231\n",
      "val Loss: 36.6936\n",
      "\n",
      "Epoch 1020/2000\n",
      "train Loss: 6.4357\n",
      "val Loss: 34.0671\n",
      "\n",
      "Epoch 1030/2000\n",
      "train Loss: 5.1307\n",
      "val Loss: 34.3234\n",
      "\n",
      "Epoch 1040/2000\n",
      "train Loss: 4.5552\n",
      "val Loss: 32.7771\n",
      "\n",
      "Epoch 1050/2000\n",
      "train Loss: 4.7606\n",
      "val Loss: 33.1105\n",
      "\n",
      "Epoch 1060/2000\n",
      "train Loss: 3.9160\n",
      "val Loss: 33.2827\n",
      "\n",
      "Epoch 1070/2000\n",
      "train Loss: 3.9904\n",
      "val Loss: 34.1939\n",
      "\n",
      "Epoch 1080/2000\n",
      "train Loss: 4.2142\n",
      "val Loss: 34.5430\n",
      "\n",
      "Epoch 1090/2000\n",
      "train Loss: 5.4189\n",
      "val Loss: 35.2911\n",
      "\n",
      "Epoch 1100/2000\n",
      "train Loss: 4.3123\n",
      "val Loss: 37.7809\n",
      "\n",
      "Epoch 1110/2000\n",
      "train Loss: 6.0903\n",
      "val Loss: 35.5803\n",
      "\n",
      "Epoch 1120/2000\n",
      "train Loss: 4.2122\n",
      "val Loss: 33.8650\n",
      "\n",
      "Epoch 1130/2000\n",
      "train Loss: 3.9820\n",
      "val Loss: 34.4826\n",
      "\n",
      "Epoch 1140/2000\n",
      "train Loss: 3.3540\n",
      "val Loss: 36.7140\n",
      "\n",
      "Epoch 1150/2000\n",
      "train Loss: 3.3614\n",
      "val Loss: 35.4949\n",
      "\n",
      "Epoch 1160/2000\n",
      "train Loss: 3.6400\n",
      "val Loss: 40.6389\n",
      "\n",
      "Epoch 1170/2000\n",
      "train Loss: 4.4018\n",
      "val Loss: 34.4697\n",
      "\n",
      "Epoch 1180/2000\n",
      "train Loss: 3.6549\n",
      "val Loss: 35.8017\n",
      "\n",
      "Epoch 1190/2000\n",
      "train Loss: 4.6993\n",
      "val Loss: 34.9495\n",
      "\n",
      "Epoch 1200/2000\n",
      "train Loss: 3.1104\n",
      "val Loss: 36.7295\n",
      "\n",
      "Epoch 1210/2000\n",
      "train Loss: 4.8562\n",
      "val Loss: 34.5312\n",
      "\n",
      "Epoch 1220/2000\n",
      "train Loss: 5.4732\n",
      "val Loss: 33.1163\n",
      "\n",
      "Epoch 1230/2000\n",
      "train Loss: 3.9982\n",
      "val Loss: 35.9455\n",
      "\n",
      "Epoch 1240/2000\n",
      "train Loss: 4.3328\n",
      "val Loss: 36.4399\n",
      "\n",
      "Epoch 1250/2000\n",
      "train Loss: 4.6970\n",
      "val Loss: 37.5095\n",
      "\n",
      "Epoch 1260/2000\n",
      "train Loss: 3.9600\n",
      "val Loss: 37.0392\n",
      "\n",
      "Epoch 1270/2000\n",
      "train Loss: 3.8516\n",
      "val Loss: 36.8989\n",
      "\n",
      "Epoch 1280/2000\n",
      "train Loss: 3.3930\n",
      "val Loss: 36.5019\n",
      "\n",
      "Epoch 1290/2000\n",
      "train Loss: 3.4898\n",
      "val Loss: 36.3995\n",
      "\n",
      "Epoch 1300/2000\n",
      "train Loss: 3.6503\n",
      "val Loss: 36.9592\n",
      "\n",
      "Epoch 1310/2000\n",
      "train Loss: 4.6873\n",
      "val Loss: 37.6439\n",
      "\n",
      "Epoch 1320/2000\n",
      "train Loss: 3.6826\n",
      "val Loss: 38.5799\n",
      "\n",
      "Epoch 1330/2000\n",
      "train Loss: 3.8365\n",
      "val Loss: 37.8519\n",
      "\n",
      "Epoch 1340/2000\n",
      "train Loss: 2.9213\n",
      "val Loss: 37.4639\n",
      "\n",
      "Epoch 1350/2000\n",
      "train Loss: 2.9580\n",
      "val Loss: 36.8248\n",
      "\n",
      "Epoch 1360/2000\n",
      "train Loss: 2.9254\n",
      "val Loss: 37.9636\n",
      "\n",
      "Epoch 1370/2000\n",
      "train Loss: 3.7539\n",
      "val Loss: 36.9344\n",
      "\n",
      "Epoch 1380/2000\n",
      "train Loss: 4.3977\n",
      "val Loss: 36.6032\n",
      "\n",
      "Epoch 1390/2000\n",
      "train Loss: 1.6212\n",
      "val Loss: 37.5635\n",
      "\n",
      "Epoch 1400/2000\n",
      "train Loss: 2.9123\n",
      "val Loss: 38.3048\n",
      "\n",
      "Epoch 1410/2000\n",
      "train Loss: 3.2702\n",
      "val Loss: 37.7381\n",
      "\n",
      "Epoch 1420/2000\n",
      "train Loss: 2.3456\n",
      "val Loss: 37.3165\n",
      "\n",
      "Epoch 1430/2000\n",
      "train Loss: 3.6090\n",
      "val Loss: 37.3964\n",
      "\n",
      "Epoch 1440/2000\n",
      "train Loss: 2.8882\n",
      "val Loss: 39.8540\n",
      "\n",
      "Epoch 1450/2000\n",
      "train Loss: 3.3229\n",
      "val Loss: 37.0092\n",
      "\n",
      "Epoch 1460/2000\n",
      "train Loss: 2.7835\n",
      "val Loss: 38.2269\n",
      "\n",
      "Epoch 1470/2000\n",
      "train Loss: 3.0710\n",
      "val Loss: 36.2198\n",
      "\n",
      "Epoch 1480/2000\n",
      "train Loss: 2.8963\n",
      "val Loss: 38.1064\n",
      "\n",
      "Epoch 1490/2000\n",
      "train Loss: 2.9449\n",
      "val Loss: 38.0103\n",
      "\n",
      "Epoch 1500/2000\n",
      "train Loss: 3.2302\n",
      "val Loss: 38.2413\n",
      "\n",
      "Epoch 1510/2000\n",
      "train Loss: 3.2220\n",
      "val Loss: 37.4259\n",
      "\n",
      "Epoch 1520/2000\n",
      "train Loss: 4.3274\n",
      "val Loss: 39.5511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1530/2000\n",
      "train Loss: 2.5867\n",
      "val Loss: 37.7279\n",
      "\n",
      "Epoch 1540/2000\n",
      "train Loss: 2.5046\n",
      "val Loss: 38.2376\n",
      "\n",
      "Epoch 1550/2000\n",
      "train Loss: 2.7017\n",
      "val Loss: 36.5751\n",
      "\n",
      "Epoch 1560/2000\n",
      "train Loss: 3.9046\n",
      "val Loss: 37.8930\n",
      "\n",
      "Epoch 1570/2000\n",
      "train Loss: 2.2605\n",
      "val Loss: 38.2635\n",
      "\n",
      "Epoch 1580/2000\n",
      "train Loss: 2.7005\n",
      "val Loss: 38.7719\n",
      "\n",
      "Epoch 1590/2000\n",
      "train Loss: 2.7591\n",
      "val Loss: 38.9216\n",
      "\n",
      "Epoch 1600/2000\n",
      "train Loss: 2.0386\n",
      "val Loss: 39.8160\n",
      "\n",
      "Epoch 1610/2000\n",
      "train Loss: 2.9230\n",
      "val Loss: 40.6668\n",
      "\n",
      "Epoch 1620/2000\n",
      "train Loss: 2.1467\n",
      "val Loss: 38.9468\n",
      "\n",
      "Epoch 1630/2000\n",
      "train Loss: 2.4916\n",
      "val Loss: 39.3260\n",
      "\n",
      "Epoch 1640/2000\n",
      "train Loss: 2.7093\n",
      "val Loss: 39.9204\n",
      "\n",
      "Epoch 1650/2000\n",
      "train Loss: 2.5376\n",
      "val Loss: 39.3479\n",
      "\n",
      "Epoch 1660/2000\n",
      "train Loss: 3.1153\n",
      "val Loss: 39.9042\n",
      "\n",
      "Epoch 1670/2000\n",
      "train Loss: 2.6767\n",
      "val Loss: 38.0717\n",
      "\n",
      "Epoch 1680/2000\n",
      "train Loss: 2.5529\n",
      "val Loss: 39.4336\n",
      "\n",
      "Epoch 1690/2000\n",
      "train Loss: 1.7759\n",
      "val Loss: 38.7404\n",
      "\n",
      "Epoch 1700/2000\n",
      "train Loss: 2.4292\n",
      "val Loss: 39.5309\n",
      "\n",
      "Epoch 1710/2000\n",
      "train Loss: 2.4697\n",
      "val Loss: 40.4762\n",
      "\n",
      "Epoch 1720/2000\n",
      "train Loss: 2.4870\n",
      "val Loss: 39.1672\n",
      "\n",
      "Epoch 1730/2000\n",
      "train Loss: 2.0141\n",
      "val Loss: 40.0388\n",
      "\n",
      "Epoch 1740/2000\n",
      "train Loss: 2.3513\n",
      "val Loss: 38.4582\n",
      "\n",
      "Epoch 1750/2000\n",
      "train Loss: 1.5860\n",
      "val Loss: 39.6950\n",
      "\n",
      "Epoch 1760/2000\n",
      "train Loss: 2.1277\n",
      "val Loss: 40.0679\n",
      "\n",
      "Epoch 1770/2000\n",
      "train Loss: 1.5863\n",
      "val Loss: 40.3322\n",
      "\n",
      "Epoch 1780/2000\n",
      "train Loss: 2.8468\n",
      "val Loss: 39.5179\n",
      "\n",
      "Epoch 1790/2000\n",
      "train Loss: 2.1320\n",
      "val Loss: 39.5771\n",
      "\n",
      "Epoch 1800/2000\n",
      "train Loss: 2.0652\n",
      "val Loss: 39.8949\n",
      "\n",
      "Epoch 1810/2000\n",
      "train Loss: 1.8209\n",
      "val Loss: 38.4082\n",
      "\n",
      "Epoch 1820/2000\n",
      "train Loss: 2.1308\n",
      "val Loss: 38.6141\n",
      "\n",
      "Epoch 1830/2000\n",
      "train Loss: 2.3336\n",
      "val Loss: 40.0965\n",
      "\n",
      "Epoch 1840/2000\n",
      "train Loss: 1.9457\n",
      "val Loss: 39.8133\n",
      "\n",
      "Epoch 1850/2000\n",
      "train Loss: 3.2542\n",
      "val Loss: 40.1887\n",
      "\n",
      "Epoch 1860/2000\n",
      "train Loss: 2.4573\n",
      "val Loss: 41.6865\n",
      "\n",
      "Epoch 1870/2000\n",
      "train Loss: 1.5633\n",
      "val Loss: 41.4958\n",
      "\n",
      "Epoch 1880/2000\n",
      "train Loss: 1.9884\n",
      "val Loss: 42.1829\n",
      "\n",
      "Epoch 1890/2000\n",
      "train Loss: 2.1120\n",
      "val Loss: 41.3507\n",
      "\n",
      "Epoch 1900/2000\n",
      "train Loss: 2.2392\n",
      "val Loss: 42.1513\n",
      "\n",
      "Epoch 1910/2000\n",
      "train Loss: 2.0821\n",
      "val Loss: 40.0074\n",
      "\n",
      "Epoch 1920/2000\n",
      "train Loss: 1.5581\n",
      "val Loss: 40.5667\n",
      "\n",
      "Epoch 1930/2000\n",
      "train Loss: 1.9681\n",
      "val Loss: 40.4127\n",
      "\n",
      "Epoch 1940/2000\n",
      "train Loss: 2.7416\n",
      "val Loss: 40.5759\n",
      "\n",
      "Epoch 1950/2000\n",
      "train Loss: 2.3932\n",
      "val Loss: 40.5977\n",
      "\n",
      "Epoch 1960/2000\n",
      "train Loss: 1.8807\n",
      "val Loss: 40.0906\n",
      "\n",
      "Epoch 1970/2000\n",
      "train Loss: 1.3882\n",
      "val Loss: 41.2372\n",
      "\n",
      "Epoch 1980/2000\n",
      "train Loss: 1.8143\n",
      "val Loss: 42.0354\n",
      "\n",
      "Epoch 1990/2000\n",
      "train Loss: 2.1387\n",
      "val Loss: 39.9739\n",
      "\n",
      "Epoch 2000/2000\n",
      "train Loss: 2.6679\n",
      "val Loss: 41.3583\n",
      "\n",
      "Training complete in 0m 17s\n",
      "Best val Loss: 19.778418\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 13.15292 and R2: -43.18219\n",
      "test RMSE: 3.6267\n"
     ]
    }
   ],
   "source": [
    "# Case 3. CNN_1D (w/o data representation)\n",
    "config = config3\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78051f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/2000\n",
      "train Loss: 211.9843\n",
      "val Loss: 285.8119\n",
      "\n",
      "Epoch 10/2000\n",
      "train Loss: 197.4490\n",
      "val Loss: 235.0284\n",
      "\n",
      "Epoch 20/2000\n",
      "train Loss: 175.5602\n",
      "val Loss: 211.7100\n",
      "\n",
      "Epoch 30/2000\n",
      "train Loss: 147.8240\n",
      "val Loss: 175.5422\n",
      "\n",
      "Epoch 40/2000\n",
      "train Loss: 123.6403\n",
      "val Loss: 144.8802\n",
      "\n",
      "Epoch 50/2000\n",
      "train Loss: 104.1462\n",
      "val Loss: 125.1565\n",
      "\n",
      "Epoch 60/2000\n",
      "train Loss: 89.8806\n",
      "val Loss: 113.5019\n",
      "\n",
      "Epoch 70/2000\n",
      "train Loss: 78.8314\n",
      "val Loss: 108.0770\n",
      "\n",
      "Epoch 80/2000\n",
      "train Loss: 69.9318\n",
      "val Loss: 78.3070\n",
      "\n",
      "Epoch 90/2000\n",
      "train Loss: 63.2097\n",
      "val Loss: 73.2328\n",
      "\n",
      "Epoch 100/2000\n",
      "train Loss: 56.7629\n",
      "val Loss: 73.9584\n",
      "\n",
      "Epoch 110/2000\n",
      "train Loss: 51.1936\n",
      "val Loss: 58.8537\n",
      "\n",
      "Epoch 120/2000\n",
      "train Loss: 46.1409\n",
      "val Loss: 62.1643\n",
      "\n",
      "Epoch 130/2000\n",
      "train Loss: 41.5442\n",
      "val Loss: 63.9642\n",
      "\n",
      "Epoch 140/2000\n",
      "train Loss: 37.2565\n",
      "val Loss: 52.5278\n",
      "\n",
      "Epoch 150/2000\n",
      "train Loss: 33.7555\n",
      "val Loss: 31.5369\n",
      "\n",
      "Epoch 160/2000\n",
      "train Loss: 30.3177\n",
      "val Loss: 55.4604\n",
      "\n",
      "Epoch 170/2000\n",
      "train Loss: 27.0422\n",
      "val Loss: 51.1821\n",
      "\n",
      "Epoch 180/2000\n",
      "train Loss: 24.6198\n",
      "val Loss: 41.2399\n",
      "\n",
      "Epoch 190/2000\n",
      "train Loss: 22.1536\n",
      "val Loss: 37.5779\n",
      "\n",
      "Epoch 200/2000\n",
      "train Loss: 20.0004\n",
      "val Loss: 41.0187\n",
      "\n",
      "Epoch 210/2000\n",
      "train Loss: 18.0961\n",
      "val Loss: 42.1844\n",
      "\n",
      "Epoch 220/2000\n",
      "train Loss: 16.3683\n",
      "val Loss: 30.9203\n",
      "\n",
      "Epoch 230/2000\n",
      "train Loss: 14.9724\n",
      "val Loss: 25.6730\n",
      "\n",
      "Epoch 240/2000\n",
      "train Loss: 13.8792\n",
      "val Loss: 74.7943\n",
      "\n",
      "Epoch 250/2000\n",
      "train Loss: 12.4955\n",
      "val Loss: 20.3477\n",
      "\n",
      "Epoch 260/2000\n",
      "train Loss: 11.6205\n",
      "val Loss: 23.2201\n",
      "\n",
      "Epoch 270/2000\n",
      "train Loss: 10.5644\n",
      "val Loss: 34.6609\n",
      "\n",
      "Epoch 280/2000\n",
      "train Loss: 9.8220\n",
      "val Loss: 24.1957\n",
      "\n",
      "Epoch 290/2000\n",
      "train Loss: 9.2860\n",
      "val Loss: 33.0250\n",
      "\n",
      "Epoch 300/2000\n",
      "train Loss: 8.6871\n",
      "val Loss: 20.5502\n",
      "\n",
      "Epoch 310/2000\n",
      "train Loss: 8.9437\n",
      "val Loss: 24.7709\n",
      "\n",
      "Epoch 320/2000\n",
      "train Loss: 8.3119\n",
      "val Loss: 26.5933\n",
      "\n",
      "Epoch 330/2000\n",
      "train Loss: 7.4382\n",
      "val Loss: 32.1818\n",
      "\n",
      "Epoch 340/2000\n",
      "train Loss: 7.0492\n",
      "val Loss: 27.7315\n",
      "\n",
      "Epoch 350/2000\n",
      "train Loss: 6.7360\n",
      "val Loss: 29.7789\n",
      "\n",
      "Epoch 360/2000\n",
      "train Loss: 6.8351\n",
      "val Loss: 44.7332\n",
      "\n",
      "Epoch 370/2000\n",
      "train Loss: 6.1492\n",
      "val Loss: 27.6327\n",
      "\n",
      "Epoch 380/2000\n",
      "train Loss: 5.6423\n",
      "val Loss: 24.0326\n",
      "\n",
      "Epoch 390/2000\n",
      "train Loss: 5.2798\n",
      "val Loss: 222.3544\n",
      "\n",
      "Epoch 400/2000\n",
      "train Loss: 5.0461\n",
      "val Loss: 21.5900\n",
      "\n",
      "Epoch 410/2000\n",
      "train Loss: 4.8510\n",
      "val Loss: 30.8222\n",
      "\n",
      "Epoch 420/2000\n",
      "train Loss: 4.6185\n",
      "val Loss: 29.6594\n",
      "\n",
      "Epoch 430/2000\n",
      "train Loss: 4.4903\n",
      "val Loss: 32.0334\n",
      "\n",
      "Epoch 440/2000\n",
      "train Loss: 4.1517\n",
      "val Loss: 21.5108\n",
      "\n",
      "Epoch 450/2000\n",
      "train Loss: 4.8667\n",
      "val Loss: 18.0575\n",
      "\n",
      "Epoch 460/2000\n",
      "train Loss: 3.7581\n",
      "val Loss: 39.1198\n",
      "\n",
      "Epoch 470/2000\n",
      "train Loss: 4.4941\n",
      "val Loss: 21.4135\n",
      "\n",
      "Epoch 480/2000\n",
      "train Loss: 4.1702\n",
      "val Loss: 22.9333\n",
      "\n",
      "Epoch 490/2000\n",
      "train Loss: 3.4477\n",
      "val Loss: 34.7276\n",
      "\n",
      "Epoch 500/2000\n",
      "train Loss: 3.3794\n",
      "val Loss: 42.7913\n",
      "\n",
      "Epoch 510/2000\n",
      "train Loss: 3.5472\n",
      "val Loss: 60.2897\n",
      "\n",
      "Epoch 520/2000\n",
      "train Loss: 3.6347\n",
      "val Loss: 82.1287\n",
      "\n",
      "Epoch 530/2000\n",
      "train Loss: 3.0922\n",
      "val Loss: 72.5172\n",
      "\n",
      "Epoch 540/2000\n",
      "train Loss: 2.8475\n",
      "val Loss: 27.4393\n",
      "\n",
      "Epoch 550/2000\n",
      "train Loss: 2.7359\n",
      "val Loss: 21.0542\n",
      "\n",
      "Epoch 560/2000\n",
      "train Loss: 2.4209\n",
      "val Loss: 37.9811\n",
      "\n",
      "Epoch 570/2000\n",
      "train Loss: 2.2239\n",
      "val Loss: 23.4341\n",
      "\n",
      "Epoch 580/2000\n",
      "train Loss: 2.5494\n",
      "val Loss: 24.6456\n",
      "\n",
      "Epoch 590/2000\n",
      "train Loss: 2.1472\n",
      "val Loss: 26.7834\n",
      "\n",
      "Epoch 600/2000\n",
      "train Loss: 2.3277\n",
      "val Loss: 28.4858\n",
      "\n",
      "Epoch 610/2000\n",
      "train Loss: 2.4503\n",
      "val Loss: 323.4228\n",
      "\n",
      "Epoch 620/2000\n",
      "train Loss: 1.5998\n",
      "val Loss: 24.5785\n",
      "\n",
      "Epoch 630/2000\n",
      "train Loss: 2.4456\n",
      "val Loss: 63.7518\n",
      "\n",
      "Epoch 640/2000\n",
      "train Loss: 2.5746\n",
      "val Loss: 19.2010\n",
      "\n",
      "Epoch 650/2000\n",
      "train Loss: 1.5389\n",
      "val Loss: 36.0249\n",
      "\n",
      "Epoch 660/2000\n",
      "train Loss: 1.6746\n",
      "val Loss: 23.0984\n",
      "\n",
      "Epoch 670/2000\n",
      "train Loss: 1.8788\n",
      "val Loss: 72.2315\n",
      "\n",
      "Epoch 680/2000\n",
      "train Loss: 1.7781\n",
      "val Loss: 24.5592\n",
      "\n",
      "Epoch 690/2000\n",
      "train Loss: 1.2446\n",
      "val Loss: 34.7908\n",
      "\n",
      "Epoch 700/2000\n",
      "train Loss: 1.0177\n",
      "val Loss: 48.5393\n",
      "\n",
      "Epoch 710/2000\n",
      "train Loss: 1.0442\n",
      "val Loss: 31.1742\n",
      "\n",
      "Epoch 720/2000\n",
      "train Loss: 1.1099\n",
      "val Loss: 62.7512\n",
      "\n",
      "Epoch 730/2000\n",
      "train Loss: 0.7887\n",
      "val Loss: 42.2607\n",
      "\n",
      "Epoch 740/2000\n",
      "train Loss: 0.8289\n",
      "val Loss: 43.4459\n",
      "\n",
      "Epoch 750/2000\n",
      "train Loss: 1.5379\n",
      "val Loss: 25.9644\n",
      "\n",
      "Epoch 760/2000\n",
      "train Loss: 0.8435\n",
      "val Loss: 62.5601\n",
      "\n",
      "Epoch 770/2000\n",
      "train Loss: 0.5922\n",
      "val Loss: 19.8971\n",
      "\n",
      "Epoch 780/2000\n",
      "train Loss: 0.7000\n",
      "val Loss: 17.7259\n",
      "\n",
      "Epoch 790/2000\n",
      "train Loss: 0.8806\n",
      "val Loss: 212.3984\n",
      "\n",
      "Epoch 800/2000\n",
      "train Loss: 1.1164\n",
      "val Loss: 286.2635\n",
      "\n",
      "Epoch 810/2000\n",
      "train Loss: 1.0581\n",
      "val Loss: 49.2651\n",
      "\n",
      "Epoch 820/2000\n",
      "train Loss: 2.1059\n",
      "val Loss: 108.5213\n",
      "\n",
      "Epoch 830/2000\n",
      "train Loss: 0.7469\n",
      "val Loss: 32.4021\n",
      "\n",
      "Epoch 840/2000\n",
      "train Loss: 0.4809\n",
      "val Loss: 19.0249\n",
      "\n",
      "Epoch 850/2000\n",
      "train Loss: 1.7944\n",
      "val Loss: 60.0613\n",
      "\n",
      "Epoch 860/2000\n",
      "train Loss: 1.4545\n",
      "val Loss: 18.0154\n",
      "\n",
      "Epoch 870/2000\n",
      "train Loss: 0.5286\n",
      "val Loss: 30.0513\n",
      "\n",
      "Epoch 880/2000\n",
      "train Loss: 0.4340\n",
      "val Loss: 18.2735\n",
      "\n",
      "Epoch 890/2000\n",
      "train Loss: 0.3757\n",
      "val Loss: 21.4354\n",
      "\n",
      "Epoch 900/2000\n",
      "train Loss: 0.4098\n",
      "val Loss: 25.7776\n",
      "\n",
      "Epoch 910/2000\n",
      "train Loss: 1.0131\n",
      "val Loss: 18.7822\n",
      "\n",
      "Epoch 920/2000\n",
      "train Loss: 0.2539\n",
      "val Loss: 32.5870\n",
      "\n",
      "Epoch 930/2000\n",
      "train Loss: 2.9213\n",
      "val Loss: 19.1737\n",
      "\n",
      "Epoch 940/2000\n",
      "train Loss: 0.4131\n",
      "val Loss: 18.5057\n",
      "\n",
      "Epoch 950/2000\n",
      "train Loss: 0.3020\n",
      "val Loss: 28.8704\n",
      "\n",
      "Epoch 960/2000\n",
      "train Loss: 0.7784\n",
      "val Loss: 201.0647\n",
      "\n",
      "Epoch 970/2000\n",
      "train Loss: 0.6959\n",
      "val Loss: 18.7006\n",
      "\n",
      "Epoch 980/2000\n",
      "train Loss: 0.4309\n",
      "val Loss: 76.7566\n",
      "\n",
      "Epoch 990/2000\n",
      "train Loss: 0.5754\n",
      "val Loss: 19.5386\n",
      "\n",
      "Epoch 1000/2000\n",
      "train Loss: 0.9973\n",
      "val Loss: 20.0302\n",
      "\n",
      "Epoch 1010/2000\n",
      "train Loss: 0.2522\n",
      "val Loss: 94.8241\n",
      "\n",
      "Epoch 1020/2000\n",
      "train Loss: 1.4829\n",
      "val Loss: 17.8671\n",
      "\n",
      "Epoch 1030/2000\n",
      "train Loss: 0.5282\n",
      "val Loss: 22.9144\n",
      "\n",
      "Epoch 1040/2000\n",
      "train Loss: 0.9606\n",
      "val Loss: 22.3910\n",
      "\n",
      "Epoch 1050/2000\n",
      "train Loss: 0.4266\n",
      "val Loss: 25.8180\n",
      "\n",
      "Epoch 1060/2000\n",
      "train Loss: 0.6723\n",
      "val Loss: 19.2295\n",
      "\n",
      "Epoch 1070/2000\n",
      "train Loss: 1.0625\n",
      "val Loss: 38.4262\n",
      "\n",
      "Epoch 1080/2000\n",
      "train Loss: 0.5380\n",
      "val Loss: 25.4755\n",
      "\n",
      "Epoch 1090/2000\n",
      "train Loss: 0.6271\n",
      "val Loss: 65.1113\n",
      "\n",
      "Epoch 1100/2000\n",
      "train Loss: 1.1109\n",
      "val Loss: 17.6021\n",
      "\n",
      "Epoch 1110/2000\n",
      "train Loss: 0.2571\n",
      "val Loss: 23.2704\n",
      "\n",
      "Epoch 1120/2000\n",
      "train Loss: 0.5024\n",
      "val Loss: 63.5671\n",
      "\n",
      "Epoch 1130/2000\n",
      "train Loss: 0.5091\n",
      "val Loss: 78.1388\n",
      "\n",
      "Epoch 1140/2000\n",
      "train Loss: 0.1972\n",
      "val Loss: 25.5671\n",
      "\n",
      "Epoch 1150/2000\n",
      "train Loss: 0.6336\n",
      "val Loss: 77.5735\n",
      "\n",
      "Epoch 1160/2000\n",
      "train Loss: 0.2936\n",
      "val Loss: 36.1203\n",
      "\n",
      "Epoch 1170/2000\n",
      "train Loss: 0.2183\n",
      "val Loss: 26.2741\n",
      "\n",
      "Epoch 1180/2000\n",
      "train Loss: 0.1184\n",
      "val Loss: 69.9987\n",
      "\n",
      "Epoch 1190/2000\n",
      "train Loss: 0.1868\n",
      "val Loss: 50.4431\n",
      "\n",
      "Epoch 1200/2000\n",
      "train Loss: 0.3901\n",
      "val Loss: 19.9944\n",
      "\n",
      "Epoch 1210/2000\n",
      "train Loss: 0.3405\n",
      "val Loss: 49.7083\n",
      "\n",
      "Epoch 1220/2000\n",
      "train Loss: 0.2620\n",
      "val Loss: 27.2215\n",
      "\n",
      "Epoch 1230/2000\n",
      "train Loss: 0.2259\n",
      "val Loss: 94.2775\n",
      "\n",
      "Epoch 1240/2000\n",
      "train Loss: 0.1264\n",
      "val Loss: 23.2915\n",
      "\n",
      "Epoch 1250/2000\n",
      "train Loss: 0.3893\n",
      "val Loss: 31.1707\n",
      "\n",
      "Epoch 1260/2000\n",
      "train Loss: 0.2203\n",
      "val Loss: 26.2481\n",
      "\n",
      "Epoch 1270/2000\n",
      "train Loss: 0.2460\n",
      "val Loss: 21.5144\n",
      "\n",
      "Epoch 1280/2000\n",
      "train Loss: 0.0947\n",
      "val Loss: 36.0379\n",
      "\n",
      "Epoch 1290/2000\n",
      "train Loss: 0.1554\n",
      "val Loss: 91.5407\n",
      "\n",
      "Epoch 1300/2000\n",
      "train Loss: 0.4930\n",
      "val Loss: 21.1345\n",
      "\n",
      "Epoch 1310/2000\n",
      "train Loss: 0.3223\n",
      "val Loss: 69.1013\n",
      "\n",
      "Epoch 1320/2000\n",
      "train Loss: 0.6737\n",
      "val Loss: 26.5575\n",
      "\n",
      "Epoch 1330/2000\n",
      "train Loss: 0.9215\n",
      "val Loss: 19.0535\n",
      "\n",
      "Epoch 1340/2000\n",
      "train Loss: 0.6290\n",
      "val Loss: 107.3575\n",
      "\n",
      "Epoch 1350/2000\n",
      "train Loss: 0.1197\n",
      "val Loss: 83.5104\n",
      "\n",
      "Epoch 1360/2000\n",
      "train Loss: 0.2890\n",
      "val Loss: 59.0717\n",
      "\n",
      "Epoch 1370/2000\n",
      "train Loss: 0.4416\n",
      "val Loss: 18.4716\n",
      "\n",
      "Epoch 1380/2000\n",
      "train Loss: 0.3155\n",
      "val Loss: 23.8462\n",
      "\n",
      "Epoch 1390/2000\n",
      "train Loss: 0.4976\n",
      "val Loss: 29.1498\n",
      "\n",
      "Epoch 1400/2000\n",
      "train Loss: 0.5570\n",
      "val Loss: 98.5802\n",
      "\n",
      "Epoch 1410/2000\n",
      "train Loss: 0.2428\n",
      "val Loss: 32.5742\n",
      "\n",
      "Epoch 1420/2000\n",
      "train Loss: 0.2816\n",
      "val Loss: 29.0182\n",
      "\n",
      "Epoch 1430/2000\n",
      "train Loss: 1.0042\n",
      "val Loss: 22.4264\n",
      "\n",
      "Epoch 1440/2000\n",
      "train Loss: 0.1931\n",
      "val Loss: 23.8931\n",
      "\n",
      "Epoch 1450/2000\n",
      "train Loss: 0.1108\n",
      "val Loss: 39.7279\n",
      "\n",
      "Epoch 1460/2000\n",
      "train Loss: 0.4951\n",
      "val Loss: 19.3387\n",
      "\n",
      "Epoch 1470/2000\n",
      "train Loss: 0.2648\n",
      "val Loss: 35.7657\n",
      "\n",
      "Epoch 1480/2000\n",
      "train Loss: 0.1151\n",
      "val Loss: 38.1357\n",
      "\n",
      "Epoch 1490/2000\n",
      "train Loss: 0.1313\n",
      "val Loss: 89.0138\n",
      "\n",
      "Epoch 1500/2000\n",
      "train Loss: 0.7542\n",
      "val Loss: 18.0490\n",
      "\n",
      "Epoch 1510/2000\n",
      "train Loss: 0.3000\n",
      "val Loss: 48.5552\n",
      "\n",
      "Epoch 1520/2000\n",
      "train Loss: 0.4677\n",
      "val Loss: 22.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1530/2000\n",
      "train Loss: 0.1678\n",
      "val Loss: 26.0538\n",
      "\n",
      "Epoch 1540/2000\n",
      "train Loss: 0.4609\n",
      "val Loss: 45.9220\n",
      "\n",
      "Epoch 1550/2000\n",
      "train Loss: 0.1874\n",
      "val Loss: 19.9847\n",
      "\n",
      "Epoch 1560/2000\n",
      "train Loss: 0.1430\n",
      "val Loss: 25.6623\n",
      "\n",
      "Epoch 1570/2000\n",
      "train Loss: 0.2389\n",
      "val Loss: 47.6350\n",
      "\n",
      "Epoch 1580/2000\n",
      "train Loss: 0.3046\n",
      "val Loss: 18.8383\n",
      "\n",
      "Epoch 1590/2000\n",
      "train Loss: 0.7313\n",
      "val Loss: 20.8972\n",
      "\n",
      "Epoch 1600/2000\n",
      "train Loss: 0.5916\n",
      "val Loss: 23.6793\n",
      "\n",
      "Epoch 1610/2000\n",
      "train Loss: 0.5273\n",
      "val Loss: 24.1695\n",
      "\n",
      "Epoch 1620/2000\n",
      "train Loss: 0.1727\n",
      "val Loss: 77.5666\n",
      "\n",
      "Epoch 1630/2000\n",
      "train Loss: 0.2674\n",
      "val Loss: 18.1358\n",
      "\n",
      "Epoch 1640/2000\n",
      "train Loss: 0.8433\n",
      "val Loss: 20.1798\n",
      "\n",
      "Epoch 1650/2000\n",
      "train Loss: 0.3381\n",
      "val Loss: 23.4147\n",
      "\n",
      "Epoch 1660/2000\n",
      "train Loss: 0.3510\n",
      "val Loss: 25.5673\n",
      "\n",
      "Epoch 1670/2000\n",
      "train Loss: 0.0990\n",
      "val Loss: 49.1895\n",
      "\n",
      "Epoch 1680/2000\n",
      "train Loss: 0.1832\n",
      "val Loss: 19.1476\n",
      "\n",
      "Epoch 1690/2000\n",
      "train Loss: 0.2549\n",
      "val Loss: 42.7964\n",
      "\n",
      "Epoch 1700/2000\n",
      "train Loss: 0.1490\n",
      "val Loss: 28.7389\n",
      "\n",
      "Epoch 1710/2000\n",
      "train Loss: 0.4720\n",
      "val Loss: 18.6387\n",
      "\n",
      "Epoch 1720/2000\n",
      "train Loss: 0.1499\n",
      "val Loss: 26.2786\n",
      "\n",
      "Epoch 1730/2000\n",
      "train Loss: 0.1791\n",
      "val Loss: 155.5823\n",
      "\n",
      "Epoch 1740/2000\n",
      "train Loss: 0.1778\n",
      "val Loss: 21.8608\n",
      "\n",
      "Epoch 1750/2000\n",
      "train Loss: 0.1965\n",
      "val Loss: 19.4860\n",
      "\n",
      "Epoch 1760/2000\n",
      "train Loss: 0.2663\n",
      "val Loss: 17.9263\n",
      "\n",
      "Epoch 1770/2000\n",
      "train Loss: 0.3138\n",
      "val Loss: 26.7343\n",
      "\n",
      "Epoch 1780/2000\n",
      "train Loss: 0.1200\n",
      "val Loss: 24.0847\n",
      "\n",
      "Epoch 1790/2000\n",
      "train Loss: 0.6962\n",
      "val Loss: 20.5554\n",
      "\n",
      "Epoch 1800/2000\n",
      "train Loss: 0.1500\n",
      "val Loss: 24.8771\n",
      "\n",
      "Epoch 1810/2000\n",
      "train Loss: 0.0566\n",
      "val Loss: 49.0893\n",
      "\n",
      "Epoch 1820/2000\n",
      "train Loss: 0.8216\n",
      "val Loss: 40.1145\n",
      "\n",
      "Epoch 1830/2000\n",
      "train Loss: 0.2563\n",
      "val Loss: 20.6562\n",
      "\n",
      "Epoch 1840/2000\n",
      "train Loss: 0.1179\n",
      "val Loss: 56.8849\n",
      "\n",
      "Epoch 1850/2000\n",
      "train Loss: 0.6501\n",
      "val Loss: 22.0301\n",
      "\n",
      "Epoch 1860/2000\n",
      "train Loss: 0.3998\n",
      "val Loss: 19.7364\n",
      "\n",
      "Epoch 1870/2000\n",
      "train Loss: 0.1072\n",
      "val Loss: 29.7421\n",
      "\n",
      "Epoch 1880/2000\n",
      "train Loss: 0.0782\n",
      "val Loss: 21.4087\n",
      "\n",
      "Epoch 1890/2000\n",
      "train Loss: 0.0480\n",
      "val Loss: 22.0304\n",
      "\n",
      "Epoch 1900/2000\n",
      "train Loss: 0.1414\n",
      "val Loss: 18.8572\n",
      "\n",
      "Epoch 1910/2000\n",
      "train Loss: 0.1403\n",
      "val Loss: 21.8132\n",
      "\n",
      "Epoch 1920/2000\n",
      "train Loss: 0.9060\n",
      "val Loss: 21.7742\n",
      "\n",
      "Epoch 1930/2000\n",
      "train Loss: 0.1849\n",
      "val Loss: 21.3620\n",
      "\n",
      "Epoch 1940/2000\n",
      "train Loss: 0.1852\n",
      "val Loss: 21.2865\n",
      "\n",
      "Epoch 1950/2000\n",
      "train Loss: 0.1801\n",
      "val Loss: 52.0799\n",
      "\n",
      "Epoch 1960/2000\n",
      "train Loss: 0.2052\n",
      "val Loss: 17.5126\n",
      "\n",
      "Epoch 1970/2000\n",
      "train Loss: 1.8861\n",
      "val Loss: 17.7042\n",
      "\n",
      "Epoch 1980/2000\n",
      "train Loss: 0.3472\n",
      "val Loss: 46.6323\n",
      "\n",
      "Epoch 1990/2000\n",
      "train Loss: 0.0959\n",
      "val Loss: 16.5569\n",
      "\n",
      "Epoch 2000/2000\n",
      "train Loss: 0.1199\n",
      "val Loss: 48.4214\n",
      "\n",
      "Training complete in 0m 58s\n",
      "Best val Loss: 12.301675\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 11.69311 and R2: -0.28344\n",
      "test RMSE: 3.4195\n"
     ]
    }
   ],
   "source": [
    "# Case 4. LSTM_FCNs (w/o data representation)\n",
    "config = config4\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261459e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7e6565a69c64523dea2d3b31d6ed9f8445dc9714e18e3f5d2b2bc6eff30a54c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
