{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b50a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import main_regression as mr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ca4b9",
   "metadata": {},
   "source": [
    "# Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8e2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9815b94",
   "metadata": {},
   "source": [
    "# Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16a24b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config1 = {\n",
    "        'model': 'LSTM', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 27,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 10, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 2. GRU model (w/o data representation)\n",
    "config2 = {\n",
    "        'model': 'GRU', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'with_representation' : False, # representation 유무, bool (defeault: False)\n",
    "        'parameter': {\n",
    "            'input_size': 27,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 10, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 3. CNN_1D model (w/o data representation)\n",
    "config3 = {\n",
    "        'model': 'CNN_1D', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/cnn_1d.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 27,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 10, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'seq_len': 10,  # 데이터의 시간 길이, int\n",
    "            'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "            'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "            'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "            'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 4. LSTM_FCNs model (w/o data representation)\n",
    "config4 = {\n",
    "        'model': 'LSTM_FCNs', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm_fcn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 27,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 10, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'num_layers': 1,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "            'lstm_drop_out': 0.4, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "            'fc_drop_out': 0.1, # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 150, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 5. DARNN model (w/o data representation)\n",
    "config5 = {\n",
    "        'model': 'DARNN', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/darnn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 27,  # 데이터의 변수 개수, int\n",
    "            'encoder_hidden_size': 64, # Encoder hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'decoder_hidden_size': 64, # Decoder hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'timestep': 16, # timestep의 크기, int(default: 16, 범위: 1이상),\n",
    "            'shift_size' : 1, # Slicing 시 shift 크기\n",
    "            'encoder_stateful': False, # Encoder의 Stateful 사용여부, bool(default: False)\n",
    "            'decoder_stateful': False, # Decoder의 Stateful 사용여부, bool(default: False)\n",
    "            'num_epochs': 300,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist': True\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 6. fully-connected layers (w/ data representation)\n",
    "config6 = {\n",
    "        'model': 'FC', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/fc.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 64,  # 데이터의 변수 개수(representation 차원), int\n",
    "            'timestep' : 1, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bias': True, # bias 사용 여부, bool(default: True)\n",
    "            'num_epochs': 500, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 32,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cca7e5",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007ceeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13866, 27)\n",
      "(13866,)\n",
      "(5869, 27)\n",
      "(5869,)\n"
     ]
    }
   ],
   "source": [
    "# raw time seires data for regression\n",
    "train = pd.read_csv('./data/train_data.csv')\n",
    "test = pd.read_csv('./data/test_data.csv')\n",
    "\n",
    "train = train.drop('date', axis=1)\n",
    "test = test.drop('date', axis=1)\n",
    "\n",
    "train_x = train.drop('Appliances', axis = 1)\n",
    "train_y = train['Appliances']\n",
    "\n",
    "test_x = test.drop('Appliances', axis = 1)\n",
    "test_y = test['Appliances']\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x representation_dims) = (13866, 27)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (13866, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x representation_dims) = (5869, 27)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (5869, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bceeae",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc494175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 21109.8579\n",
      "val Loss: 19662.6211\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 17096.3544\n",
      "val Loss: 15943.9041\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 14810.5891\n",
      "val Loss: 13671.3700\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 13274.0272\n",
      "val Loss: 12137.8744\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 12338.0450\n",
      "val Loss: 11203.0173\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 11881.3267\n",
      "val Loss: 10744.7886\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 11735.9458\n",
      "val Loss: 10595.3293\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 11703.3277\n",
      "val Loss: 10550.8439\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 10785.1211\n",
      "val Loss: 10230.9813\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 10483.6422\n",
      "val Loss: 10158.3068\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 10179.7348\n",
      "val Loss: 9933.4768\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 9963.6822\n",
      "val Loss: 9879.3951\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 9789.9676\n",
      "val Loss: 9849.1631\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 9575.7222\n",
      "val Loss: 9806.1532\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 9471.5166\n",
      "val Loss: 9837.2605\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 9308.4335\n",
      "val Loss: 9736.0855\n",
      "\n",
      "Training complete in 2m 32s\n",
      "Best val Loss: 9736.085530\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 7772.01904 and R2: -6.62988\n"
     ]
    }
   ],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config = config1\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f853abe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 20953.5240\n",
      "val Loss: 19423.9935\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 16861.7568\n",
      "val Loss: 15697.1152\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 14446.9889\n",
      "val Loss: 13298.3464\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 12921.7596\n",
      "val Loss: 11780.6570\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 12096.8473\n",
      "val Loss: 10959.0335\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 11780.5838\n",
      "val Loss: 10641.2649\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 11215.1201\n",
      "val Loss: 10222.6823\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 10645.0166\n",
      "val Loss: 9977.1915\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 10299.3431\n",
      "val Loss: 10052.9659\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 10074.4275\n",
      "val Loss: 10085.9115\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 9932.9615\n",
      "val Loss: 10448.6904\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 9729.7561\n",
      "val Loss: 10904.9271\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 9544.8649\n",
      "val Loss: 11505.1951\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 9394.8892\n",
      "val Loss: 11304.2813\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 9298.4608\n",
      "val Loss: 11611.3036\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 9139.0102\n",
      "val Loss: 11491.8376\n",
      "\n",
      "Training complete in 2m 16s\n",
      "Best val Loss: 9963.157924\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 7902.56104 and R2: -10.01323\n"
     ]
    }
   ],
   "source": [
    "# Case 2. GRU (w/o data representation)\n",
    "config = config2\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53858dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 13304.8273\n",
      "val Loss: 10569.9277\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 11400.0472\n",
      "val Loss: 10201.5337\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 11029.2726\n",
      "val Loss: 10176.1027\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 10901.8734\n",
      "val Loss: 10023.1405\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 10809.5334\n",
      "val Loss: 10041.1269\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 10758.7885\n",
      "val Loss: 10049.8166\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 10695.9239\n",
      "val Loss: 10119.1882\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 10617.2591\n",
      "val Loss: 10062.4643\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 10549.8681\n",
      "val Loss: 10079.6244\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 10485.2216\n",
      "val Loss: 10054.7976\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 10398.3151\n",
      "val Loss: 10069.3872\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 10313.7175\n",
      "val Loss: 10104.2730\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 10216.2509\n",
      "val Loss: 10134.3725\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 10140.6285\n",
      "val Loss: 10531.1352\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 10089.4050\n",
      "val Loss: 10264.4130\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 10049.5388\n",
      "val Loss: 10125.4819\n",
      "\n",
      "Training complete in 1m 2s\n",
      "Best val Loss: 9982.781333\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 7883.87256 and R2: -17.78813\n"
     ]
    }
   ],
   "source": [
    "# Case 3. CNN_1D (w/o data representation)\n",
    "config = config3\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91e3699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 21383.8549\n",
      "val Loss: 20347.7109\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 20296.6969\n",
      "val Loss: 19142.7692\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 18531.0974\n",
      "val Loss: 15023.4722\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 16580.6424\n",
      "val Loss: 18305.6355\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 14534.4019\n",
      "val Loss: 16994.4447\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 12370.3819\n",
      "val Loss: 13327.7498\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 10212.3734\n",
      "val Loss: 15127.3406\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 8367.0924\n",
      "val Loss: 12753.6360\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 6637.2425\n",
      "val Loss: 12636.8908\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 5315.9720\n",
      "val Loss: 11498.6432\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 4509.7866\n",
      "val Loss: 10986.0264\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 3558.9471\n",
      "val Loss: 10208.3579\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 3320.8893\n",
      "val Loss: 15153.6865\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 2861.5139\n",
      "val Loss: 16975.6709\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 3043.9662\n",
      "val Loss: 9988.9597\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 2602.4835\n",
      "val Loss: 9288.6772\n",
      "\n",
      "Training complete in 2m 46s\n",
      "Best val Loss: 9288.677196\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 8588.28906 and R2: -8.07453\n"
     ]
    }
   ],
   "source": [
    "# Case 4. LSTM_FCNs (w/o data representation)\n",
    "config = config4\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c59a9bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/300\n",
      "train Loss: 20671.0854\n",
      "val Loss: 18226.4856\n",
      "\n",
      "Epoch 10/300\n",
      "train Loss: 6710.9335\n",
      "val Loss: 5849.9898\n",
      "\n",
      "Epoch 20/300\n",
      "train Loss: 4985.6716\n",
      "val Loss: 4544.2122\n",
      "\n",
      "Epoch 30/300\n",
      "train Loss: 4592.1922\n",
      "val Loss: 4174.7913\n",
      "\n",
      "Epoch 40/300\n",
      "train Loss: 4465.6602\n",
      "val Loss: 4043.7333\n",
      "\n",
      "Epoch 50/300\n",
      "train Loss: 4368.6935\n",
      "val Loss: 3991.4472\n",
      "\n",
      "Epoch 60/300\n",
      "train Loss: 4270.9391\n",
      "val Loss: 4099.5761\n",
      "\n",
      "Epoch 70/300\n",
      "train Loss: 4159.3402\n",
      "val Loss: 4090.2726\n",
      "\n",
      "Epoch 80/300\n",
      "train Loss: 4048.9085\n",
      "val Loss: 4100.0456\n",
      "\n",
      "Epoch 90/300\n",
      "train Loss: 3949.9232\n",
      "val Loss: 4157.1234\n",
      "\n",
      "Epoch 100/300\n",
      "train Loss: 3851.6564\n",
      "val Loss: 4127.8567\n",
      "\n",
      "Epoch 110/300\n",
      "train Loss: 3741.9911\n",
      "val Loss: 4394.1331\n",
      "\n",
      "Epoch 120/300\n",
      "train Loss: 3645.1171\n",
      "val Loss: 4142.5263\n",
      "\n",
      "Epoch 130/300\n",
      "train Loss: 3531.7127\n",
      "val Loss: 4262.2006\n",
      "\n",
      "Epoch 140/300\n",
      "train Loss: 3405.3010\n",
      "val Loss: 4260.6374\n",
      "\n",
      "Epoch 150/300\n",
      "train Loss: 3256.4454\n",
      "val Loss: 4356.1023\n",
      "\n",
      "Epoch 160/300\n",
      "train Loss: 3111.7294\n",
      "val Loss: 4444.9313\n",
      "\n",
      "Epoch 170/300\n",
      "train Loss: 2964.8086\n",
      "val Loss: 4428.3836\n",
      "\n",
      "Epoch 180/300\n",
      "train Loss: 2853.1804\n",
      "val Loss: 4436.3273\n",
      "\n",
      "Epoch 190/300\n",
      "train Loss: 2701.8975\n",
      "val Loss: 4654.1102\n",
      "\n",
      "Epoch 200/300\n",
      "train Loss: 2569.7436\n",
      "val Loss: 4703.3743\n",
      "\n",
      "Epoch 210/300\n",
      "train Loss: 2416.3765\n",
      "val Loss: 4829.4890\n",
      "\n",
      "Epoch 220/300\n",
      "train Loss: 2348.9411\n",
      "val Loss: 4806.0876\n",
      "\n",
      "Epoch 230/300\n",
      "train Loss: 2237.1948\n",
      "val Loss: 4736.3028\n",
      "\n",
      "Epoch 240/300\n",
      "train Loss: 2067.3675\n",
      "val Loss: 4923.9851\n",
      "\n",
      "Epoch 250/300\n",
      "train Loss: 1993.3266\n",
      "val Loss: 4987.6741\n",
      "\n",
      "Epoch 260/300\n",
      "train Loss: 1898.1454\n",
      "val Loss: 5241.3930\n",
      "\n",
      "Epoch 270/300\n",
      "train Loss: 1862.4301\n",
      "val Loss: 5052.0220\n",
      "\n",
      "Epoch 280/300\n",
      "train Loss: 1688.5062\n",
      "val Loss: 5223.5107\n",
      "\n",
      "Epoch 290/300\n",
      "train Loss: 1621.7694\n",
      "val Loss: 5211.5396\n",
      "\n",
      "Epoch 300/300\n",
      "train Loss: 1559.3933\n",
      "val Loss: 5328.9920\n",
      "\n",
      "Training complete in 35m 16s\n",
      "Best val Loss: 3990.519294\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 3719.84521 and R2: 0.18703\n"
     ]
    }
   ],
   "source": [
    "# Case 5. DARNN model (w/o data representation)\n",
    "config = config5\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a8828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_repr = pd.read_csv('./data/train_repr.csv')\n",
    "test_repr = pd.read_csv('./data/test_repr.csv')\n",
    "\n",
    "train_x_repr = np.array(train_repr)\n",
    "test_x_repr = np.array(test_repr)\n",
    "\n",
    "train_y_repr = np.array(train_y[9:])\n",
    "test_y_repr = np.array(test_y[9:])\n",
    "\n",
    "train_data_repr = {'x': train_x_repr, 'y': train_y_repr}\n",
    "test_data_repr = {'x': test_x_repr, 'y': test_y_repr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e684aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/500\n",
      "train Loss: 21387.8323\n",
      "val Loss: 20262.9357\n",
      "\n",
      "Epoch 10/500\n",
      "train Loss: 13707.8572\n",
      "val Loss: 12050.3783\n",
      "\n",
      "Epoch 20/500\n",
      "train Loss: 11516.4185\n",
      "val Loss: 10255.9073\n",
      "\n",
      "Epoch 30/500\n",
      "train Loss: 11084.2828\n",
      "val Loss: 10029.6115\n",
      "\n",
      "Epoch 40/500\n",
      "train Loss: 10829.8159\n",
      "val Loss: 9878.0400\n",
      "\n",
      "Epoch 50/500\n",
      "train Loss: 10673.4569\n",
      "val Loss: 9769.4153\n",
      "\n",
      "Epoch 60/500\n",
      "train Loss: 10550.0673\n",
      "val Loss: 9697.7903\n",
      "\n",
      "Epoch 70/500\n",
      "train Loss: 10464.1036\n",
      "val Loss: 9650.9348\n",
      "\n",
      "Epoch 80/500\n",
      "train Loss: 10406.4975\n",
      "val Loss: 9627.9242\n",
      "\n",
      "Epoch 90/500\n",
      "train Loss: 10291.8745\n",
      "val Loss: 9610.4035\n",
      "\n",
      "Epoch 100/500\n",
      "train Loss: 10278.5341\n",
      "val Loss: 9608.5700\n",
      "\n",
      "Epoch 110/500\n",
      "train Loss: 10275.7946\n",
      "val Loss: 9613.0499\n",
      "\n",
      "Epoch 120/500\n",
      "train Loss: 10153.7404\n",
      "val Loss: 9630.1900\n",
      "\n",
      "Epoch 130/500\n",
      "train Loss: 10194.4854\n",
      "val Loss: 9640.3731\n",
      "\n",
      "Epoch 140/500\n",
      "train Loss: 10120.0114\n",
      "val Loss: 9651.5635\n",
      "\n",
      "Epoch 150/500\n",
      "train Loss: 10088.4127\n",
      "val Loss: 9666.7668\n",
      "\n",
      "Epoch 160/500\n",
      "train Loss: 10020.7429\n",
      "val Loss: 9677.9234\n",
      "\n",
      "Epoch 170/500\n",
      "train Loss: 10026.7412\n",
      "val Loss: 9701.9083\n",
      "\n",
      "Epoch 180/500\n",
      "train Loss: 10026.2990\n",
      "val Loss: 9714.4349\n",
      "\n",
      "Epoch 190/500\n",
      "train Loss: 9971.3570\n",
      "val Loss: 9738.0223\n",
      "\n",
      "Epoch 200/500\n",
      "train Loss: 9989.5661\n",
      "val Loss: 9752.8125\n",
      "\n",
      "Epoch 210/500\n",
      "train Loss: 9917.4578\n",
      "val Loss: 9765.0641\n",
      "\n",
      "Epoch 220/500\n",
      "train Loss: 9924.3981\n",
      "val Loss: 9785.9652\n",
      "\n",
      "Epoch 230/500\n",
      "train Loss: 9859.0496\n",
      "val Loss: 9810.1490\n",
      "\n",
      "Epoch 240/500\n",
      "train Loss: 9865.8367\n",
      "val Loss: 9828.8762\n",
      "\n",
      "Epoch 250/500\n",
      "train Loss: 9796.7945\n",
      "val Loss: 9847.9537\n",
      "\n",
      "Epoch 260/500\n",
      "train Loss: 9799.3650\n",
      "val Loss: 9865.1958\n",
      "\n",
      "Epoch 270/500\n",
      "train Loss: 9766.7963\n",
      "val Loss: 9883.1335\n",
      "\n",
      "Epoch 280/500\n",
      "train Loss: 9785.1736\n",
      "val Loss: 9902.1467\n",
      "\n",
      "Epoch 290/500\n",
      "train Loss: 9731.1649\n",
      "val Loss: 9924.6095\n",
      "\n",
      "Epoch 300/500\n",
      "train Loss: 9684.2117\n",
      "val Loss: 9933.4023\n",
      "\n",
      "Epoch 310/500\n",
      "train Loss: 9670.1326\n",
      "val Loss: 9950.1096\n",
      "\n",
      "Epoch 320/500\n",
      "train Loss: 9710.0132\n",
      "val Loss: 9968.3992\n",
      "\n",
      "Epoch 330/500\n",
      "train Loss: 9645.2635\n",
      "val Loss: 9978.8957\n",
      "\n",
      "Epoch 340/500\n",
      "train Loss: 9683.7980\n",
      "val Loss: 9994.9389\n",
      "\n",
      "Epoch 350/500\n",
      "train Loss: 9610.2120\n",
      "val Loss: 9991.8510\n",
      "\n",
      "Epoch 360/500\n",
      "train Loss: 9594.9624\n",
      "val Loss: 10006.7360\n",
      "\n",
      "Epoch 370/500\n",
      "train Loss: 9561.4885\n",
      "val Loss: 10027.5216\n",
      "\n",
      "Epoch 380/500\n",
      "train Loss: 9613.2929\n",
      "val Loss: 10039.6625\n",
      "\n",
      "Epoch 390/500\n",
      "train Loss: 9584.8013\n",
      "val Loss: 10043.2680\n",
      "\n",
      "Epoch 400/500\n",
      "train Loss: 9543.0043\n",
      "val Loss: 10056.9113\n",
      "\n",
      "Epoch 410/500\n",
      "train Loss: 9553.2975\n",
      "val Loss: 10067.6383\n",
      "\n",
      "Epoch 420/500\n",
      "train Loss: 9514.7268\n",
      "val Loss: 10074.1686\n",
      "\n",
      "Epoch 430/500\n",
      "train Loss: 9506.5760\n",
      "val Loss: 10083.2236\n",
      "\n",
      "Epoch 440/500\n",
      "train Loss: 9548.9932\n",
      "val Loss: 10092.0527\n",
      "\n",
      "Epoch 450/500\n",
      "train Loss: 9506.6624\n",
      "val Loss: 10094.8827\n",
      "\n",
      "Epoch 460/500\n",
      "train Loss: 9488.8609\n",
      "val Loss: 10104.4053\n",
      "\n",
      "Epoch 470/500\n",
      "train Loss: 9529.1757\n",
      "val Loss: 10106.5706\n",
      "\n",
      "Epoch 480/500\n",
      "train Loss: 9521.2441\n",
      "val Loss: 10112.3370\n",
      "\n",
      "Epoch 490/500\n",
      "train Loss: 9511.9961\n",
      "val Loss: 10117.8033\n",
      "\n",
      "Epoch 500/500\n",
      "train Loss: 9462.3749\n",
      "val Loss: 10124.6552\n",
      "\n",
      "Training complete in 4m 17s\n",
      "Best val Loss: 9606.579007\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 7823.7002 and R2: -5.68292\n"
     ]
    }
   ],
   "source": [
    "# Case 6. fully-connected layers (w/ data representation)\n",
    "\n",
    "# raw time seires data for regression\n",
    "config = config6\n",
    "data_reg = mr.Regression(config, train_data_repr, test_data_repr, use_representation = True)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd23b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7e6565a69c64523dea2d3b31d6ed9f8445dc9714e18e3f5d2b2bc6eff30a54c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
