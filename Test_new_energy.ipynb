{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9ee0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import main_regression as mr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f1420",
   "metadata": {},
   "source": [
    "# Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc2671e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a339ffef",
   "metadata": {},
   "source": [
    "# Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b2449b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config1 = {\n",
    "        'model': 'LSTM', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 144,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 1, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'num_classes': 1,  # 분류할 class 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 2. GRU model (w/o data representation)\n",
    "config2 = {\n",
    "        'model': 'GRU', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'with_representation' : False, # representation 유무, bool (defeault: False)\n",
    "        'parameter': {\n",
    "            'input_size': 144,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 1, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'num_classes': 1,  # 분류할 class 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 3. CNN_1D model (w/o data representation)\n",
    "config3 = {\n",
    "        'model': 'CNN_1D', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/cnn_1d.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 144,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 1, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'num_classes': 1,  # 분류할 class 개수, int\n",
    "            'seq_len': 10,  # 데이터의 시간 길이, int\n",
    "            'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "            'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "            'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "            'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 4. DA-RNN model (w/o data representation)\n",
    "config4 = {\n",
    "        'model': 'LSTM_FCNs', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm_fcn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 144,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 1, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'num_classes': 1,  # 분류할 class 개수, int\n",
    "            'num_layers': 1,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "            'lstm_drop_out': 0.4, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "            'fc_drop_out': 0.1, # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 150, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config5 = {\n",
    "        'model': 'FC', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/fc.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 144,  # 데이터의 변수 개수(representation 차원), int\n",
    "            'timestep' : 1, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bias': True, # bias 사용 여부, bool(default: True)\n",
    "            'num_epochs': 150, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 32,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 6. DARNN model (w/o data representation)\n",
    "config6 = {\n",
    "        'model': 'DARNN', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/darnn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 144,  # 데이터의 변수 개수, int\n",
    "            'encoder_hidden_size': 64, # Encoder hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'decoder_hidden_size': 64, # Decoder hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'timestep': 1, # timestep의 크기, int(default: 16, 범위: 1이상),\n",
    "            'shift_size' : 1, # Slicing 시 shift 크기\n",
    "            'encoder_stateful': False, # Encoder의 Stateful 사용여부, bool(default: False)\n",
    "            'decoder_stateful': False, # Decoder의 Stateful 사용여부, bool(default: False)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist': True\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dda35a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a0deeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_x =pd.read_csv('./data/train_new_energy.csv').values\n",
    "test_x = pd.read_csv('./data/test_new_energy.csv').values\n",
    "\n",
    "train_y = pd.read_csv('./data/train_new_energy_y.csv').values\n",
    "test_y = pd.read_csv('./data/test_new_energy_y.csv').values\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442273ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # raw time series data\n",
    "# train_x = pickle.load(open('./data/x_train_new_energy.pkl', 'rb'))\n",
    "# train_y = pickle.load(open('./data/y_train_new_energy.pkl', 'rb'))\n",
    "# test_x = pickle.load(open('./data/x_test_new_energy.pkl', 'rb'))\n",
    "# test_y = pickle.load(open('./data/y_test_new_energy.pkl', 'rb'))\n",
    "\n",
    "# train_data = {'x': train_x, 'y': train_y}\n",
    "# test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "# print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (95, 24, 144)\n",
    "# print(train_y.shape) #shape : (num_of_instance) = (95,)\n",
    "# print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (42, 24, 144)\n",
    "# print(test_y.shape)  #shape : (num_of_instance) = (42,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c8980",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f513ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Case 1. LSTM model (w/o data representation)\n",
    "# config = config1\n",
    "# data_reg = mr.Regression(config, train_data, test_data)\n",
    "# model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "# if config[\"training\"]:\n",
    "#     best_model = data_reg.train_model(model)  # 모델 학습\n",
    "#     data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "# y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "# print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "# print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4929f8ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Case 2. GRU (w/o data representation)\n",
    "# config = config2\n",
    "# data_reg = mr.Regression(config, train_data, test_data)\n",
    "# model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "# if config[\"training\"]:\n",
    "#     best_model = data_reg.train_model(model)  # 모델 학습\n",
    "#     data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "# y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "# print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "# print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Case 3. CNN_1D (w/o data representation)\n",
    "# config = config3\n",
    "# data_reg = mr.Regression(config, train_data, test_data)\n",
    "# model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "# if config[\"training\"]:\n",
    "#     best_model = data_reg.train_model(model)  # 모델 학습\n",
    "#     data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "# y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "# print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "# print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78051f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Case 4. LSTM_FCNs (w/o data representation)\n",
    "# config = config4\n",
    "# data_reg = mr.Regression(config, train_data, test_data)\n",
    "# model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "# if config[\"training\"]:\n",
    "#     best_model = data_reg.train_model(model)  # 모델 학습\n",
    "#     data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "# y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "# print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "# print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "261459e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 222.6750\n",
      "val Loss: 187.6039\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 199.0384\n",
      "val Loss: 168.5877\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 176.0440\n",
      "val Loss: 146.8719\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 150.1901\n",
      "val Loss: 125.3160\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 127.9374\n",
      "val Loss: 104.0531\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 106.9008\n",
      "val Loss: 84.2886\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 84.5725\n",
      "val Loss: 67.1401\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 68.0335\n",
      "val Loss: 52.7292\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 53.9798\n",
      "val Loss: 41.3425\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 45.0228\n",
      "val Loss: 32.5973\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 38.1522\n",
      "val Loss: 26.4813\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 33.5970\n",
      "val Loss: 22.1890\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 30.9208\n",
      "val Loss: 19.3480\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 26.9598\n",
      "val Loss: 17.7103\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 26.2711\n",
      "val Loss: 16.7760\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 24.7556\n",
      "val Loss: 16.2685\n",
      "\n",
      "Training complete in 0m 1s\n",
      "Best val Loss: 16.268509\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 14.90421 and R2: -6.0709\n",
      "test RMSE: 3.8606\n"
     ]
    }
   ],
   "source": [
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "\n",
    "# raw time seires data for regression\n",
    "config = config5\n",
    "data_reg = mr.Regression(config, train_data, test_data, use_representation = True)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7e6565a69c64523dea2d3b31d6ed9f8445dc9714e18e3f5d2b2bc6eff30a54c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
