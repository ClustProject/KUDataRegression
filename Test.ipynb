{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17071984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import main_regression as mr\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def regression_report(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred) \n",
    "    mse = mean_squared_error(y_true, y_pred) \n",
    "    rmse = np.sqrt(mse)\n",
    "      \n",
    "    print('The regression reports are as follows = ')\n",
    "    print('MAE: ', round(mae,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(rmse,4))\n",
    "    return mae, mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "746373f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1294938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config1 = {\n",
    "        'model': 'LSTM', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 1000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 2. GRU model (w/o data representation)\n",
    "config2 = {\n",
    "        'model': 'GRU', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 1000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 3. CNN_1D model (w/o data representation)\n",
    "config3 = {\n",
    "        'model': 'CNN_1D', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/cnn_1d.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'seq_len': 144,  # 데이터의 시간 길이, int\n",
    "            'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "            'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "            'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "            'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 1000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 4. LSTM_FCNs model (w/o data representation)\n",
    "config4 = {\n",
    "        'model': 'LSTM_FCNs', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm_fcn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "            'lstm_drop_out': 0.1, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "            'fc_drop_out': 0.1, # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 1000, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config5 = {\n",
    "        'model': 'FC', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/fc.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 64,  # 데이터의 변수 개수(representation 차원), int\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bias': True, # bias 사용 여부, bool(default: True)\n",
    "            'num_epochs': 1000, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2553638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 24, 144)\n",
      "(95,)\n",
      "(42, 24, 144)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "# raw time series data\n",
    "train_x = pickle.load(open('./data/x_train.pkl', 'rb'))\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "test_x = pickle.load(open('./data/x_test.pkl', 'rb'))\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (95, 24, 144)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (95,)\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (42, 24, 144)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "510aa9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 24, 144)\n",
      "(42, 24, 144)\n"
     ]
    }
   ],
   "source": [
    "# scaling time series data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "if len(train_x.shape) < 3:\n",
    "    scaler = scaler.fit(train_x)\n",
    "else:\n",
    "    origin_shape = train_x.shape\n",
    "    scaler = scaler.fit(np.transpose(train_x, (0, 2, 1)).reshape(-1, origin_shape[1]))\n",
    "\n",
    "scaled_x_data = []\n",
    "for x_data in [train_x, test_x]:\n",
    "    if len(train_x.shape) < 3:\n",
    "        x_data = scaler.transform(x_data)\n",
    "    else:\n",
    "        x_data = scaler.transform(np.transpose(x_data, (0, 2, 1)).reshape(-1, origin_shape[1]))\n",
    "        x_data = np.transpose(x_data.reshape(-1, origin_shape[2], origin_shape[1]), (0, 2, 1))\n",
    "\n",
    "    scaled_x_data.append(x_data)\n",
    "train_x, test_x = scaled_x_data        \n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (95, 24, 144)\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (42, 24, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c54a5716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95,)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "# normalization of Y data\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaler = y_scaler.fit(train_y.reshape(train_y.shape[0], -1))\n",
    "\n",
    "train_y = y_scaler.transform(train_y.reshape(train_y.shape[0], -1)).flatten()\n",
    "test_y = y_scaler.transform(test_y.reshape(test_y.shape[0], -1)).flatten()\n",
    "\n",
    "print(train_y.shape) #shape : (num_of_instance) = (95,)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb988841",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d98f014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 0.2106\n",
      "val Loss: 0.1529\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 0.0725\n",
      "val Loss: 0.0391\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 0.0422\n",
      "val Loss: 0.0319\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 0.0410\n",
      "val Loss: 0.0327\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 0.0398\n",
      "val Loss: 0.0330\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 0.0379\n",
      "val Loss: 0.0350\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 0.0345\n",
      "val Loss: 0.0364\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 0.0283\n",
      "val Loss: 0.0402\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 0.0246\n",
      "val Loss: 0.0394\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 0.0223\n",
      "val Loss: 0.0412\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 0.0198\n",
      "val Loss: 0.0449\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 0.0187\n",
      "val Loss: 0.0426\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 0.0158\n",
      "val Loss: 0.0432\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 0.0147\n",
      "val Loss: 0.0436\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 0.0133\n",
      "val Loss: 0.0488\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 0.0134\n",
      "val Loss: 0.0416\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 0.0116\n",
      "val Loss: 0.0407\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 0.0111\n",
      "val Loss: 0.0418\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 0.0105\n",
      "val Loss: 0.0405\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 0.0100\n",
      "val Loss: 0.0387\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 0.0099\n",
      "val Loss: 0.0416\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 0.0090\n",
      "val Loss: 0.0403\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 0.0082\n",
      "val Loss: 0.0403\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 0.0080\n",
      "val Loss: 0.0385\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 0.0075\n",
      "val Loss: 0.0393\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 0.0072\n",
      "val Loss: 0.0383\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 0.0063\n",
      "val Loss: 0.0374\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 0.0067\n",
      "val Loss: 0.0388\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 0.0064\n",
      "val Loss: 0.0351\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 0.0054\n",
      "val Loss: 0.0358\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 0.0053\n",
      "val Loss: 0.0369\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 0.0050\n",
      "val Loss: 0.0339\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 0.0062\n",
      "val Loss: 0.0382\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 0.0053\n",
      "val Loss: 0.0334\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 0.0046\n",
      "val Loss: 0.0346\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 0.0042\n",
      "val Loss: 0.0345\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 0.0039\n",
      "val Loss: 0.0344\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 0.0037\n",
      "val Loss: 0.0346\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 0.0039\n",
      "val Loss: 0.0333\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 0.0034\n",
      "val Loss: 0.0330\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 0.0038\n",
      "val Loss: 0.0332\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 0.0035\n",
      "val Loss: 0.0313\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 0.0030\n",
      "val Loss: 0.0319\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 0.0033\n",
      "val Loss: 0.0325\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.0331\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.0305\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.0283\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0344\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0321\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 0.0024\n",
      "val Loss: 0.0313\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 0.0389\n",
      "val Loss: 0.0460\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 0.0185\n",
      "val Loss: 0.0253\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 0.0093\n",
      "val Loss: 0.0182\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 0.0056\n",
      "val Loss: 0.0188\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 0.0049\n",
      "val Loss: 0.0232\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 0.0035\n",
      "val Loss: 0.0270\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 0.0030\n",
      "val Loss: 0.0264\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.0272\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0277\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 0.0024\n",
      "val Loss: 0.0266\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.0262\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.0263\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0265\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0262\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0252\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 0.0020\n",
      "val Loss: 0.0249\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0248\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 0.0020\n",
      "val Loss: 0.0247\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 0.0018\n",
      "val Loss: 0.0239\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0250\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0237\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0228\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.0248\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0245\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0255\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 0.0019\n",
      "val Loss: 0.0232\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0210\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0231\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0218\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0218\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0220\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0209\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0210\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0201\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0207\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0210\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0221\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0215\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0198\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0208\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0199\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0207\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0201\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0212\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0241\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0232\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0235\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.0268\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 0.0052\n",
      "val Loss: 0.0270\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 0.0018\n",
      "val Loss: 0.0282\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0267\n",
      "\n",
      "Training complete in 1m 40s\n",
      "Best val MSE: 0.018213\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config = config1\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "412e673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 0.017429009079933167, MAE = 0.10097896307706833\n",
      "\n",
      "** Dimension of result for test dataset = (42,)\n",
      "\n",
      "** Result for test dataset = \n",
      "[0.3047709  0.42683783 0.35981247 0.3466163  0.29597327 0.28176564\n",
      " 0.72853875 0.3096343  0.34975728 0.31722355 0.51728046 0.33553642\n",
      " 0.37140888 0.4732644  0.39515972 0.58336943 0.29944944 0.5012954\n",
      " 0.2999904  0.40493697 0.25795576 0.4667928  0.30028078 0.4635774\n",
      " 0.31464398 0.3430924  0.3346968  0.6965303  0.45940176 0.2944054\n",
      " 0.79077196 0.26151785 0.44176152 0.26427045 0.40654683 0.30194065\n",
      " 0.3687495  0.5474853  0.5593459  0.25312018 0.23443124 0.60113305]\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'\\n** Dimension of result for test dataset = {pred.shape}')\n",
    "print(f'\\n** Result for test dataset = \\n{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b089772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression reports are as follows = \n",
      "MAE:  2.1145\n",
      "MSE:  7.6423\n",
      "RMSE:  2.7645\n",
      "\n",
      "** Result for test dataset (inverse) = \n",
      "[11.721903  14.277985  12.874474  12.5981455 11.537681  11.240173\n",
      " 20.595602  11.823743  12.663918  11.982661  16.171852  12.366134\n",
      " 13.117303  15.250157  13.614644  17.555758  11.610471  15.837127\n",
      " 11.6217985 13.819381  10.741594  15.114641  11.62788   15.04731\n",
      " 11.928644  12.524355  12.348552  19.925344  14.959873  11.50485\n",
      " 21.898766  10.816184  14.590487  10.873823  13.85309   11.662638\n",
      " 13.061614  16.804342  17.052704  10.640336  10.24899   17.927727 ]\n"
     ]
    }
   ],
   "source": [
    "test_y_inverse = y_scaler.inverse_transform(test_y.reshape(test_y.shape[0], -1)).flatten()\n",
    "pred_y_inverse = y_scaler.inverse_transform(pred.reshape(pred.shape[0], -1)).flatten()\n",
    "mae, mse, rmse = regression_report (test_y_inverse, pred_y_inverse)\n",
    "\n",
    "print(f'\\n** Result for test dataset (inverse) = \\n{pred_y_inverse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17096cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 0.4116\n",
      "val Loss: 0.2935\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 0.0459\n",
      "val Loss: 0.0313\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 0.0434\n",
      "val Loss: 0.0329\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 0.0423\n",
      "val Loss: 0.0327\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 0.0411\n",
      "val Loss: 0.0328\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 0.0399\n",
      "val Loss: 0.0327\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 0.0387\n",
      "val Loss: 0.0324\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 0.0373\n",
      "val Loss: 0.0328\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 0.0360\n",
      "val Loss: 0.0325\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 0.0347\n",
      "val Loss: 0.0331\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 0.0334\n",
      "val Loss: 0.0331\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 0.0318\n",
      "val Loss: 0.0329\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 0.0306\n",
      "val Loss: 0.0322\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 0.0290\n",
      "val Loss: 0.0329\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 0.0277\n",
      "val Loss: 0.0311\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 0.0269\n",
      "val Loss: 0.0318\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 0.0250\n",
      "val Loss: 0.0324\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 0.0240\n",
      "val Loss: 0.0333\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 0.0239\n",
      "val Loss: 0.0296\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 0.0216\n",
      "val Loss: 0.0313\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 0.0208\n",
      "val Loss: 0.0321\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 0.0195\n",
      "val Loss: 0.0311\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 0.0198\n",
      "val Loss: 0.0301\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 0.0184\n",
      "val Loss: 0.0273\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 0.0176\n",
      "val Loss: 0.0289\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 0.0180\n",
      "val Loss: 0.0276\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 0.0174\n",
      "val Loss: 0.0254\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 0.0173\n",
      "val Loss: 0.0308\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 0.0162\n",
      "val Loss: 0.0278\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 0.0162\n",
      "val Loss: 0.0270\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 0.0156\n",
      "val Loss: 0.0285\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 0.0165\n",
      "val Loss: 0.0241\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 0.0153\n",
      "val Loss: 0.0250\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 0.0151\n",
      "val Loss: 0.0252\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 0.0146\n",
      "val Loss: 0.0230\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 0.0143\n",
      "val Loss: 0.0246\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 0.0138\n",
      "val Loss: 0.0267\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 0.0139\n",
      "val Loss: 0.0227\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 0.0132\n",
      "val Loss: 0.0225\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 0.0132\n",
      "val Loss: 0.0240\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 0.0154\n",
      "val Loss: 0.0269\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 0.0133\n",
      "val Loss: 0.0253\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 0.0128\n",
      "val Loss: 0.0232\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 0.0120\n",
      "val Loss: 0.0239\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 0.0127\n",
      "val Loss: 0.0222\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 0.0112\n",
      "val Loss: 0.0235\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 0.0115\n",
      "val Loss: 0.0229\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 0.0109\n",
      "val Loss: 0.0231\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 0.0109\n",
      "val Loss: 0.0268\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 0.0117\n",
      "val Loss: 0.0257\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 0.0104\n",
      "val Loss: 0.0255\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 0.0100\n",
      "val Loss: 0.0241\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 0.0092\n",
      "val Loss: 0.0244\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 0.0089\n",
      "val Loss: 0.0282\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 0.0093\n",
      "val Loss: 0.0228\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 0.0088\n",
      "val Loss: 0.0245\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 0.0087\n",
      "val Loss: 0.0242\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 0.0089\n",
      "val Loss: 0.0225\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 0.0089\n",
      "val Loss: 0.0246\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 0.0102\n",
      "val Loss: 0.0257\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 0.0092\n",
      "val Loss: 0.0257\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 0.0080\n",
      "val Loss: 0.0239\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 0.0078\n",
      "val Loss: 0.0234\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 0.0092\n",
      "val Loss: 0.0227\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 0.0075\n",
      "val Loss: 0.0242\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 0.0072\n",
      "val Loss: 0.0236\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 0.0086\n",
      "val Loss: 0.0234\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 0.0077\n",
      "val Loss: 0.0237\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 0.0072\n",
      "val Loss: 0.0239\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 0.0078\n",
      "val Loss: 0.0233\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 0.0064\n",
      "val Loss: 0.0238\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 0.0061\n",
      "val Loss: 0.0240\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 0.0060\n",
      "val Loss: 0.0243\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 0.0061\n",
      "val Loss: 0.0247\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 0.0060\n",
      "val Loss: 0.0237\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 0.0055\n",
      "val Loss: 0.0239\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 0.0055\n",
      "val Loss: 0.0234\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 0.0052\n",
      "val Loss: 0.0243\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 0.0064\n",
      "val Loss: 0.0234\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 0.0049\n",
      "val Loss: 0.0242\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 0.0050\n",
      "val Loss: 0.0235\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 0.0046\n",
      "val Loss: 0.0242\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 0.0056\n",
      "val Loss: 0.0235\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 0.0044\n",
      "val Loss: 0.0239\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 0.0045\n",
      "val Loss: 0.0242\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 0.0070\n",
      "val Loss: 0.0230\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 0.0039\n",
      "val Loss: 0.0241\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 0.0048\n",
      "val Loss: 0.0238\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 0.0059\n",
      "val Loss: 0.0245\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 0.0040\n",
      "val Loss: 0.0229\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 0.0037\n",
      "val Loss: 0.0231\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 0.0037\n",
      "val Loss: 0.0235\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 0.0033\n",
      "val Loss: 0.0230\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.0230\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.0232\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.0234\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 0.0027\n",
      "val Loss: 0.0236\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.0234\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0245\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 0.0038\n",
      "val Loss: 0.0248\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0228\n",
      "\n",
      "Training complete in 1m 7s\n",
      "Best val MSE: 0.021543\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 2. GRU (w/o data representation)\n",
    "config = config2\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9153c3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 0.018103018403053284, MAE = 0.10689087957143784\n",
      "\n",
      "** Dimension of result for test dataset = (42,)\n",
      "\n",
      "** Result for test dataset = \n",
      "[0.36939186 0.46465832 0.33999524 0.24856427 0.26177135 0.21089107\n",
      " 0.7682883  0.35205546 0.25180808 0.3126573  0.62921196 0.2842126\n",
      " 0.29155764 0.3062406  0.43172085 0.544011   0.48174143 0.26652867\n",
      " 0.1900303  0.3990894  0.24132988 0.51944596 0.27525833 0.34875762\n",
      " 0.365018   0.3091969  0.41964355 0.602382   0.2528928  0.23492199\n",
      " 0.675107   0.21797833 0.40153563 0.26168284 0.5106204  0.17388318\n",
      " 0.2152636  0.44397503 0.5998846  0.11629543 0.12592539 0.5139011 ]\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'\\n** Dimension of result for test dataset = {pred.shape}')\n",
    "print(f'\\n** Result for test dataset = \\n{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90e85060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression reports are as follows = \n",
      "MAE:  2.2383\n",
      "MSE:  7.9379\n",
      "RMSE:  2.8174\n",
      "\n",
      "** Result for test dataset (inverse) = \n",
      "[13.075067  15.069946  12.4595    10.544936  10.821492   9.75606\n",
      " 21.427958  12.712042  10.612862  11.887045  18.5157    11.291411\n",
      " 11.445217  11.752678  14.380235  16.73159   15.427666  10.921111\n",
      "  9.319235  13.696933  10.393448  16.2172    11.1039095 12.642984\n",
      " 12.983477  11.814584  14.1273365 17.95388   10.635576  10.259267\n",
      " 19.47674    9.904467  13.748156  10.819639  16.032393   8.981113\n",
      "  9.84762   14.636838  17.901585   7.7752266  7.976878  16.10109  ]\n"
     ]
    }
   ],
   "source": [
    "test_y_inverse = y_scaler.inverse_transform(test_y.reshape(test_y.shape[0], -1)).flatten()\n",
    "pred_y_inverse = y_scaler.inverse_transform(pred.reshape(pred.shape[0], -1)).flatten()\n",
    "mae, mse, rmse = regression_report (test_y_inverse, pred_y_inverse)\n",
    "\n",
    "print(f'\\n** Result for test dataset (inverse) = \\n{pred_y_inverse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54002e55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 0.2695\n",
      "val Loss: 0.1689\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 0.0459\n",
      "val Loss: 0.0335\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 0.0421\n",
      "val Loss: 0.0328\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 0.0389\n",
      "val Loss: 0.0345\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 0.0375\n",
      "val Loss: 0.0333\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 0.0355\n",
      "val Loss: 0.0329\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 0.0341\n",
      "val Loss: 0.0341\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 0.0311\n",
      "val Loss: 0.0360\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 0.0260\n",
      "val Loss: 0.0366\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 0.0288\n",
      "val Loss: 0.0368\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 0.0239\n",
      "val Loss: 0.0449\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 0.0209\n",
      "val Loss: 0.0421\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 0.0194\n",
      "val Loss: 0.0495\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 0.0194\n",
      "val Loss: 0.0481\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 0.0165\n",
      "val Loss: 0.0511\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 0.0168\n",
      "val Loss: 0.0502\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 0.0152\n",
      "val Loss: 0.0570\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 0.0138\n",
      "val Loss: 0.0526\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 0.0149\n",
      "val Loss: 0.0519\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 0.0124\n",
      "val Loss: 0.0527\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 0.0114\n",
      "val Loss: 0.0546\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 0.0139\n",
      "val Loss: 0.0513\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 0.0109\n",
      "val Loss: 0.0520\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 0.0117\n",
      "val Loss: 0.0579\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 0.0088\n",
      "val Loss: 0.0497\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 0.0101\n",
      "val Loss: 0.0576\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 0.0089\n",
      "val Loss: 0.0529\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 0.0099\n",
      "val Loss: 0.0494\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 0.0081\n",
      "val Loss: 0.0545\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 0.0068\n",
      "val Loss: 0.0482\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 0.0066\n",
      "val Loss: 0.0506\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 0.0067\n",
      "val Loss: 0.0497\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 0.0062\n",
      "val Loss: 0.0504\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 0.0060\n",
      "val Loss: 0.0479\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 0.0056\n",
      "val Loss: 0.0498\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 0.0055\n",
      "val Loss: 0.0473\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 0.0049\n",
      "val Loss: 0.0471\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 0.0047\n",
      "val Loss: 0.0479\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 0.0050\n",
      "val Loss: 0.0469\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 0.0037\n",
      "val Loss: 0.0455\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 0.0033\n",
      "val Loss: 0.0469\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 0.0040\n",
      "val Loss: 0.0460\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 0.0034\n",
      "val Loss: 0.0460\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 0.0034\n",
      "val Loss: 0.0467\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 0.0036\n",
      "val Loss: 0.0479\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 0.0033\n",
      "val Loss: 0.0460\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.0471\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 0.0030\n",
      "val Loss: 0.0460\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0461\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 0.0024\n",
      "val Loss: 0.0487\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 0.0027\n",
      "val Loss: 0.0450\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0477\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.0482\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0464\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.0447\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 0.0027\n",
      "val Loss: 0.0459\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 0.0024\n",
      "val Loss: 0.0464\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0477\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 0.0020\n",
      "val Loss: 0.0465\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0455\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0458\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0461\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0464\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0456\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0460\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0456\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0470\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0438\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0452\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0473\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0460\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0464\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0444\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0489\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0448\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0443\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0454\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0448\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0450\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0453\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0465\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0471\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0453\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0469\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0446\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0462\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0442\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0451\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0463\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0450\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0462\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0429\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0466\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0443\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0450\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0442\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0441\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0439\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0442\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0434\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0430\n",
      "\n",
      "Training complete in 0m 13s\n",
      "Best val MSE: 0.031621\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 3. CNN_1D (w/o data representation)\n",
    "config = config3\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75e6fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 0.02758614718914032, MAE = 0.13107439875602722\n",
      "\n",
      "** Dimension of result for test dataset = (42,)\n",
      "\n",
      "** Result for test dataset = \n",
      "[0.44077972 0.4256018  0.3758379  0.4256594  0.42308784 0.39099947\n",
      " 0.3928827  0.46756265 0.4121578  0.46640396 0.40377593 0.43973404\n",
      " 0.42629552 0.5247498  0.4278915  0.4313423  0.38731903 0.45402232\n",
      " 0.39701858 0.45266867 0.3863931  0.41109562 0.42002586 0.39317295\n",
      " 0.3822829  0.38881293 0.46851036 0.45563018 0.43082944 0.4291013\n",
      " 0.46020874 0.34560657 0.4141638  0.388745   0.3378096  0.3645021\n",
      " 0.42241335 0.55821687 0.36535075 0.3813812  0.3863528  0.43012348]\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'\\n** Dimension of result for test dataset = {pred.shape}')\n",
    "print(f'\\n** Result for test dataset = \\n{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "916b2376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression reports are as follows = \n",
      "MAE:  2.7447\n",
      "MSE:  12.0961\n",
      "RMSE:  3.4779\n",
      "\n",
      "** Result for test dataset (inverse) = \n",
      "[14.569927  14.252102  13.210046  14.253308  14.199459  13.527529\n",
      " 13.566963  15.130762  13.970585  15.106499  13.795068  14.548032\n",
      " 14.266628  16.328262  14.300048  14.372309  13.450461  14.847228\n",
      " 13.653569  14.818882  13.431072  13.948342  14.135342  13.573042\n",
      " 13.345005  13.481743  15.150607  14.880896  14.361568  14.325382\n",
      " 14.976771  12.577002  14.01259   13.480322  12.4137335 12.972674\n",
      " 14.185335  17.029062  12.990445  13.326123  13.430228  14.346786 ]\n"
     ]
    }
   ],
   "source": [
    "test_y_inverse = y_scaler.inverse_transform(test_y.reshape(test_y.shape[0], -1)).flatten()\n",
    "pred_y_inverse = y_scaler.inverse_transform(pred.reshape(pred.shape[0], -1)).flatten()\n",
    "mae, mse, rmse = regression_report (test_y_inverse, pred_y_inverse)\n",
    "\n",
    "print(f'\\n** Result for test dataset (inverse) = \\n{pred_y_inverse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c1c7762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 0.1856\n",
      "val Loss: 0.1621\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 0.0465\n",
      "val Loss: 0.0483\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 0.0132\n",
      "val Loss: 0.0362\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 0.0076\n",
      "val Loss: 0.0363\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 0.0063\n",
      "val Loss: 0.0335\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 0.0062\n",
      "val Loss: 0.0318\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.0310\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 0.0048\n",
      "val Loss: 0.0393\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0353\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 0.0075\n",
      "val Loss: 0.0426\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0387\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 0.0019\n",
      "val Loss: 0.0341\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 0.0018\n",
      "val Loss: 0.0381\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.0356\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 0.0045\n",
      "val Loss: 0.0433\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 0.0079\n",
      "val Loss: 0.0457\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.0375\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0373\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 0.0067\n",
      "val Loss: 0.0370\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0325\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 0.0030\n",
      "val Loss: 0.0368\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0437\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0401\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 0.0027\n",
      "val Loss: 0.0390\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 0.0046\n",
      "val Loss: 0.0385\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.0368\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0345\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 0.0048\n",
      "val Loss: 0.0386\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 0.0033\n",
      "val Loss: 0.0358\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 0.0032\n",
      "val Loss: 0.0318\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0328\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0395\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0411\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.0394\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.0326\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.0382\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0366\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0349\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 0.0052\n",
      "val Loss: 0.0390\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 0.0020\n",
      "val Loss: 0.0338\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0354\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 0.0062\n",
      "val Loss: 0.0319\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 0.0038\n",
      "val Loss: 0.0381\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0353\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0352\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 0.0061\n",
      "val Loss: 0.0354\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 0.0032\n",
      "val Loss: 0.0384\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0377\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0380\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.0387\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0360\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.0394\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.0296\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 0.0048\n",
      "val Loss: 0.0327\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0324\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 0.0019\n",
      "val Loss: 0.0318\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0340\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0352\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.0355\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 0.0038\n",
      "val Loss: 0.0302\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 0.0034\n",
      "val Loss: 0.0424\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 0.0044\n",
      "val Loss: 0.0328\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 0.0043\n",
      "val Loss: 0.0342\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0314\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 0.0043\n",
      "val Loss: 0.0333\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0348\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 0.0056\n",
      "val Loss: 0.0328\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.0339\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.0318\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.0341\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0364\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0358\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0318\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0300\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 0.0019\n",
      "val Loss: 0.0347\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.0359\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0297\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.0319\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0311\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0287\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0321\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0346\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0282\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.0264\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0298\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0320\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0300\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0298\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0270\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.0346\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0330\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0279\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0252\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.0304\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0224\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0273\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.0324\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0321\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0298\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.0226\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 0.0018\n",
      "val Loss: 0.0260\n",
      "\n",
      "Training complete in 1m 26s\n",
      "Best val MSE: 0.022244\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 4. LSTM_FCNs (w/o data representation)\n",
    "config = config4\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "272cff76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 0.021918687969446182, MAE = 0.11415926367044449\n",
      "\n",
      "** Dimension of result for test dataset = (42,)\n",
      "\n",
      "** Result for test dataset = \n",
      "[0.41571447 0.36990875 0.4027995  0.31158298 0.35978344 0.2612773\n",
      " 0.5857863  0.37377116 0.33932647 0.49704972 0.49419686 0.32649043\n",
      " 0.36809796 0.552688   0.4349853  0.52439344 0.4641516  0.4960039\n",
      " 0.20722315 0.4218952  0.20041293 0.39132303 0.37325558 0.40476045\n",
      " 0.35932904 0.39706486 0.32728073 0.47955844 0.25320253 0.40826923\n",
      " 0.5054712  0.26766875 0.5665003  0.20846343 0.43009248 0.40670663\n",
      " 0.32289103 0.66277146 0.5870684  0.18357942 0.48000178 0.51906145]\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'\\n** Dimension of result for test dataset = {pred.shape}')\n",
    "print(f'\\n** Result for test dataset = \\n{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "236d1144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression reports are as follows = \n",
      "MAE:  2.3905\n",
      "MSE:  9.611\n",
      "RMSE:  3.1002\n",
      "\n",
      "** Result for test dataset (inverse) = \n",
      "[14.045061  13.08589   13.774621  11.864549  12.873865  10.811147\n",
      " 17.606365  13.166768  12.445497  15.748221  15.688482  12.17671\n",
      " 13.047973  16.913286  14.448593  16.320799  15.059335  15.726322\n",
      "  9.679253  14.174486   9.536647  13.534306  13.1559725 13.815684\n",
      " 12.864351  13.654539  12.193259  15.381954  10.642061  13.889158\n",
      " 15.924567  10.944984  17.202517   9.705224  14.346137  13.856438\n",
      " 12.101338  19.218433  17.633213   9.184154  15.391237  16.209146 ]\n"
     ]
    }
   ],
   "source": [
    "test_y_inverse = y_scaler.inverse_transform(test_y.reshape(test_y.shape[0], -1)).flatten()\n",
    "pred_y_inverse = y_scaler.inverse_transform(pred.reshape(pred.shape[0], -1)).flatten()\n",
    "mae, mse, rmse = regression_report (test_y_inverse, pred_y_inverse)\n",
    "\n",
    "print(f'\\n** Result for test dataset (inverse) = \\n{pred_y_inverse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e9101",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2282e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 64)\n",
      "(95,)\n",
      "(42, 64)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "# representation data\n",
    "train_x = pd.read_csv('./data/ts2vec_repr_train.csv')\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "\n",
    "test_x = pd.read_csv('./data/ts2vec_repr_test.csv')\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x representation_dims) = (95, 64)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (95, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x representation_dims) = (42, 64)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (42, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "febc51d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 209.6828\n",
      "val Loss: 175.2797\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 192.5818\n",
      "val Loss: 161.3480\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 173.0780\n",
      "val Loss: 142.3571\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 147.4441\n",
      "val Loss: 120.1095\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 118.7403\n",
      "val Loss: 97.4779\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 95.7690\n",
      "val Loss: 75.5590\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 73.7453\n",
      "val Loss: 56.3923\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 56.7339\n",
      "val Loss: 40.8764\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 44.2354\n",
      "val Loss: 29.4787\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 34.6329\n",
      "val Loss: 21.7455\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 31.0377\n",
      "val Loss: 16.9953\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 28.1335\n",
      "val Loss: 14.2482\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 25.8113\n",
      "val Loss: 12.8126\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 23.5047\n",
      "val Loss: 12.1300\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 22.8712\n",
      "val Loss: 11.7650\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 24.5383\n",
      "val Loss: 11.6133\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 20.0763\n",
      "val Loss: 11.5351\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 21.8304\n",
      "val Loss: 11.4859\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 22.6001\n",
      "val Loss: 11.4543\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 19.0033\n",
      "val Loss: 11.4590\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 24.3079\n",
      "val Loss: 11.4661\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 19.4058\n",
      "val Loss: 11.4933\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 23.2482\n",
      "val Loss: 11.5123\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 20.9615\n",
      "val Loss: 11.5247\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 21.8321\n",
      "val Loss: 11.5575\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 20.9662\n",
      "val Loss: 11.5950\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 22.1083\n",
      "val Loss: 11.6225\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 20.9447\n",
      "val Loss: 11.6654\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 20.5481\n",
      "val Loss: 11.7084\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 19.1327\n",
      "val Loss: 11.7191\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 17.1676\n",
      "val Loss: 11.7625\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 22.0346\n",
      "val Loss: 11.8076\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 20.4503\n",
      "val Loss: 11.8385\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 22.8245\n",
      "val Loss: 11.8729\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 20.7910\n",
      "val Loss: 11.9281\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 19.8810\n",
      "val Loss: 11.9295\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 18.1702\n",
      "val Loss: 11.9844\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 18.9202\n",
      "val Loss: 12.0117\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 21.0925\n",
      "val Loss: 12.0649\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 20.7334\n",
      "val Loss: 12.0870\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 20.2236\n",
      "val Loss: 12.1089\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 19.2267\n",
      "val Loss: 12.1256\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 16.9208\n",
      "val Loss: 12.1672\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 20.3608\n",
      "val Loss: 12.1961\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 17.9472\n",
      "val Loss: 12.2197\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 18.6062\n",
      "val Loss: 12.2516\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 21.6494\n",
      "val Loss: 12.3194\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 19.0472\n",
      "val Loss: 12.3396\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 19.8896\n",
      "val Loss: 12.3488\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 19.5189\n",
      "val Loss: 12.3615\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 18.6221\n",
      "val Loss: 12.3976\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 17.1369\n",
      "val Loss: 12.4324\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 17.3973\n",
      "val Loss: 12.4615\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 19.7457\n",
      "val Loss: 12.5121\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 17.9775\n",
      "val Loss: 12.5292\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 19.3555\n",
      "val Loss: 12.5854\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 19.0472\n",
      "val Loss: 12.6163\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 17.5420\n",
      "val Loss: 12.6415\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 16.5858\n",
      "val Loss: 12.6753\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 18.0993\n",
      "val Loss: 12.6987\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 18.2420\n",
      "val Loss: 12.7443\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 19.4447\n",
      "val Loss: 12.7833\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 18.0782\n",
      "val Loss: 12.8161\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 17.7419\n",
      "val Loss: 12.8383\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 17.2524\n",
      "val Loss: 12.8767\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 17.4193\n",
      "val Loss: 12.9339\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 16.3792\n",
      "val Loss: 13.0046\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 15.0446\n",
      "val Loss: 13.0637\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 17.5269\n",
      "val Loss: 13.1325\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 19.1007\n",
      "val Loss: 13.1565\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 16.4248\n",
      "val Loss: 13.1760\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 18.5978\n",
      "val Loss: 13.2481\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 17.5303\n",
      "val Loss: 13.2887\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 18.9380\n",
      "val Loss: 13.3064\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 14.7057\n",
      "val Loss: 13.3638\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 13.8565\n",
      "val Loss: 13.3796\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 16.5686\n",
      "val Loss: 13.4800\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 17.0075\n",
      "val Loss: 13.4776\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 16.0031\n",
      "val Loss: 13.5203\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 15.5280\n",
      "val Loss: 13.5611\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 18.3408\n",
      "val Loss: 13.6667\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 19.8426\n",
      "val Loss: 13.7165\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 18.2997\n",
      "val Loss: 13.7166\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 14.6855\n",
      "val Loss: 13.7598\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 15.0123\n",
      "val Loss: 13.8631\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 16.0743\n",
      "val Loss: 13.9380\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 17.2478\n",
      "val Loss: 13.9089\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 15.8649\n",
      "val Loss: 13.9827\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 14.7107\n",
      "val Loss: 14.0407\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 13.7963\n",
      "val Loss: 14.0647\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 13.1087\n",
      "val Loss: 14.1506\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 13.8707\n",
      "val Loss: 14.2003\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 16.4876\n",
      "val Loss: 14.1934\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 15.6818\n",
      "val Loss: 14.2589\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 14.7399\n",
      "val Loss: 14.3039\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 15.2364\n",
      "val Loss: 14.3264\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 14.7490\n",
      "val Loss: 14.3264\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 15.0947\n",
      "val Loss: 14.3361\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 13.7155\n",
      "val Loss: 14.3733\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 16.5207\n",
      "val Loss: 14.4511\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 14.3774\n",
      "val Loss: 14.4615\n",
      "\n",
      "Training complete in 0m 9s\n",
      "Best val MSE: 11.446979\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config = config5\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d74c221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 14.826444625854492, MAE = 3.108508825302124\n",
      "\n",
      "** Dimension of result for test dataset = (42,)\n",
      "\n",
      "** Result for test dataset = \n",
      "[13.576086  14.051125  13.788996  11.888471  16.93226   12.359262\n",
      " 11.974563  15.386085  13.054042  12.623264  12.654381  16.077137\n",
      " 13.450314  15.690181  16.198381  13.821231  13.064769  13.32776\n",
      " 12.786972  13.3713255 13.498327  12.48228   15.992512  15.445408\n",
      " 15.823911  11.946144  12.971921  13.934993  12.8658285 13.864472\n",
      " 13.1964655 12.532198  16.855518  16.06662   15.764783  12.323561\n",
      " 12.073018  14.434633  11.96619   12.237625  13.90027   14.222074 ]\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'\\n** Dimension of result for test dataset = {pred.shape}')\n",
    "print(f'\\n** Result for test dataset = \\n{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1bb1f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression reports are as follows = \n",
      "MAE:  65.0922\n",
      "MSE:  6501.1523\n",
      "RMSE:  80.6297\n",
      "\n",
      "** Result for test dataset (inverse) = \n",
      "[289.62326 299.57056 294.08157 254.28458 359.90155 264.14297 256.08734\n",
      " 327.52463 278.69165 269.67117 270.32275 341.99527 286.98956 333.8924\n",
      " 344.53412 294.7566  278.91626 284.4233  273.0992  285.33557 287.995\n",
      " 266.71893 340.2232  328.76685 336.6927  255.49226 276.97205 297.13876\n",
      " 274.75046 295.66205 281.67398 267.76422 358.29456 341.77502 335.45453\n",
      " 263.39536 258.14902 307.60123 255.91203 261.5959  296.41168 303.15024]\n"
     ]
    }
   ],
   "source": [
    "test_y_inverse = y_scaler.inverse_transform(test_y.reshape(test_y.shape[0], -1)).flatten()\n",
    "pred_y_inverse = y_scaler.inverse_transform(pred.reshape(pred.shape[0], -1)).flatten()\n",
    "mae, mse, rmse = regression_report (test_y_inverse, pred_y_inverse)\n",
    "\n",
    "print(f'\\n** Result for test dataset (inverse) = \\n{pred_y_inverse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "55fce49eafdf681291895f50af6c2444e3b18b6b90c1589104c163ac22e77f76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
