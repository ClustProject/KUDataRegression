{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import main_regression as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config1 = {\n",
    "        'model': 'LSTM', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 1000,  # 학습 epoch 횟수, int(default: 1000, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 16, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 2. GRU model (w/o data representation)\n",
    "config2 = {\n",
    "        'model': 'GRU', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 1000,  # 학습 epoch 횟수, int(default: 1000, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 16, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 3. CNN_1D model (w/o data representation)\n",
    "config3 = {\n",
    "        'model': 'CNN_1D', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/cnn_1d.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'seq_len': 144,  # 데이터의 시간 길이, int\n",
    "            'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "            'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "            'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "            'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 1000,  # 학습 epoch 횟수, int(default: 1000, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 16, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 4. LSTM_FCNs model (w/o data representation)\n",
    "config4 = {\n",
    "        'model': 'LSTM_FCNs', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm_fcn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'lstm_drop_out': 0.1, # LSTM dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'fc_drop_out': 0.1, # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 1000, # 학습 epoch 횟수, int(default: 1000, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 16, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config5 = {\n",
    "        'model': 'FC', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/fc.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 64,  # 데이터의 변수 개수(representation 차원), int\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bias': True, # bias 사용 여부, bool(default: True)\n",
    "            'num_epochs': 1000, # 학습 epoch 횟수, int(default: 1000, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 16, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 24, 144)\n",
      "(95,)\n",
      "(42, 24, 144)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "# raw time series data\n",
    "train_x = pickle.load(open('./data/x_train.pkl', 'rb'))\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "test_x = pickle.load(open('./data/x_test.pkl', 'rb'))\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (95, 24, 144)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (95,)\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (42, 24, 144)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 223.7674\n",
      "val Loss: 190.3345\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 210.2965\n",
      "val Loss: 177.4592\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 180.4303\n",
      "val Loss: 148.4286\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 144.4305\n",
      "val Loss: 116.1962\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 119.0877\n",
      "val Loss: 93.6555\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 99.2963\n",
      "val Loss: 76.1784\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 83.4011\n",
      "val Loss: 62.2586\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 70.4260\n",
      "val Loss: 51.1112\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 60.1143\n",
      "val Loss: 42.4102\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 51.2951\n",
      "val Loss: 35.1722\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 44.4562\n",
      "val Loss: 29.6943\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 39.0166\n",
      "val Loss: 25.4268\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 34.6994\n",
      "val Loss: 22.1687\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 31.2190\n",
      "val Loss: 19.6624\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 28.4767\n",
      "val Loss: 17.7805\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 26.2840\n",
      "val Loss: 16.3688\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 24.4931\n",
      "val Loss: 15.3279\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 23.1821\n",
      "val Loss: 14.6373\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 22.1717\n",
      "val Loss: 14.1857\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 21.4109\n",
      "val Loss: 13.9166\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 20.8486\n",
      "val Loss: 13.7774\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 20.4399\n",
      "val Loss: 13.7297\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 20.1232\n",
      "val Loss: 13.7449\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 19.8889\n",
      "val Loss: 13.8015\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 19.7354\n",
      "val Loss: 13.8815\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 19.6240\n",
      "val Loss: 13.9715\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 19.5392\n",
      "val Loss: 14.0684\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 19.4897\n",
      "val Loss: 14.1504\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 19.4536\n",
      "val Loss: 14.2407\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 19.4249\n",
      "val Loss: 14.3066\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 19.3940\n",
      "val Loss: 14.2827\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 19.3764\n",
      "val Loss: 14.3400\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 19.3600\n",
      "val Loss: 14.3630\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 19.3467\n",
      "val Loss: 14.3559\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 19.3367\n",
      "val Loss: 14.3761\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 19.3206\n",
      "val Loss: 14.3691\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 19.3048\n",
      "val Loss: 14.3787\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 19.2993\n",
      "val Loss: 14.4056\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 19.2955\n",
      "val Loss: 14.4463\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 19.2928\n",
      "val Loss: 14.4490\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 19.2906\n",
      "val Loss: 14.4803\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 19.2840\n",
      "val Loss: 14.4709\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 19.2830\n",
      "val Loss: 14.4980\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 19.2810\n",
      "val Loss: 14.4903\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 19.2776\n",
      "val Loss: 14.4874\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 19.2742\n",
      "val Loss: 14.4849\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 19.2723\n",
      "val Loss: 14.4800\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 19.2703\n",
      "val Loss: 14.4822\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 19.2543\n",
      "val Loss: 14.4581\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 19.2452\n",
      "val Loss: 14.3727\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 19.1760\n",
      "val Loss: 14.3377\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 19.0338\n",
      "val Loss: 14.0338\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 18.9058\n",
      "val Loss: 13.7303\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 18.8260\n",
      "val Loss: 13.5519\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 18.7559\n",
      "val Loss: 13.6831\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 18.6589\n",
      "val Loss: 13.5693\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 18.5667\n",
      "val Loss: 13.6029\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 18.8159\n",
      "val Loss: 14.1091\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 18.5782\n",
      "val Loss: 14.1524\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 18.4762\n",
      "val Loss: 14.0312\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 18.3533\n",
      "val Loss: 14.0049\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 18.3368\n",
      "val Loss: 13.6758\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 18.1004\n",
      "val Loss: 13.7691\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 17.9420\n",
      "val Loss: 13.3228\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 17.2239\n",
      "val Loss: 14.0429\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 18.8362\n",
      "val Loss: 13.8197\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 18.4006\n",
      "val Loss: 14.5915\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 17.7590\n",
      "val Loss: 16.2878\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 17.2251\n",
      "val Loss: 16.8584\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 15.6169\n",
      "val Loss: 16.5112\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 17.4632\n",
      "val Loss: 16.5675\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 17.1545\n",
      "val Loss: 17.2966\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 17.4074\n",
      "val Loss: 16.4380\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 16.7203\n",
      "val Loss: 14.3777\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 15.8552\n",
      "val Loss: 13.1769\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 14.5281\n",
      "val Loss: 17.6117\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 14.0983\n",
      "val Loss: 20.2160\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 15.5641\n",
      "val Loss: 21.1371\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 14.8174\n",
      "val Loss: 15.8238\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 18.2407\n",
      "val Loss: 19.3068\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 12.1335\n",
      "val Loss: 20.7688\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 12.3667\n",
      "val Loss: 20.6137\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 12.0791\n",
      "val Loss: 19.7681\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 11.7200\n",
      "val Loss: 19.4847\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 9.5326\n",
      "val Loss: 21.2023\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 8.2983\n",
      "val Loss: 21.1746\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 9.1856\n",
      "val Loss: 20.5857\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 8.0722\n",
      "val Loss: 18.6093\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 8.9260\n",
      "val Loss: 20.9648\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 9.1887\n",
      "val Loss: 18.7994\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 7.4298\n",
      "val Loss: 20.2945\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 11.3311\n",
      "val Loss: 21.6520\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 17.7656\n",
      "val Loss: 17.6519\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 13.0899\n",
      "val Loss: 16.9270\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 10.6388\n",
      "val Loss: 17.5640\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 8.9843\n",
      "val Loss: 17.8575\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 8.4607\n",
      "val Loss: 20.4819\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 6.7895\n",
      "val Loss: 17.5963\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 7.1238\n",
      "val Loss: 23.8454\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 5.5995\n",
      "val Loss: 19.1809\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 14.1153\n",
      "val Loss: 28.9053\n",
      "\n",
      "Training complete in 0m 51s\n",
      "Best val MSE: 12.985419\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config = config1\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 12.972700119018555, MAE = 2.7908825874328613\n",
      "** Dimension of result for test dataset = (42,)\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'** Dimension of result for test dataset = {pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 227.3942\n",
      "val Loss: 191.6880\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 186.3391\n",
      "val Loss: 153.6383\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 148.0420\n",
      "val Loss: 119.2658\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 118.3456\n",
      "val Loss: 92.8377\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 96.7763\n",
      "val Loss: 73.8525\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 80.3770\n",
      "val Loss: 59.6750\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 67.3567\n",
      "val Loss: 48.4864\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 57.0061\n",
      "val Loss: 39.8115\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 48.6998\n",
      "val Loss: 33.0317\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 42.0997\n",
      "val Loss: 27.8164\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 36.9311\n",
      "val Loss: 23.8177\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 32.8255\n",
      "val Loss: 20.7926\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 29.5859\n",
      "val Loss: 18.5334\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 27.0894\n",
      "val Loss: 16.8793\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 25.1445\n",
      "val Loss: 15.6843\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 23.6446\n",
      "val Loss: 14.8627\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 22.5003\n",
      "val Loss: 14.3160\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 21.6382\n",
      "val Loss: 13.9830\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 20.9965\n",
      "val Loss: 13.8075\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 20.5219\n",
      "val Loss: 13.7322\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 20.1746\n",
      "val Loss: 13.7308\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 19.9321\n",
      "val Loss: 13.7829\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 19.7604\n",
      "val Loss: 13.8596\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 19.6387\n",
      "val Loss: 13.9457\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 19.5494\n",
      "val Loss: 14.0372\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 19.4931\n",
      "val Loss: 14.1137\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 19.4432\n",
      "val Loss: 14.1977\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 19.4139\n",
      "val Loss: 14.2766\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 19.3972\n",
      "val Loss: 14.3353\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 19.3828\n",
      "val Loss: 14.3998\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 19.3734\n",
      "val Loss: 14.4567\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 19.3694\n",
      "val Loss: 14.4879\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 19.3642\n",
      "val Loss: 14.5291\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 19.3616\n",
      "val Loss: 14.5616\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 19.3538\n",
      "val Loss: 14.5696\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 19.3483\n",
      "val Loss: 14.5609\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 19.3315\n",
      "val Loss: 14.3758\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 19.3128\n",
      "val Loss: 14.3646\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 19.2997\n",
      "val Loss: 14.3752\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 19.2900\n",
      "val Loss: 14.3769\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 19.2732\n",
      "val Loss: 14.3696\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 19.2384\n",
      "val Loss: 14.3487\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 19.2317\n",
      "val Loss: 14.3790\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 19.2048\n",
      "val Loss: 14.3380\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 19.1806\n",
      "val Loss: 14.3276\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 19.1513\n",
      "val Loss: 14.2930\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 19.1248\n",
      "val Loss: 14.2610\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 19.0947\n",
      "val Loss: 14.2416\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 19.0503\n",
      "val Loss: 14.1987\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 18.9866\n",
      "val Loss: 14.0443\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 18.9317\n",
      "val Loss: 13.9505\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 18.8182\n",
      "val Loss: 13.8970\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 18.7312\n",
      "val Loss: 13.8860\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 18.6275\n",
      "val Loss: 13.8560\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 18.5486\n",
      "val Loss: 13.7623\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 18.4318\n",
      "val Loss: 13.7766\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 18.3177\n",
      "val Loss: 13.7110\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 18.1632\n",
      "val Loss: 13.6430\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 17.9902\n",
      "val Loss: 13.5794\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 17.8584\n",
      "val Loss: 13.5015\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 17.6197\n",
      "val Loss: 13.5819\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 17.4612\n",
      "val Loss: 13.5083\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 17.2370\n",
      "val Loss: 13.5902\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 16.9900\n",
      "val Loss: 13.5702\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 16.7220\n",
      "val Loss: 13.6288\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 16.3948\n",
      "val Loss: 13.6713\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 16.0342\n",
      "val Loss: 13.7784\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 15.4393\n",
      "val Loss: 13.8261\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 14.3018\n",
      "val Loss: 13.8744\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 14.3087\n",
      "val Loss: 15.3111\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 11.6149\n",
      "val Loss: 16.6535\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 10.4023\n",
      "val Loss: 17.1706\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 11.2995\n",
      "val Loss: 17.8412\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 11.3940\n",
      "val Loss: 16.4504\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 9.6635\n",
      "val Loss: 17.2208\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 9.3099\n",
      "val Loss: 18.0855\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 8.8950\n",
      "val Loss: 18.1751\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 8.4477\n",
      "val Loss: 18.8687\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 8.1157\n",
      "val Loss: 19.3660\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 7.9172\n",
      "val Loss: 19.4104\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 8.1769\n",
      "val Loss: 21.0208\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 7.5049\n",
      "val Loss: 20.9791\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 7.2253\n",
      "val Loss: 21.6953\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 6.5945\n",
      "val Loss: 23.0053\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 6.0672\n",
      "val Loss: 23.6911\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 6.0520\n",
      "val Loss: 24.1620\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 5.2756\n",
      "val Loss: 23.5321\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 4.7825\n",
      "val Loss: 24.0709\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 4.5519\n",
      "val Loss: 25.5406\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 5.7823\n",
      "val Loss: 27.7883\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 4.4849\n",
      "val Loss: 25.5849\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 4.1666\n",
      "val Loss: 26.6095\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 4.1099\n",
      "val Loss: 26.7463\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 3.4089\n",
      "val Loss: 26.4750\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 3.2379\n",
      "val Loss: 27.2603\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 3.8022\n",
      "val Loss: 27.2975\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 3.0276\n",
      "val Loss: 28.8227\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 2.7369\n",
      "val Loss: 29.3002\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 3.9149\n",
      "val Loss: 28.6138\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 3.0072\n",
      "val Loss: 28.8591\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 3.9504\n",
      "val Loss: 26.7995\n",
      "\n",
      "Training complete in 0m 51s\n",
      "Best val MSE: 13.473467\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 2. GRU (w/o data representation)\n",
    "config = config2\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 12.435452461242676, MAE = 2.773865222930908\n",
      "** Dimension of result for test dataset = (42,)\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'** Dimension of result for test dataset = {pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 555.0059\n",
      "val Loss: 109.0806\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 42.7734\n",
      "val Loss: 19.1337\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 41.0078\n",
      "val Loss: 15.5636\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 37.4624\n",
      "val Loss: 14.8062\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 24.0640\n",
      "val Loss: 14.9046\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 29.2808\n",
      "val Loss: 14.5940\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 29.1140\n",
      "val Loss: 15.6754\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 27.6092\n",
      "val Loss: 15.3248\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 30.7468\n",
      "val Loss: 15.7165\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 20.9283\n",
      "val Loss: 15.7559\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 19.6466\n",
      "val Loss: 15.9551\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 20.0110\n",
      "val Loss: 17.1988\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 18.5151\n",
      "val Loss: 16.0409\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 20.4064\n",
      "val Loss: 16.8151\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 19.8867\n",
      "val Loss: 16.5886\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 17.6717\n",
      "val Loss: 17.6459\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 19.0035\n",
      "val Loss: 16.3855\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 18.1048\n",
      "val Loss: 17.7671\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 17.3821\n",
      "val Loss: 17.1699\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 16.0525\n",
      "val Loss: 17.3985\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 17.2557\n",
      "val Loss: 16.9033\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 17.8090\n",
      "val Loss: 18.1819\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 17.8747\n",
      "val Loss: 18.8890\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 16.0577\n",
      "val Loss: 18.9857\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 17.2152\n",
      "val Loss: 17.5184\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 16.1319\n",
      "val Loss: 19.5190\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 12.8397\n",
      "val Loss: 18.5670\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 15.1004\n",
      "val Loss: 18.3409\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 15.4717\n",
      "val Loss: 19.0157\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 13.2881\n",
      "val Loss: 19.7815\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 13.4759\n",
      "val Loss: 19.2804\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 13.1980\n",
      "val Loss: 19.7820\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 13.5442\n",
      "val Loss: 18.7694\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 14.4478\n",
      "val Loss: 20.0204\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 12.0844\n",
      "val Loss: 19.5993\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 13.0346\n",
      "val Loss: 18.9168\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 13.2133\n",
      "val Loss: 20.3233\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 13.3213\n",
      "val Loss: 19.7138\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 13.0863\n",
      "val Loss: 19.5253\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 12.7726\n",
      "val Loss: 22.0314\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 12.2210\n",
      "val Loss: 21.0305\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 12.7922\n",
      "val Loss: 19.0287\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 11.6126\n",
      "val Loss: 19.9477\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 10.8970\n",
      "val Loss: 21.0548\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 12.1716\n",
      "val Loss: 22.0941\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 12.2536\n",
      "val Loss: 22.3655\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 10.3120\n",
      "val Loss: 21.1971\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 11.1759\n",
      "val Loss: 20.9482\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 10.9824\n",
      "val Loss: 21.7182\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 10.6022\n",
      "val Loss: 20.1725\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 9.7508\n",
      "val Loss: 22.2346\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 10.6889\n",
      "val Loss: 23.3253\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 10.8770\n",
      "val Loss: 22.8928\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 10.1429\n",
      "val Loss: 22.5965\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 10.1168\n",
      "val Loss: 22.1137\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 9.4067\n",
      "val Loss: 20.5207\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 9.4891\n",
      "val Loss: 25.5947\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 8.0958\n",
      "val Loss: 20.5999\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 10.7243\n",
      "val Loss: 22.2357\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 9.5101\n",
      "val Loss: 20.1804\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 9.1366\n",
      "val Loss: 22.4583\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 7.6495\n",
      "val Loss: 22.4533\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 8.0126\n",
      "val Loss: 24.3499\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 8.3610\n",
      "val Loss: 23.4962\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 8.4374\n",
      "val Loss: 26.1860\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 8.0787\n",
      "val Loss: 22.4267\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 7.6522\n",
      "val Loss: 23.4851\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 8.5770\n",
      "val Loss: 23.0228\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 8.8912\n",
      "val Loss: 21.9717\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 7.1696\n",
      "val Loss: 23.5663\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 8.5033\n",
      "val Loss: 24.5067\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 6.2606\n",
      "val Loss: 25.1551\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 6.3754\n",
      "val Loss: 23.1733\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 6.4410\n",
      "val Loss: 21.5729\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 7.5969\n",
      "val Loss: 21.4468\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 5.6540\n",
      "val Loss: 23.8209\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 5.6998\n",
      "val Loss: 24.4293\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 6.8598\n",
      "val Loss: 23.1221\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 6.2056\n",
      "val Loss: 21.8388\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 6.0475\n",
      "val Loss: 23.9532\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 5.5585\n",
      "val Loss: 24.1072\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 5.8177\n",
      "val Loss: 23.6353\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 4.4757\n",
      "val Loss: 25.8336\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 6.2244\n",
      "val Loss: 24.1991\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 5.3184\n",
      "val Loss: 23.0747\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 5.2945\n",
      "val Loss: 24.5983\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 4.8561\n",
      "val Loss: 23.5734\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 5.6439\n",
      "val Loss: 23.2014\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 5.1591\n",
      "val Loss: 24.9217\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 5.0010\n",
      "val Loss: 22.7202\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 3.8643\n",
      "val Loss: 24.7934\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 4.3514\n",
      "val Loss: 22.2226\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 4.8510\n",
      "val Loss: 22.5665\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 4.7554\n",
      "val Loss: 23.3007\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 4.3276\n",
      "val Loss: 22.9997\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 4.5275\n",
      "val Loss: 23.2608\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 4.1675\n",
      "val Loss: 25.4870\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 3.9097\n",
      "val Loss: 21.9997\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 3.2376\n",
      "val Loss: 22.4619\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 4.4503\n",
      "val Loss: 25.2646\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 3.9048\n",
      "val Loss: 22.6197\n",
      "\n",
      "Training complete in 0m 9s\n",
      "Best val MSE: 14.505277\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 3. CNN_1D (w/o data representation)\n",
    "config = config3\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 12.220710754394531, MAE = 2.7250516414642334\n",
      "** Dimension of result for test dataset = (42,)\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'** Dimension of result for test dataset = {pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 227.9608\n",
      "val Loss: 187.8042\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 214.2792\n",
      "val Loss: 186.4743\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 182.9382\n",
      "val Loss: 150.9421\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 153.0073\n",
      "val Loss: 124.5707\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 131.3564\n",
      "val Loss: 103.7000\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 115.0392\n",
      "val Loss: 85.5239\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 102.1320\n",
      "val Loss: 76.8003\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 91.6300\n",
      "val Loss: 68.4533\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 83.4663\n",
      "val Loss: 60.1736\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 76.6745\n",
      "val Loss: 55.9470\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 70.6409\n",
      "val Loss: 45.8753\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 65.1769\n",
      "val Loss: 43.7059\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 60.3001\n",
      "val Loss: 45.1425\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 55.8308\n",
      "val Loss: 41.9959\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 51.9045\n",
      "val Loss: 40.7986\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 48.1885\n",
      "val Loss: 38.0941\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 44.3104\n",
      "val Loss: 30.1289\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 41.1139\n",
      "val Loss: 29.6885\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 37.9464\n",
      "val Loss: 30.8677\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 35.6450\n",
      "val Loss: 25.6090\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 33.1901\n",
      "val Loss: 18.2841\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 30.3937\n",
      "val Loss: 22.5936\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 28.7012\n",
      "val Loss: 17.0451\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 26.3572\n",
      "val Loss: 22.6850\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 24.5925\n",
      "val Loss: 14.1376\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 22.8001\n",
      "val Loss: 17.4403\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 22.3809\n",
      "val Loss: 34.1817\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 19.7962\n",
      "val Loss: 19.8490\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 18.5485\n",
      "val Loss: 15.3856\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 17.5841\n",
      "val Loss: 17.4979\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 16.3683\n",
      "val Loss: 15.3776\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 15.7017\n",
      "val Loss: 16.4676\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 16.1779\n",
      "val Loss: 17.4856\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 13.4146\n",
      "val Loss: 16.2212\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 13.3091\n",
      "val Loss: 17.2445\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 12.9023\n",
      "val Loss: 14.1466\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 11.6864\n",
      "val Loss: 15.0168\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 11.2094\n",
      "val Loss: 14.8085\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 10.4339\n",
      "val Loss: 19.9609\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 9.9561\n",
      "val Loss: 16.4539\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 9.7368\n",
      "val Loss: 16.3163\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 9.2808\n",
      "val Loss: 14.0990\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 8.8887\n",
      "val Loss: 14.4861\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 8.8727\n",
      "val Loss: 62.8943\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 8.7852\n",
      "val Loss: 15.2272\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 8.3223\n",
      "val Loss: 17.4518\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 8.0988\n",
      "val Loss: 56.5624\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 7.4317\n",
      "val Loss: 14.6852\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 7.2580\n",
      "val Loss: 17.3928\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 6.8595\n",
      "val Loss: 17.3747\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 6.4011\n",
      "val Loss: 15.9819\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 5.8482\n",
      "val Loss: 22.2949\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 5.6212\n",
      "val Loss: 15.8071\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 7.0074\n",
      "val Loss: 16.2104\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 5.2127\n",
      "val Loss: 19.7917\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 5.3465\n",
      "val Loss: 24.3303\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 6.0712\n",
      "val Loss: 18.3128\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 4.6516\n",
      "val Loss: 16.5351\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 4.4670\n",
      "val Loss: 15.8466\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 4.3837\n",
      "val Loss: 20.2222\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 4.9071\n",
      "val Loss: 43.1842\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 4.5012\n",
      "val Loss: 70.4335\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 4.6933\n",
      "val Loss: 56.6356\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 3.4955\n",
      "val Loss: 18.0145\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 4.7703\n",
      "val Loss: 15.0450\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 4.1981\n",
      "val Loss: 15.5353\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 3.0456\n",
      "val Loss: 22.9250\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 3.0796\n",
      "val Loss: 18.0551\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 2.9834\n",
      "val Loss: 15.6576\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 2.6928\n",
      "val Loss: 25.3806\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 3.5216\n",
      "val Loss: 21.1522\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 4.2368\n",
      "val Loss: 18.2403\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 3.1565\n",
      "val Loss: 17.4412\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 2.0023\n",
      "val Loss: 35.5663\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 3.1501\n",
      "val Loss: 19.6653\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 3.4409\n",
      "val Loss: 30.4896\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 2.7559\n",
      "val Loss: 33.8991\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 2.7078\n",
      "val Loss: 21.1730\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 2.2649\n",
      "val Loss: 22.7456\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 2.4417\n",
      "val Loss: 28.1449\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 2.0209\n",
      "val Loss: 17.6869\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 1.5526\n",
      "val Loss: 32.1106\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 3.5845\n",
      "val Loss: 62.3966\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 3.3549\n",
      "val Loss: 118.0276\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 2.9529\n",
      "val Loss: 16.2406\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 1.9605\n",
      "val Loss: 21.7770\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 1.8109\n",
      "val Loss: 18.4717\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 2.8326\n",
      "val Loss: 22.3114\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 1.6442\n",
      "val Loss: 23.4258\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 1.4500\n",
      "val Loss: 20.4205\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 0.7616\n",
      "val Loss: 23.4132\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 0.7575\n",
      "val Loss: 19.6473\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 1.0087\n",
      "val Loss: 16.1272\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 2.0761\n",
      "val Loss: 22.4274\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 1.5752\n",
      "val Loss: 18.5250\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 1.3033\n",
      "val Loss: 61.6075\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 1.4871\n",
      "val Loss: 19.1164\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 1.1591\n",
      "val Loss: 17.1060\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 0.9571\n",
      "val Loss: 16.9370\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 1.4913\n",
      "val Loss: 18.4170\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 1.2885\n",
      "val Loss: 46.7382\n",
      "\n",
      "Training complete in 0m 47s\n",
      "Best val MSE: 12.419332\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 4. LSTM_FCNs (w/o data representation)\n",
    "config = config4\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 14.570467948913574, MAE = 2.9160358905792236\n",
      "** Dimension of result for test dataset = (42,)\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'** Dimension of result for test dataset = {pred.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 64)\n",
      "(95,)\n",
      "(42, 64)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "# representation data\n",
    "train_x = pd.read_csv('./data/ts2vec_repr_train.csv')\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "\n",
    "test_x = pd.read_csv('./data/ts2vec_repr_test.csv')\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x representation_dims) = (95, 64)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (95, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x representation_dims) = (42, 64)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (42, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 230.7502\n",
      "val Loss: 195.8775\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 212.3306\n",
      "val Loss: 181.2488\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 192.4345\n",
      "val Loss: 164.4762\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 165.8161\n",
      "val Loss: 140.7580\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 137.7342\n",
      "val Loss: 114.9524\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 114.6146\n",
      "val Loss: 91.1035\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 87.3861\n",
      "val Loss: 70.2700\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 70.0523\n",
      "val Loss: 52.8536\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 57.3371\n",
      "val Loss: 39.0701\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 41.9194\n",
      "val Loss: 28.8224\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 36.1336\n",
      "val Loss: 21.8171\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 33.4344\n",
      "val Loss: 17.3724\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 28.2753\n",
      "val Loss: 14.7237\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 24.4812\n",
      "val Loss: 13.3183\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 22.3405\n",
      "val Loss: 12.4961\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 23.7632\n",
      "val Loss: 12.0579\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 24.7017\n",
      "val Loss: 11.8135\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 24.6635\n",
      "val Loss: 11.6641\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 26.6737\n",
      "val Loss: 11.5822\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 23.1612\n",
      "val Loss: 11.5177\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 22.5634\n",
      "val Loss: 11.4738\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 21.7504\n",
      "val Loss: 11.4571\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 23.7032\n",
      "val Loss: 11.4445\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 23.6962\n",
      "val Loss: 11.4332\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 22.4368\n",
      "val Loss: 11.4384\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 22.1944\n",
      "val Loss: 11.4374\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 22.1023\n",
      "val Loss: 11.4487\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 18.1272\n",
      "val Loss: 11.4750\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 22.7817\n",
      "val Loss: 11.5075\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 22.7932\n",
      "val Loss: 11.5260\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 19.8784\n",
      "val Loss: 11.5413\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 20.7964\n",
      "val Loss: 11.5637\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 23.0108\n",
      "val Loss: 11.5746\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 20.1866\n",
      "val Loss: 11.6114\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 22.7330\n",
      "val Loss: 11.6306\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 21.0295\n",
      "val Loss: 11.6604\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 20.5405\n",
      "val Loss: 11.6647\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 22.7776\n",
      "val Loss: 11.6996\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 22.0866\n",
      "val Loss: 11.7387\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 19.8328\n",
      "val Loss: 11.7595\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 20.0705\n",
      "val Loss: 11.7930\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 19.4975\n",
      "val Loss: 11.8115\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 19.1771\n",
      "val Loss: 11.8330\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 20.9999\n",
      "val Loss: 11.8553\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 20.4723\n",
      "val Loss: 11.8753\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 20.8714\n",
      "val Loss: 11.9203\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 21.3522\n",
      "val Loss: 11.9298\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 18.2848\n",
      "val Loss: 11.9605\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 21.6016\n",
      "val Loss: 12.0096\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 19.5476\n",
      "val Loss: 12.0467\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 18.2058\n",
      "val Loss: 12.1070\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 19.9165\n",
      "val Loss: 12.1133\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 20.3429\n",
      "val Loss: 12.1214\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 22.1939\n",
      "val Loss: 12.1431\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 17.4962\n",
      "val Loss: 12.1644\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 19.3950\n",
      "val Loss: 12.1949\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 19.9721\n",
      "val Loss: 12.2044\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 18.4691\n",
      "val Loss: 12.2256\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 20.6382\n",
      "val Loss: 12.2837\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 19.5603\n",
      "val Loss: 12.3549\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 20.9236\n",
      "val Loss: 12.3616\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 18.1574\n",
      "val Loss: 12.3947\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 18.1543\n",
      "val Loss: 12.4252\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 19.5565\n",
      "val Loss: 12.4244\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 17.3905\n",
      "val Loss: 12.4453\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 17.0471\n",
      "val Loss: 12.4686\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 18.5307\n",
      "val Loss: 12.4867\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 17.4900\n",
      "val Loss: 12.4759\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 17.9332\n",
      "val Loss: 12.5368\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 18.4508\n",
      "val Loss: 12.5945\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 17.2855\n",
      "val Loss: 12.6433\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 18.2128\n",
      "val Loss: 12.6363\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 16.6907\n",
      "val Loss: 12.7143\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 18.3501\n",
      "val Loss: 12.7099\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 18.0234\n",
      "val Loss: 12.7567\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 16.4879\n",
      "val Loss: 12.7951\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 17.1324\n",
      "val Loss: 12.8237\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 18.5782\n",
      "val Loss: 12.8799\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 16.7342\n",
      "val Loss: 12.9263\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 16.4448\n",
      "val Loss: 12.9670\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 17.2502\n",
      "val Loss: 12.9209\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 16.7568\n",
      "val Loss: 13.0070\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 18.1609\n",
      "val Loss: 12.9763\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 17.0830\n",
      "val Loss: 12.9807\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 18.5745\n",
      "val Loss: 12.9999\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 16.2276\n",
      "val Loss: 13.0546\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 17.0021\n",
      "val Loss: 13.1307\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 15.2579\n",
      "val Loss: 13.1557\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 17.3327\n",
      "val Loss: 13.1451\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 15.9873\n",
      "val Loss: 13.2524\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 17.6619\n",
      "val Loss: 13.2542\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 15.7114\n",
      "val Loss: 13.2716\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 15.4914\n",
      "val Loss: 13.3504\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 14.3933\n",
      "val Loss: 13.3356\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 15.2561\n",
      "val Loss: 13.3396\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 15.1682\n",
      "val Loss: 13.3956\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 15.4758\n",
      "val Loss: 13.4029\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 15.7242\n",
      "val Loss: 13.4764\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 16.4518\n",
      "val Loss: 13.4885\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 15.3100\n",
      "val Loss: 13.5267\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 14.7892\n",
      "val Loss: 13.5250\n",
      "\n",
      "Training complete in 0m 6s\n",
      "Best val MSE: 11.431566\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config = config5\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 15.044198036193848, MAE = 3.089829921722412\n",
      "** Dimension of result for test dataset = (42,)\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'** Dimension of result for test dataset = {pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "iitp_time_serise",
   "language": "python",
   "name": "iitp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
