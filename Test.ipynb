{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ee0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import main_regression as mr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f1420",
   "metadata": {},
   "source": [
    "# Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc2671e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a339ffef",
   "metadata": {},
   "source": [
    "# Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b2449b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config1 = {\n",
    "        'model': 'LSTM', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 144, # timestep = window_size\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'shift_size' : 1,\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 2000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0003,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False,\n",
    "            'shift_size' : 1,\n",
    "\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 2. GRU model (w/o data representation)\n",
    "config2 = {\n",
    "        'model': 'GRU', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'with_representation' : False, # representation 유무, bool (defeault: False)\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 144, # timestep = window_size\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 16,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 2000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0003,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False,\n",
    "            'shift_size' : 1,\n",
    "\n",
    "\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 3. CNN_1D model (w/o data representation)\n",
    "config3 = {\n",
    "        'model': 'CNN_1D', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/cnn_1d.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 144, # timestep = window_size\n",
    "            'seq_len': 144,  # 데이터의 시간 길이, int\n",
    "            'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "            'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "            'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "            'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 2000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0003,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택4\n",
    "            'need_yhist' : False,\n",
    "            'shift_size' : 1,\n",
    "\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 4. LSTM_FCNs model (w/o data representation)\n",
    "config4 = {\n",
    "        'model': 'LSTM_FCNs', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm_fcn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'timestep' : 144, # timestep = window_size\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "            'lstm_drop_out': 0.001, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "            'fc_drop_out': 0.001, # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 2000, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0003,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False,\n",
    "            'shift_size' : 1,\n",
    "\n",
    "\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config5 = {\n",
    "        'model': 'FC', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC', 'DARNN} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/fc.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 144,  # 데이터의 변수 개수(representation 차원), int\n",
    "            'timestep' : 1, # timestep = window_size\n",
    "            'shift_size': 1, # shift 정도, int\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bias': True, # bias 사용 여부, bool(default: True)\n",
    "            'num_epochs': 2000, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda',  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'need_yhist' : False\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dda35a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "442273ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 24, 144)\n",
      "(95,)\n",
      "(42, 24, 144)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "# raw time series data\n",
    "train_x = pickle.load(open('./data/x_train_new_energy.pkl', 'rb'))\n",
    "train_y = pickle.load(open('./data/y_train_new_energy.pkl', 'rb'))\n",
    "test_x = pickle.load(open('./data/x_test_new_energy.pkl', 'rb'))\n",
    "test_y = pickle.load(open('./data/y_test_new_energy.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (95, 24, 144)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (95,)\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (42, 24, 144)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (42,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c8980",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f513ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/2000\n",
      "train Loss: 222.6936\n",
      "val Loss: 187.7219\n",
      "\n",
      "Epoch 10/2000\n",
      "train Loss: 165.4655\n",
      "val Loss: 131.8825\n",
      "\n",
      "Epoch 20/2000\n",
      "train Loss: 94.9833\n",
      "val Loss: 70.5002\n",
      "\n",
      "Epoch 30/2000\n",
      "train Loss: 57.2592\n",
      "val Loss: 39.0989\n",
      "\n",
      "Epoch 40/2000\n",
      "train Loss: 37.1636\n",
      "val Loss: 23.5779\n",
      "\n",
      "Epoch 50/2000\n",
      "train Loss: 26.9331\n",
      "val Loss: 16.6143\n",
      "\n",
      "Epoch 60/2000\n",
      "train Loss: 22.3273\n",
      "val Loss: 14.1925\n",
      "\n",
      "Epoch 70/2000\n",
      "train Loss: 20.4854\n",
      "val Loss: 13.7292\n",
      "\n",
      "Epoch 80/2000\n",
      "train Loss: 19.7527\n",
      "val Loss: 13.8964\n",
      "\n",
      "Epoch 90/2000\n",
      "train Loss: 19.4778\n",
      "val Loss: 14.1848\n",
      "\n",
      "Epoch 100/2000\n",
      "train Loss: 19.4023\n",
      "val Loss: 14.4099\n",
      "\n",
      "Epoch 110/2000\n",
      "train Loss: 19.3856\n",
      "val Loss: 14.5618\n",
      "\n",
      "Epoch 120/2000\n",
      "train Loss: 19.3693\n",
      "val Loss: 14.6043\n",
      "\n",
      "Epoch 130/2000\n",
      "train Loss: 19.3616\n",
      "val Loss: 14.6482\n",
      "\n",
      "Epoch 140/2000\n",
      "train Loss: 19.3636\n",
      "val Loss: 14.6680\n",
      "\n",
      "Epoch 150/2000\n",
      "train Loss: 19.3577\n",
      "val Loss: 14.6775\n",
      "\n",
      "Epoch 160/2000\n",
      "train Loss: 19.3554\n",
      "val Loss: 14.6804\n",
      "\n",
      "Epoch 170/2000\n",
      "train Loss: 19.3498\n",
      "val Loss: 14.6825\n",
      "\n",
      "Epoch 180/2000\n",
      "train Loss: 19.3494\n",
      "val Loss: 14.6995\n",
      "\n",
      "Epoch 190/2000\n",
      "train Loss: 19.3465\n",
      "val Loss: 14.6766\n",
      "\n",
      "Epoch 200/2000\n",
      "train Loss: 19.3344\n",
      "val Loss: 14.6072\n",
      "\n",
      "Epoch 210/2000\n",
      "train Loss: 19.2906\n",
      "val Loss: 14.5606\n",
      "\n",
      "Epoch 220/2000\n",
      "train Loss: 19.2700\n",
      "val Loss: 14.4898\n",
      "\n",
      "Epoch 230/2000\n",
      "train Loss: 19.2405\n",
      "val Loss: 14.5797\n",
      "\n",
      "Epoch 240/2000\n",
      "train Loss: 19.2699\n",
      "val Loss: 14.5109\n",
      "\n",
      "Epoch 250/2000\n",
      "train Loss: 19.1445\n",
      "val Loss: 14.5224\n",
      "\n",
      "Epoch 260/2000\n",
      "train Loss: 19.1064\n",
      "val Loss: 14.3168\n",
      "\n",
      "Epoch 270/2000\n",
      "train Loss: 18.9533\n",
      "val Loss: 14.2080\n",
      "\n",
      "Epoch 280/2000\n",
      "train Loss: 18.9296\n",
      "val Loss: 14.2077\n",
      "\n",
      "Epoch 290/2000\n",
      "train Loss: 18.7018\n",
      "val Loss: 14.3185\n",
      "\n",
      "Epoch 300/2000\n",
      "train Loss: 18.2069\n",
      "val Loss: 15.1488\n",
      "\n",
      "Epoch 310/2000\n",
      "train Loss: 19.1528\n",
      "val Loss: 16.5346\n",
      "\n",
      "Epoch 320/2000\n",
      "train Loss: 18.4658\n",
      "val Loss: 14.1874\n",
      "\n",
      "Epoch 330/2000\n",
      "train Loss: 18.0128\n",
      "val Loss: 14.6809\n",
      "\n",
      "Epoch 340/2000\n",
      "train Loss: 16.4026\n",
      "val Loss: 13.6720\n",
      "\n",
      "Epoch 350/2000\n",
      "train Loss: 17.6502\n",
      "val Loss: 15.1043\n",
      "\n",
      "Epoch 360/2000\n",
      "train Loss: 15.2445\n",
      "val Loss: 13.7779\n",
      "\n",
      "Epoch 370/2000\n",
      "train Loss: 16.9169\n",
      "val Loss: 15.4375\n",
      "\n",
      "Epoch 380/2000\n",
      "train Loss: 18.9103\n",
      "val Loss: 20.9984\n",
      "\n",
      "Epoch 390/2000\n",
      "train Loss: 14.0121\n",
      "val Loss: 11.3852\n",
      "\n",
      "Epoch 400/2000\n",
      "train Loss: 16.6196\n",
      "val Loss: 16.1885\n",
      "\n",
      "Epoch 410/2000\n",
      "train Loss: 14.2382\n",
      "val Loss: 15.6161\n",
      "\n",
      "Epoch 420/2000\n",
      "train Loss: 16.7204\n",
      "val Loss: 15.1077\n",
      "\n",
      "Epoch 430/2000\n",
      "train Loss: 12.7081\n",
      "val Loss: 15.5435\n",
      "\n",
      "Epoch 440/2000\n",
      "train Loss: 11.5297\n",
      "val Loss: 15.7641\n",
      "\n",
      "Epoch 450/2000\n",
      "train Loss: 12.0272\n",
      "val Loss: 16.4915\n",
      "\n",
      "Epoch 460/2000\n",
      "train Loss: 14.9781\n",
      "val Loss: 16.2579\n",
      "\n",
      "Epoch 470/2000\n",
      "train Loss: 12.6403\n",
      "val Loss: 18.6563\n",
      "\n",
      "Epoch 480/2000\n",
      "train Loss: 10.7790\n",
      "val Loss: 19.6247\n",
      "\n",
      "Epoch 490/2000\n",
      "train Loss: 10.5671\n",
      "val Loss: 22.9632\n",
      "\n",
      "Epoch 500/2000\n",
      "train Loss: 11.2994\n",
      "val Loss: 17.4746\n",
      "\n",
      "Epoch 510/2000\n",
      "train Loss: 10.3180\n",
      "val Loss: 17.6480\n",
      "\n",
      "Epoch 520/2000\n",
      "train Loss: 17.2632\n",
      "val Loss: 15.0977\n",
      "\n",
      "Epoch 530/2000\n",
      "train Loss: 14.5406\n",
      "val Loss: 15.1999\n",
      "\n",
      "Epoch 540/2000\n",
      "train Loss: 37.1097\n",
      "val Loss: 22.2907\n",
      "\n",
      "Epoch 550/2000\n",
      "train Loss: 19.3722\n",
      "val Loss: 15.0285\n",
      "\n",
      "Epoch 560/2000\n",
      "train Loss: 19.2979\n",
      "val Loss: 14.7918\n",
      "\n",
      "Epoch 570/2000\n",
      "train Loss: 19.2989\n",
      "val Loss: 14.6402\n",
      "\n",
      "Epoch 580/2000\n",
      "train Loss: 19.2369\n",
      "val Loss: 14.8329\n",
      "\n",
      "Epoch 590/2000\n",
      "train Loss: 19.1320\n",
      "val Loss: 14.9067\n",
      "\n",
      "Epoch 600/2000\n",
      "train Loss: 19.0381\n",
      "val Loss: 14.7395\n",
      "\n",
      "Epoch 610/2000\n",
      "train Loss: 19.1060\n",
      "val Loss: 14.5933\n",
      "\n",
      "Epoch 620/2000\n",
      "train Loss: 18.7373\n",
      "val Loss: 15.4692\n",
      "\n",
      "Epoch 630/2000\n",
      "train Loss: 18.4411\n",
      "val Loss: 15.8495\n",
      "\n",
      "Epoch 640/2000\n",
      "train Loss: 18.5356\n",
      "val Loss: 15.7282\n",
      "\n",
      "Epoch 650/2000\n",
      "train Loss: 18.4502\n",
      "val Loss: 15.5922\n",
      "\n",
      "Epoch 660/2000\n",
      "train Loss: 18.4011\n",
      "val Loss: 15.8883\n",
      "\n",
      "Epoch 670/2000\n",
      "train Loss: 19.7052\n",
      "val Loss: 14.5710\n",
      "\n",
      "Epoch 680/2000\n",
      "train Loss: 18.9277\n",
      "val Loss: 15.2379\n",
      "\n",
      "Epoch 690/2000\n",
      "train Loss: 18.8679\n",
      "val Loss: 15.3163\n",
      "\n",
      "Epoch 700/2000\n",
      "train Loss: 18.8376\n",
      "val Loss: 15.3476\n",
      "\n",
      "Epoch 710/2000\n",
      "train Loss: 18.5969\n",
      "val Loss: 16.1536\n",
      "\n",
      "Epoch 720/2000\n",
      "train Loss: 18.6483\n",
      "val Loss: 16.3094\n",
      "\n",
      "Epoch 730/2000\n",
      "train Loss: 18.2613\n",
      "val Loss: 17.4212\n",
      "\n",
      "Epoch 740/2000\n",
      "train Loss: 18.8319\n",
      "val Loss: 16.7933\n",
      "\n",
      "Epoch 750/2000\n",
      "train Loss: 18.3221\n",
      "val Loss: 16.3401\n",
      "\n",
      "Epoch 760/2000\n",
      "train Loss: 18.2802\n",
      "val Loss: 16.9793\n",
      "\n",
      "Epoch 770/2000\n",
      "train Loss: 18.5373\n",
      "val Loss: 16.5830\n",
      "\n",
      "Epoch 780/2000\n",
      "train Loss: 19.0566\n",
      "val Loss: 16.0152\n",
      "\n",
      "Epoch 790/2000\n",
      "train Loss: 18.8363\n",
      "val Loss: 15.8560\n",
      "\n",
      "Epoch 800/2000\n",
      "train Loss: 18.6527\n",
      "val Loss: 17.0390\n",
      "\n",
      "Epoch 810/2000\n",
      "train Loss: 18.0878\n",
      "val Loss: 16.4307\n",
      "\n",
      "Epoch 820/2000\n",
      "train Loss: 18.9087\n",
      "val Loss: 18.5704\n",
      "\n",
      "Epoch 830/2000\n",
      "train Loss: 17.5484\n",
      "val Loss: 15.7392\n",
      "\n",
      "Epoch 840/2000\n",
      "train Loss: 20.3078\n",
      "val Loss: 21.3896\n",
      "\n",
      "Epoch 850/2000\n",
      "train Loss: 18.8776\n",
      "val Loss: 15.0768\n",
      "\n",
      "Epoch 860/2000\n",
      "train Loss: 18.3756\n",
      "val Loss: 18.7097\n",
      "\n",
      "Epoch 870/2000\n",
      "train Loss: 17.6638\n",
      "val Loss: 17.6734\n",
      "\n",
      "Epoch 880/2000\n",
      "train Loss: 19.2747\n",
      "val Loss: 16.3935\n",
      "\n",
      "Epoch 890/2000\n",
      "train Loss: 18.6303\n",
      "val Loss: 16.4652\n",
      "\n",
      "Epoch 900/2000\n",
      "train Loss: 17.9207\n",
      "val Loss: 16.2124\n",
      "\n",
      "Epoch 910/2000\n",
      "train Loss: 18.3224\n",
      "val Loss: 16.2755\n",
      "\n",
      "Epoch 920/2000\n",
      "train Loss: 17.6238\n",
      "val Loss: 16.8570\n",
      "\n",
      "Epoch 930/2000\n",
      "train Loss: 21.3151\n",
      "val Loss: 18.2473\n",
      "\n",
      "Epoch 940/2000\n",
      "train Loss: 19.3163\n",
      "val Loss: 14.4656\n",
      "\n",
      "Epoch 950/2000\n",
      "train Loss: 19.3027\n",
      "val Loss: 14.6398\n",
      "\n",
      "Epoch 960/2000\n",
      "train Loss: 19.2160\n",
      "val Loss: 14.7781\n",
      "\n",
      "Epoch 970/2000\n",
      "train Loss: 19.0999\n",
      "val Loss: 14.6323\n",
      "\n",
      "Epoch 980/2000\n",
      "train Loss: 19.2680\n",
      "val Loss: 14.9053\n",
      "\n",
      "Epoch 990/2000\n",
      "train Loss: 18.6715\n",
      "val Loss: 14.7606\n",
      "\n",
      "Epoch 1000/2000\n",
      "train Loss: 18.4736\n",
      "val Loss: 15.7539\n",
      "\n",
      "Epoch 1010/2000\n",
      "train Loss: 18.7567\n",
      "val Loss: 15.3233\n",
      "\n",
      "Epoch 1020/2000\n",
      "train Loss: 18.5348\n",
      "val Loss: 15.8764\n",
      "\n",
      "Epoch 1030/2000\n",
      "train Loss: 18.5211\n",
      "val Loss: 16.4545\n",
      "\n",
      "Epoch 1040/2000\n",
      "train Loss: 16.4531\n",
      "val Loss: 18.0216\n",
      "\n",
      "Epoch 1050/2000\n",
      "train Loss: 15.4388\n",
      "val Loss: 17.0154\n",
      "\n",
      "Epoch 1060/2000\n",
      "train Loss: 16.0470\n",
      "val Loss: 17.1320\n",
      "\n",
      "Epoch 1070/2000\n",
      "train Loss: 15.3004\n",
      "val Loss: 19.2345\n",
      "\n",
      "Epoch 1080/2000\n",
      "train Loss: 13.2226\n",
      "val Loss: 18.3274\n",
      "\n",
      "Epoch 1090/2000\n",
      "train Loss: 12.4162\n",
      "val Loss: 21.0307\n",
      "\n",
      "Epoch 1100/2000\n",
      "train Loss: 17.1750\n",
      "val Loss: 14.6647\n",
      "\n",
      "Epoch 1110/2000\n",
      "train Loss: 14.1107\n",
      "val Loss: 20.6272\n",
      "\n",
      "Epoch 1120/2000\n",
      "train Loss: 18.8655\n",
      "val Loss: 19.8107\n",
      "\n",
      "Epoch 1130/2000\n",
      "train Loss: 15.5032\n",
      "val Loss: 18.4337\n",
      "\n",
      "Epoch 1140/2000\n",
      "train Loss: 12.7728\n",
      "val Loss: 21.5333\n",
      "\n",
      "Epoch 1150/2000\n",
      "train Loss: 11.8573\n",
      "val Loss: 20.1706\n",
      "\n",
      "Epoch 1160/2000\n",
      "train Loss: 21.1021\n",
      "val Loss: 17.1394\n",
      "\n",
      "Epoch 1170/2000\n",
      "train Loss: 19.2867\n",
      "val Loss: 14.6402\n",
      "\n",
      "Epoch 1180/2000\n",
      "train Loss: 19.2818\n",
      "val Loss: 14.4129\n",
      "\n",
      "Epoch 1190/2000\n",
      "train Loss: 19.2671\n",
      "val Loss: 14.5318\n",
      "\n",
      "Epoch 1200/2000\n",
      "train Loss: 19.2594\n",
      "val Loss: 14.5968\n",
      "\n",
      "Epoch 1210/2000\n",
      "train Loss: 19.2853\n",
      "val Loss: 14.5208\n",
      "\n",
      "Epoch 1220/2000\n",
      "train Loss: 19.1914\n",
      "val Loss: 14.3548\n",
      "\n",
      "Epoch 1230/2000\n",
      "train Loss: 19.1291\n",
      "val Loss: 14.3773\n",
      "\n",
      "Epoch 1240/2000\n",
      "train Loss: 19.1311\n",
      "val Loss: 14.1862\n",
      "\n",
      "Epoch 1250/2000\n",
      "train Loss: 19.0084\n",
      "val Loss: 14.2565\n",
      "\n",
      "Epoch 1260/2000\n",
      "train Loss: 18.8604\n",
      "val Loss: 14.0998\n",
      "\n",
      "Epoch 1270/2000\n",
      "train Loss: 18.6260\n",
      "val Loss: 13.9950\n",
      "\n",
      "Epoch 1280/2000\n",
      "train Loss: 18.5412\n",
      "val Loss: 13.6712\n",
      "\n",
      "Epoch 1290/2000\n",
      "train Loss: 18.2049\n",
      "val Loss: 13.5945\n",
      "\n",
      "Epoch 1300/2000\n",
      "train Loss: 18.3853\n",
      "val Loss: 13.6052\n",
      "\n",
      "Epoch 1310/2000\n",
      "train Loss: 18.1229\n",
      "val Loss: 14.0755\n",
      "\n",
      "Epoch 1320/2000\n",
      "train Loss: 17.3871\n",
      "val Loss: 14.2050\n",
      "\n",
      "Epoch 1330/2000\n",
      "train Loss: 17.6526\n",
      "val Loss: 13.8025\n",
      "\n",
      "Epoch 1340/2000\n",
      "train Loss: 18.1302\n",
      "val Loss: 14.2853\n",
      "\n",
      "Epoch 1350/2000\n",
      "train Loss: 17.0986\n",
      "val Loss: 13.8035\n",
      "\n",
      "Epoch 1360/2000\n",
      "train Loss: 16.4748\n",
      "val Loss: 14.6108\n",
      "\n",
      "Epoch 1370/2000\n",
      "train Loss: 16.6583\n",
      "val Loss: 14.7933\n",
      "\n",
      "Epoch 1380/2000\n",
      "train Loss: 17.9293\n",
      "val Loss: 14.9112\n",
      "\n",
      "Epoch 1390/2000\n",
      "train Loss: 17.7158\n",
      "val Loss: 14.7151\n",
      "\n",
      "Epoch 1400/2000\n",
      "train Loss: 13.7427\n",
      "val Loss: 19.3481\n",
      "\n",
      "Epoch 1410/2000\n",
      "train Loss: 13.4901\n",
      "val Loss: 16.8967\n",
      "\n",
      "Epoch 1420/2000\n",
      "train Loss: 13.9275\n",
      "val Loss: 21.5250\n",
      "\n",
      "Epoch 1430/2000\n",
      "train Loss: 12.6035\n",
      "val Loss: 17.9849\n",
      "\n",
      "Epoch 1440/2000\n",
      "train Loss: 14.5388\n",
      "val Loss: 21.3921\n",
      "\n",
      "Epoch 1450/2000\n",
      "train Loss: 12.5590\n",
      "val Loss: 17.7948\n",
      "\n",
      "Epoch 1460/2000\n",
      "train Loss: 9.8639\n",
      "val Loss: 20.8604\n",
      "\n",
      "Epoch 1470/2000\n",
      "train Loss: 8.2973\n",
      "val Loss: 22.3905\n",
      "\n",
      "Epoch 1480/2000\n",
      "train Loss: 9.3045\n",
      "val Loss: 20.3652\n",
      "\n",
      "Epoch 1490/2000\n",
      "train Loss: 25.8719\n",
      "val Loss: 25.5567\n",
      "\n",
      "Epoch 1500/2000\n",
      "train Loss: 15.7727\n",
      "val Loss: 17.3328\n",
      "\n",
      "Epoch 1510/2000\n",
      "train Loss: 14.4576\n",
      "val Loss: 19.5543\n",
      "\n",
      "Epoch 1520/2000\n",
      "train Loss: 13.6124\n",
      "val Loss: 18.9377\n",
      "\n",
      "Epoch 1530/2000\n",
      "train Loss: 12.3966\n",
      "val Loss: 21.1881\n",
      "\n",
      "Epoch 1540/2000\n",
      "train Loss: 12.0391\n",
      "val Loss: 20.1061\n",
      "\n",
      "Epoch 1550/2000\n",
      "train Loss: 10.9310\n",
      "val Loss: 22.3978\n",
      "\n",
      "Epoch 1560/2000\n",
      "train Loss: 11.0931\n",
      "val Loss: 24.6147\n",
      "\n",
      "Epoch 1570/2000\n",
      "train Loss: 8.6990\n",
      "val Loss: 24.7181\n",
      "\n",
      "Epoch 1580/2000\n",
      "train Loss: 8.8474\n",
      "val Loss: 23.8986\n",
      "\n",
      "Epoch 1590/2000\n",
      "train Loss: 10.6460\n",
      "val Loss: 22.6328\n",
      "\n",
      "Epoch 1600/2000\n",
      "train Loss: 7.6655\n",
      "val Loss: 24.2962\n",
      "\n",
      "Epoch 1610/2000\n",
      "train Loss: 10.0380\n",
      "val Loss: 23.9615\n",
      "\n",
      "Epoch 1620/2000\n",
      "train Loss: 10.2012\n",
      "val Loss: 21.9670\n",
      "\n",
      "Epoch 1630/2000\n",
      "train Loss: 9.1217\n",
      "val Loss: 23.2232\n",
      "\n",
      "Epoch 1640/2000\n",
      "train Loss: 10.6945\n",
      "val Loss: 31.1350\n",
      "\n",
      "Epoch 1650/2000\n",
      "train Loss: 8.6845\n",
      "val Loss: 21.1268\n",
      "\n",
      "Epoch 1660/2000\n",
      "train Loss: 8.1566\n",
      "val Loss: 21.5186\n",
      "\n",
      "Epoch 1670/2000\n",
      "train Loss: 6.3567\n",
      "val Loss: 22.0932\n",
      "\n",
      "Epoch 1680/2000\n",
      "train Loss: 10.7300\n",
      "val Loss: 19.1613\n",
      "\n",
      "Epoch 1690/2000\n",
      "train Loss: 5.4663\n",
      "val Loss: 26.9704\n",
      "\n",
      "Epoch 1700/2000\n",
      "train Loss: 5.4157\n",
      "val Loss: 25.8230\n",
      "\n",
      "Epoch 1710/2000\n",
      "train Loss: 6.4339\n",
      "val Loss: 25.3619\n",
      "\n",
      "Epoch 1720/2000\n",
      "train Loss: 17.0625\n",
      "val Loss: 29.0534\n",
      "\n",
      "Epoch 1730/2000\n",
      "train Loss: 11.5890\n",
      "val Loss: 25.9576\n",
      "\n",
      "Epoch 1740/2000\n",
      "train Loss: 9.5337\n",
      "val Loss: 30.9775\n",
      "\n",
      "Epoch 1750/2000\n",
      "train Loss: 7.7587\n",
      "val Loss: 30.6152\n",
      "\n",
      "Epoch 1760/2000\n",
      "train Loss: 6.7758\n",
      "val Loss: 32.4369\n",
      "\n",
      "Epoch 1770/2000\n",
      "train Loss: 12.2289\n",
      "val Loss: 16.4835\n",
      "\n",
      "Epoch 1780/2000\n",
      "train Loss: 5.6715\n",
      "val Loss: 32.4852\n",
      "\n",
      "Epoch 1790/2000\n",
      "train Loss: 5.2192\n",
      "val Loss: 29.5648\n",
      "\n",
      "Epoch 1800/2000\n",
      "train Loss: 4.3346\n",
      "val Loss: 35.2084\n",
      "\n",
      "Epoch 1810/2000\n",
      "train Loss: 4.0109\n",
      "val Loss: 36.7350\n",
      "\n",
      "Epoch 1820/2000\n",
      "train Loss: 10.8244\n",
      "val Loss: 30.0871\n",
      "\n",
      "Epoch 1830/2000\n",
      "train Loss: 4.0803\n",
      "val Loss: 36.7547\n",
      "\n",
      "Epoch 1840/2000\n",
      "train Loss: 3.4649\n",
      "val Loss: 37.5010\n",
      "\n",
      "Epoch 1850/2000\n",
      "train Loss: 4.6902\n",
      "val Loss: 37.4878\n",
      "\n",
      "Epoch 1860/2000\n",
      "train Loss: 2.9556\n",
      "val Loss: 34.9198\n",
      "\n",
      "Epoch 1870/2000\n",
      "train Loss: 2.7697\n",
      "val Loss: 35.2733\n",
      "\n",
      "Epoch 1880/2000\n",
      "train Loss: 3.4263\n",
      "val Loss: 35.9754\n",
      "\n",
      "Epoch 1890/2000\n",
      "train Loss: 2.0265\n",
      "val Loss: 35.2622\n",
      "\n",
      "Epoch 1900/2000\n",
      "train Loss: 4.2295\n",
      "val Loss: 32.0523\n",
      "\n",
      "Epoch 1910/2000\n",
      "train Loss: 2.4081\n",
      "val Loss: 36.0172\n",
      "\n",
      "Epoch 1920/2000\n",
      "train Loss: 2.0838\n",
      "val Loss: 38.1388\n",
      "\n",
      "Epoch 1930/2000\n",
      "train Loss: 4.1280\n",
      "val Loss: 35.0023\n",
      "\n",
      "Epoch 1940/2000\n",
      "train Loss: 1.3951\n",
      "val Loss: 39.4099\n",
      "\n",
      "Epoch 1950/2000\n",
      "train Loss: 1.0830\n",
      "val Loss: 36.4787\n",
      "\n",
      "Epoch 1960/2000\n",
      "train Loss: 1.1876\n",
      "val Loss: 39.8265\n",
      "\n",
      "Epoch 1970/2000\n",
      "train Loss: 1.2515\n",
      "val Loss: 38.8902\n",
      "\n",
      "Epoch 1980/2000\n",
      "train Loss: 5.2005\n",
      "val Loss: 35.0189\n",
      "\n",
      "Epoch 1990/2000\n",
      "train Loss: 2.5352\n",
      "val Loss: 36.2517\n",
      "\n",
      "Epoch 2000/2000\n",
      "train Loss: 1.1476\n",
      "val Loss: 39.8864\n",
      "\n",
      "Training complete in 1m 59s\n",
      "Best val Loss: 11.385186\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 15.29853 and R2: -3.8035\n",
      "test RMSE: 3.9113\n"
     ]
    }
   ],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config = config1\n",
    "data_reg = mr.Regression(config, train_data, test_data, use_representation=True)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4929f8ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/2000\n",
      "train Loss: 225.6518\n",
      "val Loss: 191.2764\n",
      "\n",
      "Epoch 10/2000\n",
      "train Loss: 199.6607\n",
      "val Loss: 167.0832\n",
      "\n",
      "Epoch 20/2000\n",
      "train Loss: 171.3232\n",
      "val Loss: 141.0707\n",
      "\n",
      "Epoch 30/2000\n",
      "train Loss: 148.5514\n",
      "val Loss: 120.5289\n",
      "\n",
      "Epoch 40/2000\n",
      "train Loss: 130.3471\n",
      "val Loss: 104.0884\n",
      "\n",
      "Epoch 50/2000\n",
      "train Loss: 114.2071\n",
      "val Loss: 89.6738\n",
      "\n",
      "Epoch 60/2000\n",
      "train Loss: 101.0050\n",
      "val Loss: 78.0037\n",
      "\n",
      "Epoch 70/2000\n",
      "train Loss: 89.8570\n",
      "val Loss: 68.1942\n",
      "\n",
      "Epoch 80/2000\n",
      "train Loss: 80.2721\n",
      "val Loss: 59.8409\n",
      "\n",
      "Epoch 90/2000\n",
      "train Loss: 71.9747\n",
      "val Loss: 52.6845\n",
      "\n",
      "Epoch 100/2000\n",
      "train Loss: 64.7673\n",
      "val Loss: 46.5445\n",
      "\n",
      "Epoch 110/2000\n",
      "train Loss: 58.5368\n",
      "val Loss: 41.3081\n",
      "\n",
      "Epoch 120/2000\n",
      "train Loss: 53.1165\n",
      "val Loss: 36.7847\n",
      "\n",
      "Epoch 130/2000\n",
      "train Loss: 48.3358\n",
      "val Loss: 32.8760\n",
      "\n",
      "Epoch 140/2000\n",
      "train Loss: 44.1963\n",
      "val Loss: 29.5709\n",
      "\n",
      "Epoch 150/2000\n",
      "train Loss: 40.6226\n",
      "val Loss: 26.7376\n",
      "\n",
      "Epoch 160/2000\n",
      "train Loss: 37.5043\n",
      "val Loss: 24.3331\n",
      "\n",
      "Epoch 170/2000\n",
      "train Loss: 34.7614\n",
      "val Loss: 22.2841\n",
      "\n",
      "Epoch 180/2000\n",
      "train Loss: 32.4234\n",
      "val Loss: 20.5569\n",
      "\n",
      "Epoch 190/2000\n",
      "train Loss: 30.3757\n",
      "val Loss: 19.1027\n",
      "\n",
      "Epoch 200/2000\n",
      "train Loss: 28.5954\n",
      "val Loss: 17.9009\n",
      "\n",
      "Epoch 210/2000\n",
      "train Loss: 27.0756\n",
      "val Loss: 16.9063\n",
      "\n",
      "Epoch 220/2000\n",
      "train Loss: 25.8013\n",
      "val Loss: 16.1018\n",
      "\n",
      "Epoch 230/2000\n",
      "train Loss: 24.7007\n",
      "val Loss: 15.4557\n",
      "\n",
      "Epoch 240/2000\n",
      "train Loss: 23.7700\n",
      "val Loss: 14.9402\n",
      "\n",
      "Epoch 250/2000\n",
      "train Loss: 22.9712\n",
      "val Loss: 14.5515\n",
      "\n",
      "Epoch 260/2000\n",
      "train Loss: 22.3002\n",
      "val Loss: 14.2493\n",
      "\n",
      "Epoch 270/2000\n",
      "train Loss: 21.7415\n",
      "val Loss: 14.0313\n",
      "\n",
      "Epoch 280/2000\n",
      "train Loss: 21.2790\n",
      "val Loss: 13.8807\n",
      "\n",
      "Epoch 290/2000\n",
      "train Loss: 20.8868\n",
      "val Loss: 13.7876\n",
      "\n",
      "Epoch 300/2000\n",
      "train Loss: 20.5782\n",
      "val Loss: 13.7403\n",
      "\n",
      "Epoch 310/2000\n",
      "train Loss: 20.3330\n",
      "val Loss: 13.7291\n",
      "\n",
      "Epoch 320/2000\n",
      "train Loss: 20.1278\n",
      "val Loss: 13.7431\n",
      "\n",
      "Epoch 330/2000\n",
      "train Loss: 19.9621\n",
      "val Loss: 13.7774\n",
      "\n",
      "Epoch 340/2000\n",
      "train Loss: 19.8261\n",
      "val Loss: 13.8280\n",
      "\n",
      "Epoch 350/2000\n",
      "train Loss: 19.7254\n",
      "val Loss: 13.8859\n",
      "\n",
      "Epoch 360/2000\n",
      "train Loss: 19.6425\n",
      "val Loss: 13.9503\n",
      "\n",
      "Epoch 370/2000\n",
      "train Loss: 19.5748\n",
      "val Loss: 14.0200\n",
      "\n",
      "Epoch 380/2000\n",
      "train Loss: 19.5305\n",
      "val Loss: 14.0909\n",
      "\n",
      "Epoch 390/2000\n",
      "train Loss: 19.4918\n",
      "val Loss: 14.1465\n",
      "\n",
      "Epoch 400/2000\n",
      "train Loss: 19.4620\n",
      "val Loss: 14.2079\n",
      "\n",
      "Epoch 410/2000\n",
      "train Loss: 19.4394\n",
      "val Loss: 14.2719\n",
      "\n",
      "Epoch 420/2000\n",
      "train Loss: 19.4247\n",
      "val Loss: 14.3253\n",
      "\n",
      "Epoch 430/2000\n",
      "train Loss: 19.4131\n",
      "val Loss: 14.3776\n",
      "\n",
      "Epoch 440/2000\n",
      "train Loss: 19.4045\n",
      "val Loss: 14.4288\n",
      "\n",
      "Epoch 450/2000\n",
      "train Loss: 19.3981\n",
      "val Loss: 14.4627\n",
      "\n",
      "Epoch 460/2000\n",
      "train Loss: 19.3926\n",
      "val Loss: 14.4950\n",
      "\n",
      "Epoch 470/2000\n",
      "train Loss: 19.3881\n",
      "val Loss: 14.5310\n",
      "\n",
      "Epoch 480/2000\n",
      "train Loss: 19.3850\n",
      "val Loss: 14.5557\n",
      "\n",
      "Epoch 490/2000\n",
      "train Loss: 19.3854\n",
      "val Loss: 14.5734\n",
      "\n",
      "Epoch 500/2000\n",
      "train Loss: 19.3841\n",
      "val Loss: 14.5802\n",
      "\n",
      "Epoch 510/2000\n",
      "train Loss: 19.3825\n",
      "val Loss: 14.5930\n",
      "\n",
      "Epoch 520/2000\n",
      "train Loss: 19.3817\n",
      "val Loss: 14.6070\n",
      "\n",
      "Epoch 530/2000\n",
      "train Loss: 19.3814\n",
      "val Loss: 14.6262\n",
      "\n",
      "Epoch 540/2000\n",
      "train Loss: 19.3822\n",
      "val Loss: 14.6439\n",
      "\n",
      "Epoch 550/2000\n",
      "train Loss: 19.3804\n",
      "val Loss: 14.6571\n",
      "\n",
      "Epoch 560/2000\n",
      "train Loss: 19.3804\n",
      "val Loss: 14.6563\n",
      "\n",
      "Epoch 570/2000\n",
      "train Loss: 19.3808\n",
      "val Loss: 14.6649\n",
      "\n",
      "Epoch 580/2000\n",
      "train Loss: 19.3803\n",
      "val Loss: 14.6647\n",
      "\n",
      "Epoch 590/2000\n",
      "train Loss: 19.3812\n",
      "val Loss: 14.6625\n",
      "\n",
      "Epoch 600/2000\n",
      "train Loss: 19.3808\n",
      "val Loss: 14.6717\n",
      "\n",
      "Epoch 610/2000\n",
      "train Loss: 19.3808\n",
      "val Loss: 14.6730\n",
      "\n",
      "Epoch 620/2000\n",
      "train Loss: 19.3800\n",
      "val Loss: 14.6779\n",
      "\n",
      "Epoch 630/2000\n",
      "train Loss: 19.3803\n",
      "val Loss: 14.6785\n",
      "\n",
      "Epoch 640/2000\n",
      "train Loss: 19.3800\n",
      "val Loss: 14.6745\n",
      "\n",
      "Epoch 650/2000\n",
      "train Loss: 19.3797\n",
      "val Loss: 14.6780\n",
      "\n",
      "Epoch 660/2000\n",
      "train Loss: 19.3813\n",
      "val Loss: 14.6972\n",
      "\n",
      "Epoch 670/2000\n",
      "train Loss: 19.3820\n",
      "val Loss: 14.7025\n",
      "\n",
      "Epoch 680/2000\n",
      "train Loss: 19.3798\n",
      "val Loss: 14.7106\n",
      "\n",
      "Epoch 690/2000\n",
      "train Loss: 19.3808\n",
      "val Loss: 14.6908\n",
      "\n",
      "Epoch 700/2000\n",
      "train Loss: 19.3805\n",
      "val Loss: 14.6726\n",
      "\n",
      "Epoch 710/2000\n",
      "train Loss: 19.3810\n",
      "val Loss: 14.6765\n",
      "\n",
      "Epoch 720/2000\n",
      "train Loss: 19.3803\n",
      "val Loss: 14.6951\n",
      "\n",
      "Epoch 730/2000\n",
      "train Loss: 19.3804\n",
      "val Loss: 14.7070\n",
      "\n",
      "Epoch 740/2000\n",
      "train Loss: 19.3837\n",
      "val Loss: 14.6936\n",
      "\n",
      "Epoch 750/2000\n",
      "train Loss: 19.3803\n",
      "val Loss: 14.6940\n",
      "\n",
      "Epoch 760/2000\n",
      "train Loss: 19.3806\n",
      "val Loss: 14.6938\n",
      "\n",
      "Epoch 770/2000\n",
      "train Loss: 19.3795\n",
      "val Loss: 14.6763\n",
      "\n",
      "Epoch 780/2000\n",
      "train Loss: 19.3835\n",
      "val Loss: 14.6998\n",
      "\n",
      "Epoch 790/2000\n",
      "train Loss: 19.3808\n",
      "val Loss: 14.6962\n",
      "\n",
      "Epoch 800/2000\n",
      "train Loss: 19.3795\n",
      "val Loss: 14.6659\n",
      "\n",
      "Epoch 810/2000\n",
      "train Loss: 19.3782\n",
      "val Loss: 14.6481\n",
      "\n",
      "Epoch 820/2000\n",
      "train Loss: 19.3781\n",
      "val Loss: 14.6436\n",
      "\n",
      "Epoch 830/2000\n",
      "train Loss: 19.3751\n",
      "val Loss: 14.6289\n",
      "\n",
      "Epoch 840/2000\n",
      "train Loss: 19.3734\n",
      "val Loss: 14.6470\n",
      "\n",
      "Epoch 850/2000\n",
      "train Loss: 19.3710\n",
      "val Loss: 14.6279\n",
      "\n",
      "Epoch 860/2000\n",
      "train Loss: 19.3710\n",
      "val Loss: 14.6303\n",
      "\n",
      "Epoch 870/2000\n",
      "train Loss: 19.3562\n",
      "val Loss: 14.5845\n",
      "\n",
      "Epoch 880/2000\n",
      "train Loss: 19.3398\n",
      "val Loss: 14.5597\n",
      "\n",
      "Epoch 890/2000\n",
      "train Loss: 19.3389\n",
      "val Loss: 14.5599\n",
      "\n",
      "Epoch 900/2000\n",
      "train Loss: 19.3336\n",
      "val Loss: 14.5884\n",
      "\n",
      "Epoch 910/2000\n",
      "train Loss: 19.3337\n",
      "val Loss: 14.6299\n",
      "\n",
      "Epoch 920/2000\n",
      "train Loss: 19.3275\n",
      "val Loss: 14.6000\n",
      "\n",
      "Epoch 930/2000\n",
      "train Loss: 19.3257\n",
      "val Loss: 14.5997\n",
      "\n",
      "Epoch 940/2000\n",
      "train Loss: 19.3213\n",
      "val Loss: 14.5883\n",
      "\n",
      "Epoch 950/2000\n",
      "train Loss: 19.3153\n",
      "val Loss: 14.5918\n",
      "\n",
      "Epoch 960/2000\n",
      "train Loss: 19.3147\n",
      "val Loss: 14.5931\n",
      "\n",
      "Epoch 970/2000\n",
      "train Loss: 19.3096\n",
      "val Loss: 14.5856\n",
      "\n",
      "Epoch 980/2000\n",
      "train Loss: 19.3093\n",
      "val Loss: 14.5741\n",
      "\n",
      "Epoch 990/2000\n",
      "train Loss: 19.3025\n",
      "val Loss: 14.6074\n",
      "\n",
      "Epoch 1000/2000\n",
      "train Loss: 19.3040\n",
      "val Loss: 14.6035\n",
      "\n",
      "Epoch 1010/2000\n",
      "train Loss: 19.2966\n",
      "val Loss: 14.5617\n",
      "\n",
      "Epoch 1020/2000\n",
      "train Loss: 19.2892\n",
      "val Loss: 14.5421\n",
      "\n",
      "Epoch 1030/2000\n",
      "train Loss: 19.2815\n",
      "val Loss: 14.5262\n",
      "\n",
      "Epoch 1040/2000\n",
      "train Loss: 19.2729\n",
      "val Loss: 14.5392\n",
      "\n",
      "Epoch 1050/2000\n",
      "train Loss: 19.2667\n",
      "val Loss: 14.5652\n",
      "\n",
      "Epoch 1060/2000\n",
      "train Loss: 19.2227\n",
      "val Loss: 14.4724\n",
      "\n",
      "Epoch 1070/2000\n",
      "train Loss: 19.1665\n",
      "val Loss: 14.3368\n",
      "\n",
      "Epoch 1080/2000\n",
      "train Loss: 19.1254\n",
      "val Loss: 14.2490\n",
      "\n",
      "Epoch 1090/2000\n",
      "train Loss: 19.0435\n",
      "val Loss: 14.2298\n",
      "\n",
      "Epoch 1100/2000\n",
      "train Loss: 18.9753\n",
      "val Loss: 14.1686\n",
      "\n",
      "Epoch 1110/2000\n",
      "train Loss: 18.9137\n",
      "val Loss: 14.1990\n",
      "\n",
      "Epoch 1120/2000\n",
      "train Loss: 18.8718\n",
      "val Loss: 14.1354\n",
      "\n",
      "Epoch 1130/2000\n",
      "train Loss: 18.8268\n",
      "val Loss: 14.1894\n",
      "\n",
      "Epoch 1140/2000\n",
      "train Loss: 18.7865\n",
      "val Loss: 14.1683\n",
      "\n",
      "Epoch 1150/2000\n",
      "train Loss: 18.7218\n",
      "val Loss: 14.0808\n",
      "\n",
      "Epoch 1160/2000\n",
      "train Loss: 18.6611\n",
      "val Loss: 13.9403\n",
      "\n",
      "Epoch 1170/2000\n",
      "train Loss: 18.5554\n",
      "val Loss: 14.0007\n",
      "\n",
      "Epoch 1180/2000\n",
      "train Loss: 18.4685\n",
      "val Loss: 13.8558\n",
      "\n",
      "Epoch 1190/2000\n",
      "train Loss: 18.3470\n",
      "val Loss: 13.8967\n",
      "\n",
      "Epoch 1200/2000\n",
      "train Loss: 18.2436\n",
      "val Loss: 13.8006\n",
      "\n",
      "Epoch 1210/2000\n",
      "train Loss: 18.1348\n",
      "val Loss: 13.6929\n",
      "\n",
      "Epoch 1220/2000\n",
      "train Loss: 18.0539\n",
      "val Loss: 13.8687\n",
      "\n",
      "Epoch 1230/2000\n",
      "train Loss: 17.9961\n",
      "val Loss: 13.6984\n",
      "\n",
      "Epoch 1240/2000\n",
      "train Loss: 17.9013\n",
      "val Loss: 13.7757\n",
      "\n",
      "Epoch 1250/2000\n",
      "train Loss: 17.8195\n",
      "val Loss: 13.8366\n",
      "\n",
      "Epoch 1260/2000\n",
      "train Loss: 17.7220\n",
      "val Loss: 13.8451\n",
      "\n",
      "Epoch 1270/2000\n",
      "train Loss: 17.7275\n",
      "val Loss: 14.0891\n",
      "\n",
      "Epoch 1280/2000\n",
      "train Loss: 17.6054\n",
      "val Loss: 13.9466\n",
      "\n",
      "Epoch 1290/2000\n",
      "train Loss: 17.4791\n",
      "val Loss: 13.7632\n",
      "\n",
      "Epoch 1300/2000\n",
      "train Loss: 17.3794\n",
      "val Loss: 13.8670\n",
      "\n",
      "Epoch 1310/2000\n",
      "train Loss: 17.3262\n",
      "val Loss: 13.9674\n",
      "\n",
      "Epoch 1320/2000\n",
      "train Loss: 17.2391\n",
      "val Loss: 13.8191\n",
      "\n",
      "Epoch 1330/2000\n",
      "train Loss: 17.1254\n",
      "val Loss: 13.8593\n",
      "\n",
      "Epoch 1340/2000\n",
      "train Loss: 17.1111\n",
      "val Loss: 14.1788\n",
      "\n",
      "Epoch 1350/2000\n",
      "train Loss: 17.0424\n",
      "val Loss: 14.1075\n",
      "\n",
      "Epoch 1360/2000\n",
      "train Loss: 16.9664\n",
      "val Loss: 14.1918\n",
      "\n",
      "Epoch 1370/2000\n",
      "train Loss: 16.9275\n",
      "val Loss: 14.1068\n",
      "\n",
      "Epoch 1380/2000\n",
      "train Loss: 16.9851\n",
      "val Loss: 14.4901\n",
      "\n",
      "Epoch 1390/2000\n",
      "train Loss: 16.7055\n",
      "val Loss: 14.0816\n",
      "\n",
      "Epoch 1400/2000\n",
      "train Loss: 16.6167\n",
      "val Loss: 14.1132\n",
      "\n",
      "Epoch 1410/2000\n",
      "train Loss: 16.5278\n",
      "val Loss: 14.3118\n",
      "\n",
      "Epoch 1420/2000\n",
      "train Loss: 16.5020\n",
      "val Loss: 14.1557\n",
      "\n",
      "Epoch 1430/2000\n",
      "train Loss: 16.3322\n",
      "val Loss: 14.2086\n",
      "\n",
      "Epoch 1440/2000\n",
      "train Loss: 16.1856\n",
      "val Loss: 14.2527\n",
      "\n",
      "Epoch 1450/2000\n",
      "train Loss: 16.0181\n",
      "val Loss: 14.1856\n",
      "\n",
      "Epoch 1460/2000\n",
      "train Loss: 15.8130\n",
      "val Loss: 14.2636\n",
      "\n",
      "Epoch 1470/2000\n",
      "train Loss: 15.5780\n",
      "val Loss: 14.1134\n",
      "\n",
      "Epoch 1480/2000\n",
      "train Loss: 15.4748\n",
      "val Loss: 13.8032\n",
      "\n",
      "Epoch 1490/2000\n",
      "train Loss: 15.1608\n",
      "val Loss: 14.4438\n",
      "\n",
      "Epoch 1500/2000\n",
      "train Loss: 14.5784\n",
      "val Loss: 14.2488\n",
      "\n",
      "Epoch 1510/2000\n",
      "train Loss: 14.1384\n",
      "val Loss: 14.6258\n",
      "\n",
      "Epoch 1520/2000\n",
      "train Loss: 13.9146\n",
      "val Loss: 15.0232\n",
      "\n",
      "Epoch 1530/2000\n",
      "train Loss: 14.8881\n",
      "val Loss: 14.2746\n",
      "\n",
      "Epoch 1540/2000\n",
      "train Loss: 14.5584\n",
      "val Loss: 13.6548\n",
      "\n",
      "Epoch 1550/2000\n",
      "train Loss: 14.0157\n",
      "val Loss: 14.4387\n",
      "\n",
      "Epoch 1560/2000\n",
      "train Loss: 13.0016\n",
      "val Loss: 14.6598\n",
      "\n",
      "Epoch 1570/2000\n",
      "train Loss: 12.9358\n",
      "val Loss: 14.8042\n",
      "\n",
      "Epoch 1580/2000\n",
      "train Loss: 12.5783\n",
      "val Loss: 14.7364\n",
      "\n",
      "Epoch 1590/2000\n",
      "train Loss: 12.1442\n",
      "val Loss: 14.8582\n",
      "\n",
      "Epoch 1600/2000\n",
      "train Loss: 12.4383\n",
      "val Loss: 15.3455\n",
      "\n",
      "Epoch 1610/2000\n",
      "train Loss: 11.8598\n",
      "val Loss: 15.0085\n",
      "\n",
      "Epoch 1620/2000\n",
      "train Loss: 11.9699\n",
      "val Loss: 15.1594\n",
      "\n",
      "Epoch 1630/2000\n",
      "train Loss: 12.7347\n",
      "val Loss: 14.5500\n",
      "\n",
      "Epoch 1640/2000\n",
      "train Loss: 11.4926\n",
      "val Loss: 15.5132\n",
      "\n",
      "Epoch 1650/2000\n",
      "train Loss: 11.4852\n",
      "val Loss: 16.0847\n",
      "\n",
      "Epoch 1660/2000\n",
      "train Loss: 11.3635\n",
      "val Loss: 16.1692\n",
      "\n",
      "Epoch 1670/2000\n",
      "train Loss: 11.5857\n",
      "val Loss: 16.0664\n",
      "\n",
      "Epoch 1680/2000\n",
      "train Loss: 11.3937\n",
      "val Loss: 16.6611\n",
      "\n",
      "Epoch 1690/2000\n",
      "train Loss: 11.0999\n",
      "val Loss: 16.3333\n",
      "\n",
      "Epoch 1700/2000\n",
      "train Loss: 11.0766\n",
      "val Loss: 16.7088\n",
      "\n",
      "Epoch 1710/2000\n",
      "train Loss: 11.0844\n",
      "val Loss: 17.3556\n",
      "\n",
      "Epoch 1720/2000\n",
      "train Loss: 10.8262\n",
      "val Loss: 17.2615\n",
      "\n",
      "Epoch 1730/2000\n",
      "train Loss: 10.7423\n",
      "val Loss: 17.4315\n",
      "\n",
      "Epoch 1740/2000\n",
      "train Loss: 11.1146\n",
      "val Loss: 17.4528\n",
      "\n",
      "Epoch 1750/2000\n",
      "train Loss: 10.5377\n",
      "val Loss: 17.6652\n",
      "\n",
      "Epoch 1760/2000\n",
      "train Loss: 10.3554\n",
      "val Loss: 17.9045\n",
      "\n",
      "Epoch 1770/2000\n",
      "train Loss: 10.2706\n",
      "val Loss: 17.5489\n",
      "\n",
      "Epoch 1780/2000\n",
      "train Loss: 10.1670\n",
      "val Loss: 17.0594\n",
      "\n",
      "Epoch 1790/2000\n",
      "train Loss: 9.7922\n",
      "val Loss: 17.4517\n",
      "\n",
      "Epoch 1800/2000\n",
      "train Loss: 9.8450\n",
      "val Loss: 16.7358\n",
      "\n",
      "Epoch 1810/2000\n",
      "train Loss: 10.3471\n",
      "val Loss: 16.5750\n",
      "\n",
      "Epoch 1820/2000\n",
      "train Loss: 9.7704\n",
      "val Loss: 16.9769\n",
      "\n",
      "Epoch 1830/2000\n",
      "train Loss: 9.5382\n",
      "val Loss: 17.3852\n",
      "\n",
      "Epoch 1840/2000\n",
      "train Loss: 9.2303\n",
      "val Loss: 17.5748\n",
      "\n",
      "Epoch 1850/2000\n",
      "train Loss: 9.8970\n",
      "val Loss: 15.1992\n",
      "\n",
      "Epoch 1860/2000\n",
      "train Loss: 10.2311\n",
      "val Loss: 16.5512\n",
      "\n",
      "Epoch 1870/2000\n",
      "train Loss: 10.5927\n",
      "val Loss: 14.8256\n",
      "\n",
      "Epoch 1880/2000\n",
      "train Loss: 9.7559\n",
      "val Loss: 17.0147\n",
      "\n",
      "Epoch 1890/2000\n",
      "train Loss: 9.1106\n",
      "val Loss: 18.4613\n",
      "\n",
      "Epoch 1900/2000\n",
      "train Loss: 8.8363\n",
      "val Loss: 15.8665\n",
      "\n",
      "Epoch 1910/2000\n",
      "train Loss: 9.0828\n",
      "val Loss: 17.9872\n",
      "\n",
      "Epoch 1920/2000\n",
      "train Loss: 8.5259\n",
      "val Loss: 17.1744\n",
      "\n",
      "Epoch 1930/2000\n",
      "train Loss: 8.9805\n",
      "val Loss: 15.2755\n",
      "\n",
      "Epoch 1940/2000\n",
      "train Loss: 8.7392\n",
      "val Loss: 18.6595\n",
      "\n",
      "Epoch 1950/2000\n",
      "train Loss: 9.2557\n",
      "val Loss: 17.0426\n",
      "\n",
      "Epoch 1960/2000\n",
      "train Loss: 8.7805\n",
      "val Loss: 17.9718\n",
      "\n",
      "Epoch 1970/2000\n",
      "train Loss: 9.4424\n",
      "val Loss: 15.0221\n",
      "\n",
      "Epoch 1980/2000\n",
      "train Loss: 9.1751\n",
      "val Loss: 17.5988\n",
      "\n",
      "Epoch 1990/2000\n",
      "train Loss: 8.8063\n",
      "val Loss: 17.5234\n",
      "\n",
      "Epoch 2000/2000\n",
      "train Loss: 8.3751\n",
      "val Loss: 16.8345\n",
      "\n",
      "Training complete in 1m 54s\n",
      "Best val Loss: 12.851265\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 12.37718 and R2: -1.92076\n",
      "test RMSE: 3.5181\n"
     ]
    }
   ],
   "source": [
    "# Case 2. GRU (w/o data representation)\n",
    "config = config2\n",
    "data_reg = mr.Regression(config, train_data, test_data, use_representation=True)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "917f5a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/2000\n",
      "train Loss: 241.7953\n",
      "val Loss: 200.1572\n",
      "\n",
      "Epoch 10/2000\n",
      "train Loss: 25.4863\n",
      "val Loss: 16.7112\n",
      "\n",
      "Epoch 20/2000\n",
      "train Loss: 28.1218\n",
      "val Loss: 19.6314\n",
      "\n",
      "Epoch 30/2000\n",
      "train Loss: 27.5288\n",
      "val Loss: 16.1003\n",
      "\n",
      "Epoch 40/2000\n",
      "train Loss: 22.6572\n",
      "val Loss: 15.0557\n",
      "\n",
      "Epoch 50/2000\n",
      "train Loss: 23.2195\n",
      "val Loss: 15.3886\n",
      "\n",
      "Epoch 60/2000\n",
      "train Loss: 20.4684\n",
      "val Loss: 17.9040\n",
      "\n",
      "Epoch 70/2000\n",
      "train Loss: 20.7106\n",
      "val Loss: 16.3008\n",
      "\n",
      "Epoch 80/2000\n",
      "train Loss: 17.5504\n",
      "val Loss: 16.3044\n",
      "\n",
      "Epoch 90/2000\n",
      "train Loss: 18.3929\n",
      "val Loss: 15.3937\n",
      "\n",
      "Epoch 100/2000\n",
      "train Loss: 18.9795\n",
      "val Loss: 15.2887\n",
      "\n",
      "Epoch 110/2000\n",
      "train Loss: 17.2724\n",
      "val Loss: 15.1479\n",
      "\n",
      "Epoch 120/2000\n",
      "train Loss: 15.8387\n",
      "val Loss: 19.0238\n",
      "\n",
      "Epoch 130/2000\n",
      "train Loss: 20.2261\n",
      "val Loss: 17.5141\n",
      "\n",
      "Epoch 140/2000\n",
      "train Loss: 16.0169\n",
      "val Loss: 18.2457\n",
      "\n",
      "Epoch 150/2000\n",
      "train Loss: 17.6703\n",
      "val Loss: 16.6404\n",
      "\n",
      "Epoch 160/2000\n",
      "train Loss: 18.6532\n",
      "val Loss: 16.0960\n",
      "\n",
      "Epoch 170/2000\n",
      "train Loss: 16.2398\n",
      "val Loss: 21.4689\n",
      "\n",
      "Epoch 180/2000\n",
      "train Loss: 16.7169\n",
      "val Loss: 18.3985\n",
      "\n",
      "Epoch 190/2000\n",
      "train Loss: 14.5210\n",
      "val Loss: 17.6819\n",
      "\n",
      "Epoch 200/2000\n",
      "train Loss: 16.8269\n",
      "val Loss: 18.2462\n",
      "\n",
      "Epoch 210/2000\n",
      "train Loss: 15.1894\n",
      "val Loss: 17.9400\n",
      "\n",
      "Epoch 220/2000\n",
      "train Loss: 15.6290\n",
      "val Loss: 16.4921\n",
      "\n",
      "Epoch 230/2000\n",
      "train Loss: 15.2466\n",
      "val Loss: 19.4501\n",
      "\n",
      "Epoch 240/2000\n",
      "train Loss: 16.3710\n",
      "val Loss: 17.5016\n",
      "\n",
      "Epoch 250/2000\n",
      "train Loss: 14.2474\n",
      "val Loss: 16.6283\n",
      "\n",
      "Epoch 260/2000\n",
      "train Loss: 16.8376\n",
      "val Loss: 19.3847\n",
      "\n",
      "Epoch 270/2000\n",
      "train Loss: 14.0909\n",
      "val Loss: 17.0104\n",
      "\n",
      "Epoch 280/2000\n",
      "train Loss: 13.4750\n",
      "val Loss: 18.3775\n",
      "\n",
      "Epoch 290/2000\n",
      "train Loss: 12.3165\n",
      "val Loss: 21.4153\n",
      "\n",
      "Epoch 300/2000\n",
      "train Loss: 14.1713\n",
      "val Loss: 19.0356\n",
      "\n",
      "Epoch 310/2000\n",
      "train Loss: 11.5265\n",
      "val Loss: 18.4626\n",
      "\n",
      "Epoch 320/2000\n",
      "train Loss: 12.5215\n",
      "val Loss: 19.5411\n",
      "\n",
      "Epoch 330/2000\n",
      "train Loss: 11.4374\n",
      "val Loss: 19.0741\n",
      "\n",
      "Epoch 340/2000\n",
      "train Loss: 10.7660\n",
      "val Loss: 20.3589\n",
      "\n",
      "Epoch 350/2000\n",
      "train Loss: 10.9344\n",
      "val Loss: 19.4103\n",
      "\n",
      "Epoch 360/2000\n",
      "train Loss: 10.2553\n",
      "val Loss: 21.0738\n",
      "\n",
      "Epoch 370/2000\n",
      "train Loss: 11.2332\n",
      "val Loss: 20.5979\n",
      "\n",
      "Epoch 380/2000\n",
      "train Loss: 8.7921\n",
      "val Loss: 21.1843\n",
      "\n",
      "Epoch 390/2000\n",
      "train Loss: 9.2855\n",
      "val Loss: 20.7633\n",
      "\n",
      "Epoch 400/2000\n",
      "train Loss: 9.7825\n",
      "val Loss: 21.0583\n",
      "\n",
      "Epoch 410/2000\n",
      "train Loss: 8.5340\n",
      "val Loss: 22.7776\n",
      "\n",
      "Epoch 420/2000\n",
      "train Loss: 10.2857\n",
      "val Loss: 20.9173\n",
      "\n",
      "Epoch 430/2000\n",
      "train Loss: 8.7381\n",
      "val Loss: 22.4500\n",
      "\n",
      "Epoch 440/2000\n",
      "train Loss: 7.6566\n",
      "val Loss: 21.0393\n",
      "\n",
      "Epoch 450/2000\n",
      "train Loss: 6.4762\n",
      "val Loss: 21.7766\n",
      "\n",
      "Epoch 460/2000\n",
      "train Loss: 6.5978\n",
      "val Loss: 22.2713\n",
      "\n",
      "Epoch 470/2000\n",
      "train Loss: 6.6824\n",
      "val Loss: 24.3798\n",
      "\n",
      "Epoch 480/2000\n",
      "train Loss: 7.5629\n",
      "val Loss: 22.5666\n",
      "\n",
      "Epoch 490/2000\n",
      "train Loss: 5.6129\n",
      "val Loss: 25.7608\n",
      "\n",
      "Epoch 500/2000\n",
      "train Loss: 5.1946\n",
      "val Loss: 23.7221\n",
      "\n",
      "Epoch 510/2000\n",
      "train Loss: 8.1798\n",
      "val Loss: 23.4262\n",
      "\n",
      "Epoch 520/2000\n",
      "train Loss: 6.2690\n",
      "val Loss: 23.8333\n",
      "\n",
      "Epoch 530/2000\n",
      "train Loss: 5.5508\n",
      "val Loss: 24.9352\n",
      "\n",
      "Epoch 540/2000\n",
      "train Loss: 5.2023\n",
      "val Loss: 25.4603\n",
      "\n",
      "Epoch 550/2000\n",
      "train Loss: 4.7024\n",
      "val Loss: 25.7560\n",
      "\n",
      "Epoch 560/2000\n",
      "train Loss: 5.5830\n",
      "val Loss: 30.1707\n",
      "\n",
      "Epoch 570/2000\n",
      "train Loss: 4.0957\n",
      "val Loss: 24.0355\n",
      "\n",
      "Epoch 580/2000\n",
      "train Loss: 3.8673\n",
      "val Loss: 25.7795\n",
      "\n",
      "Epoch 590/2000\n",
      "train Loss: 3.4038\n",
      "val Loss: 24.9847\n",
      "\n",
      "Epoch 600/2000\n",
      "train Loss: 4.4217\n",
      "val Loss: 25.9421\n",
      "\n",
      "Epoch 610/2000\n",
      "train Loss: 2.8999\n",
      "val Loss: 25.5665\n",
      "\n",
      "Epoch 620/2000\n",
      "train Loss: 4.5745\n",
      "val Loss: 26.4413\n",
      "\n",
      "Epoch 630/2000\n",
      "train Loss: 3.5811\n",
      "val Loss: 26.9834\n",
      "\n",
      "Epoch 640/2000\n",
      "train Loss: 3.8365\n",
      "val Loss: 28.1288\n",
      "\n",
      "Epoch 650/2000\n",
      "train Loss: 3.8812\n",
      "val Loss: 26.1966\n",
      "\n",
      "Epoch 660/2000\n",
      "train Loss: 3.3325\n",
      "val Loss: 26.7419\n",
      "\n",
      "Epoch 670/2000\n",
      "train Loss: 4.0464\n",
      "val Loss: 27.8262\n",
      "\n",
      "Epoch 680/2000\n",
      "train Loss: 3.0823\n",
      "val Loss: 27.3340\n",
      "\n",
      "Epoch 690/2000\n",
      "train Loss: 3.0093\n",
      "val Loss: 26.5394\n",
      "\n",
      "Epoch 700/2000\n",
      "train Loss: 2.5793\n",
      "val Loss: 28.6181\n",
      "\n",
      "Epoch 710/2000\n",
      "train Loss: 1.9382\n",
      "val Loss: 28.8587\n",
      "\n",
      "Epoch 720/2000\n",
      "train Loss: 2.2225\n",
      "val Loss: 28.5346\n",
      "\n",
      "Epoch 730/2000\n",
      "train Loss: 2.0633\n",
      "val Loss: 26.7084\n",
      "\n",
      "Epoch 740/2000\n",
      "train Loss: 2.2763\n",
      "val Loss: 26.0856\n",
      "\n",
      "Epoch 750/2000\n",
      "train Loss: 2.1711\n",
      "val Loss: 26.9379\n",
      "\n",
      "Epoch 760/2000\n",
      "train Loss: 1.6088\n",
      "val Loss: 25.4111\n",
      "\n",
      "Epoch 770/2000\n",
      "train Loss: 1.7924\n",
      "val Loss: 29.2426\n",
      "\n",
      "Epoch 780/2000\n",
      "train Loss: 2.4373\n",
      "val Loss: 26.5667\n",
      "\n",
      "Epoch 790/2000\n",
      "train Loss: 1.6395\n",
      "val Loss: 27.7548\n",
      "\n",
      "Epoch 800/2000\n",
      "train Loss: 2.2255\n",
      "val Loss: 29.7638\n",
      "\n",
      "Epoch 810/2000\n",
      "train Loss: 3.5419\n",
      "val Loss: 29.4142\n",
      "\n",
      "Epoch 820/2000\n",
      "train Loss: 1.7549\n",
      "val Loss: 26.6302\n",
      "\n",
      "Epoch 830/2000\n",
      "train Loss: 1.8940\n",
      "val Loss: 26.6146\n",
      "\n",
      "Epoch 840/2000\n",
      "train Loss: 1.4583\n",
      "val Loss: 26.0963\n",
      "\n",
      "Epoch 850/2000\n",
      "train Loss: 1.4160\n",
      "val Loss: 28.1013\n",
      "\n",
      "Epoch 860/2000\n",
      "train Loss: 1.5066\n",
      "val Loss: 28.6055\n",
      "\n",
      "Epoch 870/2000\n",
      "train Loss: 2.2088\n",
      "val Loss: 29.4898\n",
      "\n",
      "Epoch 880/2000\n",
      "train Loss: 2.5834\n",
      "val Loss: 25.1910\n",
      "\n",
      "Epoch 890/2000\n",
      "train Loss: 1.4627\n",
      "val Loss: 26.8356\n",
      "\n",
      "Epoch 900/2000\n",
      "train Loss: 1.4515\n",
      "val Loss: 26.7918\n",
      "\n",
      "Epoch 910/2000\n",
      "train Loss: 1.3298\n",
      "val Loss: 27.3518\n",
      "\n",
      "Epoch 920/2000\n",
      "train Loss: 1.2762\n",
      "val Loss: 26.4822\n",
      "\n",
      "Epoch 930/2000\n",
      "train Loss: 1.8248\n",
      "val Loss: 28.8366\n",
      "\n",
      "Epoch 940/2000\n",
      "train Loss: 1.2337\n",
      "val Loss: 27.9445\n",
      "\n",
      "Epoch 950/2000\n",
      "train Loss: 1.6921\n",
      "val Loss: 26.6071\n",
      "\n",
      "Epoch 960/2000\n",
      "train Loss: 0.9079\n",
      "val Loss: 28.6792\n",
      "\n",
      "Epoch 970/2000\n",
      "train Loss: 1.3905\n",
      "val Loss: 28.5660\n",
      "\n",
      "Epoch 980/2000\n",
      "train Loss: 1.0099\n",
      "val Loss: 28.7272\n",
      "\n",
      "Epoch 990/2000\n",
      "train Loss: 1.3472\n",
      "val Loss: 26.9022\n",
      "\n",
      "Epoch 1000/2000\n",
      "train Loss: 2.4388\n",
      "val Loss: 30.5780\n",
      "\n",
      "Epoch 1010/2000\n",
      "train Loss: 0.9729\n",
      "val Loss: 26.8710\n",
      "\n",
      "Epoch 1020/2000\n",
      "train Loss: 0.9401\n",
      "val Loss: 25.6151\n",
      "\n",
      "Epoch 1030/2000\n",
      "train Loss: 1.6673\n",
      "val Loss: 28.6391\n",
      "\n",
      "Epoch 1040/2000\n",
      "train Loss: 1.6574\n",
      "val Loss: 27.5393\n",
      "\n",
      "Epoch 1050/2000\n",
      "train Loss: 1.7829\n",
      "val Loss: 28.2511\n",
      "\n",
      "Epoch 1060/2000\n",
      "train Loss: 1.2623\n",
      "val Loss: 28.5467\n",
      "\n",
      "Epoch 1070/2000\n",
      "train Loss: 1.0593\n",
      "val Loss: 27.4714\n",
      "\n",
      "Epoch 1080/2000\n",
      "train Loss: 0.7911\n",
      "val Loss: 26.3366\n",
      "\n",
      "Epoch 1090/2000\n",
      "train Loss: 1.3579\n",
      "val Loss: 26.6720\n",
      "\n",
      "Epoch 1100/2000\n",
      "train Loss: 1.1262\n",
      "val Loss: 26.2636\n",
      "\n",
      "Epoch 1110/2000\n",
      "train Loss: 0.9521\n",
      "val Loss: 27.4726\n",
      "\n",
      "Epoch 1120/2000\n",
      "train Loss: 1.2743\n",
      "val Loss: 29.9044\n",
      "\n",
      "Epoch 1130/2000\n",
      "train Loss: 1.3229\n",
      "val Loss: 26.4921\n",
      "\n",
      "Epoch 1140/2000\n",
      "train Loss: 1.2916\n",
      "val Loss: 30.4408\n",
      "\n",
      "Epoch 1150/2000\n",
      "train Loss: 1.1904\n",
      "val Loss: 27.3803\n",
      "\n",
      "Epoch 1160/2000\n",
      "train Loss: 1.4523\n",
      "val Loss: 28.2346\n",
      "\n",
      "Epoch 1170/2000\n",
      "train Loss: 0.7771\n",
      "val Loss: 27.2574\n",
      "\n",
      "Epoch 1180/2000\n",
      "train Loss: 0.9004\n",
      "val Loss: 27.4768\n",
      "\n",
      "Epoch 1190/2000\n",
      "train Loss: 1.2263\n",
      "val Loss: 31.3688\n",
      "\n",
      "Epoch 1200/2000\n",
      "train Loss: 1.5878\n",
      "val Loss: 26.9459\n",
      "\n",
      "Epoch 1210/2000\n",
      "train Loss: 0.9469\n",
      "val Loss: 28.4022\n",
      "\n",
      "Epoch 1220/2000\n",
      "train Loss: 1.2443\n",
      "val Loss: 27.9270\n",
      "\n",
      "Epoch 1230/2000\n",
      "train Loss: 0.9684\n",
      "val Loss: 26.2080\n",
      "\n",
      "Epoch 1240/2000\n",
      "train Loss: 0.6780\n",
      "val Loss: 28.1180\n",
      "\n",
      "Epoch 1250/2000\n",
      "train Loss: 1.1350\n",
      "val Loss: 27.3560\n",
      "\n",
      "Epoch 1260/2000\n",
      "train Loss: 1.0292\n",
      "val Loss: 26.4617\n",
      "\n",
      "Epoch 1270/2000\n",
      "train Loss: 1.0053\n",
      "val Loss: 28.0455\n",
      "\n",
      "Epoch 1280/2000\n",
      "train Loss: 1.1297\n",
      "val Loss: 27.8947\n",
      "\n",
      "Epoch 1290/2000\n",
      "train Loss: 1.1536\n",
      "val Loss: 27.1953\n",
      "\n",
      "Epoch 1300/2000\n",
      "train Loss: 1.2774\n",
      "val Loss: 29.1581\n",
      "\n",
      "Epoch 1310/2000\n",
      "train Loss: 0.8364\n",
      "val Loss: 27.6812\n",
      "\n",
      "Epoch 1320/2000\n",
      "train Loss: 0.7795\n",
      "val Loss: 28.3501\n",
      "\n",
      "Epoch 1330/2000\n",
      "train Loss: 1.3228\n",
      "val Loss: 31.3862\n",
      "\n",
      "Epoch 1340/2000\n",
      "train Loss: 1.1426\n",
      "val Loss: 27.0181\n",
      "\n",
      "Epoch 1350/2000\n",
      "train Loss: 1.1131\n",
      "val Loss: 30.4472\n",
      "\n",
      "Epoch 1360/2000\n",
      "train Loss: 0.9440\n",
      "val Loss: 27.7614\n",
      "\n",
      "Epoch 1370/2000\n",
      "train Loss: 0.8769\n",
      "val Loss: 28.0292\n",
      "\n",
      "Epoch 1380/2000\n",
      "train Loss: 1.0282\n",
      "val Loss: 26.9116\n",
      "\n",
      "Epoch 1390/2000\n",
      "train Loss: 0.9050\n",
      "val Loss: 24.8002\n",
      "\n",
      "Epoch 1400/2000\n",
      "train Loss: 0.6176\n",
      "val Loss: 26.0531\n",
      "\n",
      "Epoch 1410/2000\n",
      "train Loss: 0.8872\n",
      "val Loss: 27.8733\n",
      "\n",
      "Epoch 1420/2000\n",
      "train Loss: 0.9680\n",
      "val Loss: 27.9751\n",
      "\n",
      "Epoch 1430/2000\n",
      "train Loss: 0.8897\n",
      "val Loss: 27.1951\n",
      "\n",
      "Epoch 1440/2000\n",
      "train Loss: 1.0096\n",
      "val Loss: 26.9885\n",
      "\n",
      "Epoch 1450/2000\n",
      "train Loss: 1.1018\n",
      "val Loss: 30.1890\n",
      "\n",
      "Epoch 1460/2000\n",
      "train Loss: 1.7607\n",
      "val Loss: 26.9825\n",
      "\n",
      "Epoch 1470/2000\n",
      "train Loss: 0.7908\n",
      "val Loss: 27.9678\n",
      "\n",
      "Epoch 1480/2000\n",
      "train Loss: 1.1776\n",
      "val Loss: 25.7489\n",
      "\n",
      "Epoch 1490/2000\n",
      "train Loss: 0.7635\n",
      "val Loss: 25.5572\n",
      "\n",
      "Epoch 1500/2000\n",
      "train Loss: 1.0377\n",
      "val Loss: 25.1372\n",
      "\n",
      "Epoch 1510/2000\n",
      "train Loss: 0.9214\n",
      "val Loss: 28.1588\n",
      "\n",
      "Epoch 1520/2000\n",
      "train Loss: 0.8862\n",
      "val Loss: 27.8965\n",
      "\n",
      "Epoch 1530/2000\n",
      "train Loss: 1.0644\n",
      "val Loss: 28.0995\n",
      "\n",
      "Epoch 1540/2000\n",
      "train Loss: 0.7589\n",
      "val Loss: 28.3072\n",
      "\n",
      "Epoch 1550/2000\n",
      "train Loss: 0.6965\n",
      "val Loss: 24.3650\n",
      "\n",
      "Epoch 1560/2000\n",
      "train Loss: 1.5551\n",
      "val Loss: 28.6463\n",
      "\n",
      "Epoch 1570/2000\n",
      "train Loss: 1.1248\n",
      "val Loss: 28.2010\n",
      "\n",
      "Epoch 1580/2000\n",
      "train Loss: 0.7634\n",
      "val Loss: 25.7403\n",
      "\n",
      "Epoch 1590/2000\n",
      "train Loss: 1.1511\n",
      "val Loss: 27.1548\n",
      "\n",
      "Epoch 1600/2000\n",
      "train Loss: 0.9647\n",
      "val Loss: 29.2429\n",
      "\n",
      "Epoch 1610/2000\n",
      "train Loss: 0.7901\n",
      "val Loss: 26.5806\n",
      "\n",
      "Epoch 1620/2000\n",
      "train Loss: 0.6273\n",
      "val Loss: 25.6809\n",
      "\n",
      "Epoch 1630/2000\n",
      "train Loss: 1.0801\n",
      "val Loss: 26.2190\n",
      "\n",
      "Epoch 1640/2000\n",
      "train Loss: 0.6247\n",
      "val Loss: 24.7951\n",
      "\n",
      "Epoch 1650/2000\n",
      "train Loss: 0.8781\n",
      "val Loss: 26.6206\n",
      "\n",
      "Epoch 1660/2000\n",
      "train Loss: 1.1631\n",
      "val Loss: 27.3484\n",
      "\n",
      "Epoch 1670/2000\n",
      "train Loss: 1.0371\n",
      "val Loss: 26.0949\n",
      "\n",
      "Epoch 1680/2000\n",
      "train Loss: 0.7091\n",
      "val Loss: 28.4442\n",
      "\n",
      "Epoch 1690/2000\n",
      "train Loss: 0.6772\n",
      "val Loss: 27.0403\n",
      "\n",
      "Epoch 1700/2000\n",
      "train Loss: 1.0081\n",
      "val Loss: 25.4573\n",
      "\n",
      "Epoch 1710/2000\n",
      "train Loss: 1.1663\n",
      "val Loss: 23.8951\n",
      "\n",
      "Epoch 1720/2000\n",
      "train Loss: 0.5441\n",
      "val Loss: 26.0356\n",
      "\n",
      "Epoch 1730/2000\n",
      "train Loss: 0.9654\n",
      "val Loss: 25.7592\n",
      "\n",
      "Epoch 1740/2000\n",
      "train Loss: 1.0006\n",
      "val Loss: 25.0827\n",
      "\n",
      "Epoch 1750/2000\n",
      "train Loss: 0.6288\n",
      "val Loss: 25.5254\n",
      "\n",
      "Epoch 1760/2000\n",
      "train Loss: 1.4283\n",
      "val Loss: 25.3676\n",
      "\n",
      "Epoch 1770/2000\n",
      "train Loss: 0.8337\n",
      "val Loss: 26.3882\n",
      "\n",
      "Epoch 1780/2000\n",
      "train Loss: 0.4854\n",
      "val Loss: 24.8312\n",
      "\n",
      "Epoch 1790/2000\n",
      "train Loss: 0.6255\n",
      "val Loss: 24.9803\n",
      "\n",
      "Epoch 1800/2000\n",
      "train Loss: 0.6391\n",
      "val Loss: 24.4107\n",
      "\n",
      "Epoch 1810/2000\n",
      "train Loss: 0.6136\n",
      "val Loss: 25.1915\n",
      "\n",
      "Epoch 1820/2000\n",
      "train Loss: 0.8650\n",
      "val Loss: 24.5501\n",
      "\n",
      "Epoch 1830/2000\n",
      "train Loss: 0.9532\n",
      "val Loss: 24.5819\n",
      "\n",
      "Epoch 1840/2000\n",
      "train Loss: 0.8229\n",
      "val Loss: 25.5890\n",
      "\n",
      "Epoch 1850/2000\n",
      "train Loss: 0.7698\n",
      "val Loss: 26.3620\n",
      "\n",
      "Epoch 1860/2000\n",
      "train Loss: 0.6823\n",
      "val Loss: 27.3382\n",
      "\n",
      "Epoch 1870/2000\n",
      "train Loss: 0.6314\n",
      "val Loss: 27.1365\n",
      "\n",
      "Epoch 1880/2000\n",
      "train Loss: 0.8084\n",
      "val Loss: 26.9770\n",
      "\n",
      "Epoch 1890/2000\n",
      "train Loss: 0.8552\n",
      "val Loss: 27.0123\n",
      "\n",
      "Epoch 1900/2000\n",
      "train Loss: 1.0672\n",
      "val Loss: 29.5447\n",
      "\n",
      "Epoch 1910/2000\n",
      "train Loss: 0.4966\n",
      "val Loss: 24.5825\n",
      "\n",
      "Epoch 1920/2000\n",
      "train Loss: 0.9851\n",
      "val Loss: 25.4839\n",
      "\n",
      "Epoch 1930/2000\n",
      "train Loss: 0.8587\n",
      "val Loss: 25.8952\n",
      "\n",
      "Epoch 1940/2000\n",
      "train Loss: 0.8863\n",
      "val Loss: 28.7675\n",
      "\n",
      "Epoch 1950/2000\n",
      "train Loss: 0.5619\n",
      "val Loss: 25.4032\n",
      "\n",
      "Epoch 1960/2000\n",
      "train Loss: 0.5446\n",
      "val Loss: 27.1959\n",
      "\n",
      "Epoch 1970/2000\n",
      "train Loss: 0.7546\n",
      "val Loss: 29.1163\n",
      "\n",
      "Epoch 1980/2000\n",
      "train Loss: 0.3706\n",
      "val Loss: 28.2837\n",
      "\n",
      "Epoch 1990/2000\n",
      "train Loss: 0.5656\n",
      "val Loss: 28.0890\n",
      "\n",
      "Epoch 2000/2000\n",
      "train Loss: 0.6626\n",
      "val Loss: 25.3548\n",
      "\n",
      "Training complete in 0m 18s\n",
      "Best val Loss: 14.887598\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 13.74899 and R2: -20.05477\n",
      "test RMSE: 3.708\n"
     ]
    }
   ],
   "source": [
    "# Case 3. CNN_1D (w/o data representation)\n",
    "config = config3\n",
    "data_reg = mr.Regression(config, train_data, test_data, use_representation=True)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e78051f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/2000\n",
      "train Loss: 226.0511\n",
      "val Loss: 200.1778\n",
      "\n",
      "Epoch 10/2000\n",
      "train Loss: 169.3904\n",
      "val Loss: 134.2786\n",
      "\n",
      "Epoch 20/2000\n",
      "train Loss: 108.7624\n",
      "val Loss: 84.0601\n",
      "\n",
      "Epoch 30/2000\n",
      "train Loss: 79.7754\n",
      "val Loss: 50.5382\n",
      "\n",
      "Epoch 40/2000\n",
      "train Loss: 61.8190\n",
      "val Loss: 37.8694\n",
      "\n",
      "Epoch 50/2000\n",
      "train Loss: 48.7371\n",
      "val Loss: 33.1911\n",
      "\n",
      "Epoch 60/2000\n",
      "train Loss: 38.3243\n",
      "val Loss: 27.9385\n",
      "\n",
      "Epoch 70/2000\n",
      "train Loss: 30.1517\n",
      "val Loss: 14.4212\n",
      "\n",
      "Epoch 80/2000\n",
      "train Loss: 24.0227\n",
      "val Loss: 20.7905\n",
      "\n",
      "Epoch 90/2000\n",
      "train Loss: 19.8376\n",
      "val Loss: 20.3671\n",
      "\n",
      "Epoch 100/2000\n",
      "train Loss: 17.1810\n",
      "val Loss: 19.5929\n",
      "\n",
      "Epoch 110/2000\n",
      "train Loss: 14.2604\n",
      "val Loss: 20.3327\n",
      "\n",
      "Epoch 120/2000\n",
      "train Loss: 11.7465\n",
      "val Loss: 14.9605\n",
      "\n",
      "Epoch 130/2000\n",
      "train Loss: 10.2184\n",
      "val Loss: 16.7348\n",
      "\n",
      "Epoch 140/2000\n",
      "train Loss: 9.4282\n",
      "val Loss: 17.1257\n",
      "\n",
      "Epoch 150/2000\n",
      "train Loss: 8.6618\n",
      "val Loss: 16.7103\n",
      "\n",
      "Epoch 160/2000\n",
      "train Loss: 6.9807\n",
      "val Loss: 17.0364\n",
      "\n",
      "Epoch 170/2000\n",
      "train Loss: 6.5157\n",
      "val Loss: 21.5285\n",
      "\n",
      "Epoch 180/2000\n",
      "train Loss: 5.8267\n",
      "val Loss: 44.6534\n",
      "\n",
      "Epoch 190/2000\n",
      "train Loss: 6.2122\n",
      "val Loss: 37.1357\n",
      "\n",
      "Epoch 200/2000\n",
      "train Loss: 5.4434\n",
      "val Loss: 35.7210\n",
      "\n",
      "Epoch 210/2000\n",
      "train Loss: 7.0974\n",
      "val Loss: 15.5775\n",
      "\n",
      "Epoch 220/2000\n",
      "train Loss: 4.3787\n",
      "val Loss: 22.8140\n",
      "\n",
      "Epoch 230/2000\n",
      "train Loss: 4.3414\n",
      "val Loss: 63.5376\n",
      "\n",
      "Epoch 240/2000\n",
      "train Loss: 3.3632\n",
      "val Loss: 19.0103\n",
      "\n",
      "Epoch 250/2000\n",
      "train Loss: 2.6065\n",
      "val Loss: 19.2476\n",
      "\n",
      "Epoch 260/2000\n",
      "train Loss: 3.5346\n",
      "val Loss: 25.5728\n",
      "\n",
      "Epoch 270/2000\n",
      "train Loss: 3.3694\n",
      "val Loss: 27.1523\n",
      "\n",
      "Epoch 280/2000\n",
      "train Loss: 3.0245\n",
      "val Loss: 19.9550\n",
      "\n",
      "Epoch 290/2000\n",
      "train Loss: 2.4284\n",
      "val Loss: 39.9668\n",
      "\n",
      "Epoch 300/2000\n",
      "train Loss: 3.6446\n",
      "val Loss: 46.1049\n",
      "\n",
      "Epoch 310/2000\n",
      "train Loss: 1.9527\n",
      "val Loss: 20.0288\n",
      "\n",
      "Epoch 320/2000\n",
      "train Loss: 1.9828\n",
      "val Loss: 40.6653\n",
      "\n",
      "Epoch 330/2000\n",
      "train Loss: 2.1076\n",
      "val Loss: 20.5935\n",
      "\n",
      "Epoch 340/2000\n",
      "train Loss: 2.4540\n",
      "val Loss: 42.6940\n",
      "\n",
      "Epoch 350/2000\n",
      "train Loss: 1.8334\n",
      "val Loss: 56.1422\n",
      "\n",
      "Epoch 360/2000\n",
      "train Loss: 1.2538\n",
      "val Loss: 41.5743\n",
      "\n",
      "Epoch 370/2000\n",
      "train Loss: 2.3283\n",
      "val Loss: 40.1566\n",
      "\n",
      "Epoch 380/2000\n",
      "train Loss: 1.7099\n",
      "val Loss: 54.9300\n",
      "\n",
      "Epoch 390/2000\n",
      "train Loss: 3.3674\n",
      "val Loss: 25.5509\n",
      "\n",
      "Epoch 400/2000\n",
      "train Loss: 0.7472\n",
      "val Loss: 18.1707\n",
      "\n",
      "Epoch 410/2000\n",
      "train Loss: 1.0949\n",
      "val Loss: 26.5830\n",
      "\n",
      "Epoch 420/2000\n",
      "train Loss: 1.1399\n",
      "val Loss: 19.1110\n",
      "\n",
      "Epoch 430/2000\n",
      "train Loss: 1.2644\n",
      "val Loss: 18.2675\n",
      "\n",
      "Epoch 440/2000\n",
      "train Loss: 1.7618\n",
      "val Loss: 33.7582\n",
      "\n",
      "Epoch 450/2000\n",
      "train Loss: 0.7511\n",
      "val Loss: 84.4716\n",
      "\n",
      "Epoch 460/2000\n",
      "train Loss: 2.1699\n",
      "val Loss: 19.7873\n",
      "\n",
      "Epoch 470/2000\n",
      "train Loss: 1.3126\n",
      "val Loss: 21.6714\n",
      "\n",
      "Epoch 480/2000\n",
      "train Loss: 0.9800\n",
      "val Loss: 22.3510\n",
      "\n",
      "Epoch 490/2000\n",
      "train Loss: 1.1386\n",
      "val Loss: 44.5015\n",
      "\n",
      "Epoch 500/2000\n",
      "train Loss: 1.7614\n",
      "val Loss: 42.8750\n",
      "\n",
      "Epoch 510/2000\n",
      "train Loss: 3.7664\n",
      "val Loss: 75.5753\n",
      "\n",
      "Epoch 520/2000\n",
      "train Loss: 1.8744\n",
      "val Loss: 20.3342\n",
      "\n",
      "Epoch 530/2000\n",
      "train Loss: 0.6868\n",
      "val Loss: 17.1343\n",
      "\n",
      "Epoch 540/2000\n",
      "train Loss: 0.7009\n",
      "val Loss: 17.1192\n",
      "\n",
      "Epoch 550/2000\n",
      "train Loss: 1.2633\n",
      "val Loss: 25.2578\n",
      "\n",
      "Epoch 560/2000\n",
      "train Loss: 0.6901\n",
      "val Loss: 22.8131\n",
      "\n",
      "Epoch 570/2000\n",
      "train Loss: 1.1168\n",
      "val Loss: 34.6908\n",
      "\n",
      "Epoch 580/2000\n",
      "train Loss: 0.8917\n",
      "val Loss: 28.9763\n",
      "\n",
      "Epoch 590/2000\n",
      "train Loss: 2.2317\n",
      "val Loss: 20.8194\n",
      "\n",
      "Epoch 600/2000\n",
      "train Loss: 0.8666\n",
      "val Loss: 22.9292\n",
      "\n",
      "Epoch 610/2000\n",
      "train Loss: 1.8463\n",
      "val Loss: 17.8552\n",
      "\n",
      "Epoch 620/2000\n",
      "train Loss: 0.7005\n",
      "val Loss: 26.2202\n",
      "\n",
      "Epoch 630/2000\n",
      "train Loss: 2.2968\n",
      "val Loss: 90.6158\n",
      "\n",
      "Epoch 640/2000\n",
      "train Loss: 1.3115\n",
      "val Loss: 24.6764\n",
      "\n",
      "Epoch 650/2000\n",
      "train Loss: 1.0870\n",
      "val Loss: 39.9495\n",
      "\n",
      "Epoch 660/2000\n",
      "train Loss: 3.6877\n",
      "val Loss: 20.9105\n",
      "\n",
      "Epoch 670/2000\n",
      "train Loss: 0.6590\n",
      "val Loss: 40.0885\n",
      "\n",
      "Epoch 680/2000\n",
      "train Loss: 1.1239\n",
      "val Loss: 21.1265\n",
      "\n",
      "Epoch 690/2000\n",
      "train Loss: 1.0272\n",
      "val Loss: 23.9383\n",
      "\n",
      "Epoch 700/2000\n",
      "train Loss: 0.6583\n",
      "val Loss: 34.7839\n",
      "\n",
      "Epoch 710/2000\n",
      "train Loss: 1.8345\n",
      "val Loss: 79.6758\n",
      "\n",
      "Epoch 720/2000\n",
      "train Loss: 0.7773\n",
      "val Loss: 27.5351\n",
      "\n",
      "Epoch 730/2000\n",
      "train Loss: 0.7115\n",
      "val Loss: 27.0678\n",
      "\n",
      "Epoch 740/2000\n",
      "train Loss: 1.5088\n",
      "val Loss: 17.7304\n",
      "\n",
      "Epoch 750/2000\n",
      "train Loss: 0.9379\n",
      "val Loss: 17.3577\n",
      "\n",
      "Epoch 760/2000\n",
      "train Loss: 1.0632\n",
      "val Loss: 16.9853\n",
      "\n",
      "Epoch 770/2000\n",
      "train Loss: 0.7921\n",
      "val Loss: 65.3174\n",
      "\n",
      "Epoch 780/2000\n",
      "train Loss: 0.5785\n",
      "val Loss: 24.8490\n",
      "\n",
      "Epoch 790/2000\n",
      "train Loss: 1.5512\n",
      "val Loss: 34.3067\n",
      "\n",
      "Epoch 800/2000\n",
      "train Loss: 0.8040\n",
      "val Loss: 30.8262\n",
      "\n",
      "Epoch 810/2000\n",
      "train Loss: 0.1421\n",
      "val Loss: 40.5913\n",
      "\n",
      "Epoch 820/2000\n",
      "train Loss: 0.4894\n",
      "val Loss: 21.8734\n",
      "\n",
      "Epoch 830/2000\n",
      "train Loss: 0.7674\n",
      "val Loss: 97.2900\n",
      "\n",
      "Epoch 840/2000\n",
      "train Loss: 0.7956\n",
      "val Loss: 17.2711\n",
      "\n",
      "Epoch 850/2000\n",
      "train Loss: 0.5090\n",
      "val Loss: 34.9619\n",
      "\n",
      "Epoch 860/2000\n",
      "train Loss: 0.4860\n",
      "val Loss: 63.7540\n",
      "\n",
      "Epoch 870/2000\n",
      "train Loss: 0.7246\n",
      "val Loss: 18.4335\n",
      "\n",
      "Epoch 880/2000\n",
      "train Loss: 1.3627\n",
      "val Loss: 23.2348\n",
      "\n",
      "Epoch 890/2000\n",
      "train Loss: 0.7192\n",
      "val Loss: 18.3539\n",
      "\n",
      "Epoch 900/2000\n",
      "train Loss: 0.9076\n",
      "val Loss: 33.6727\n",
      "\n",
      "Epoch 910/2000\n",
      "train Loss: 1.0556\n",
      "val Loss: 16.9192\n",
      "\n",
      "Epoch 920/2000\n",
      "train Loss: 1.4179\n",
      "val Loss: 26.6557\n",
      "\n",
      "Epoch 930/2000\n",
      "train Loss: 1.3759\n",
      "val Loss: 49.6131\n",
      "\n",
      "Epoch 940/2000\n",
      "train Loss: 0.5054\n",
      "val Loss: 16.9198\n",
      "\n",
      "Epoch 950/2000\n",
      "train Loss: 0.9666\n",
      "val Loss: 26.3960\n",
      "\n",
      "Epoch 960/2000\n",
      "train Loss: 0.7990\n",
      "val Loss: 24.2427\n",
      "\n",
      "Epoch 970/2000\n",
      "train Loss: 0.8346\n",
      "val Loss: 21.6900\n",
      "\n",
      "Epoch 980/2000\n",
      "train Loss: 0.5055\n",
      "val Loss: 26.9838\n",
      "\n",
      "Epoch 990/2000\n",
      "train Loss: 0.4636\n",
      "val Loss: 17.5745\n",
      "\n",
      "Epoch 1000/2000\n",
      "train Loss: 0.9673\n",
      "val Loss: 21.4870\n",
      "\n",
      "Epoch 1010/2000\n",
      "train Loss: 0.3193\n",
      "val Loss: 23.0577\n",
      "\n",
      "Epoch 1020/2000\n",
      "train Loss: 0.8693\n",
      "val Loss: 28.6047\n",
      "\n",
      "Epoch 1030/2000\n",
      "train Loss: 0.4707\n",
      "val Loss: 18.3415\n",
      "\n",
      "Epoch 1040/2000\n",
      "train Loss: 0.6215\n",
      "val Loss: 34.9760\n",
      "\n",
      "Epoch 1050/2000\n",
      "train Loss: 0.6981\n",
      "val Loss: 15.5064\n",
      "\n",
      "Epoch 1060/2000\n",
      "train Loss: 1.1728\n",
      "val Loss: 25.4719\n",
      "\n",
      "Epoch 1070/2000\n",
      "train Loss: 0.5557\n",
      "val Loss: 21.3107\n",
      "\n",
      "Epoch 1080/2000\n",
      "train Loss: 0.4800\n",
      "val Loss: 23.4261\n",
      "\n",
      "Epoch 1090/2000\n",
      "train Loss: 1.2337\n",
      "val Loss: 18.5315\n",
      "\n",
      "Epoch 1100/2000\n",
      "train Loss: 0.7005\n",
      "val Loss: 27.2930\n",
      "\n",
      "Epoch 1110/2000\n",
      "train Loss: 0.4642\n",
      "val Loss: 26.0027\n",
      "\n",
      "Epoch 1120/2000\n",
      "train Loss: 1.1433\n",
      "val Loss: 19.4402\n",
      "\n",
      "Epoch 1130/2000\n",
      "train Loss: 1.1706\n",
      "val Loss: 25.4498\n",
      "\n",
      "Epoch 1140/2000\n",
      "train Loss: 0.4648\n",
      "val Loss: 24.0136\n",
      "\n",
      "Epoch 1150/2000\n",
      "train Loss: 0.3361\n",
      "val Loss: 19.6329\n",
      "\n",
      "Epoch 1160/2000\n",
      "train Loss: 0.4989\n",
      "val Loss: 23.3654\n",
      "\n",
      "Epoch 1170/2000\n",
      "train Loss: 0.3117\n",
      "val Loss: 20.0389\n",
      "\n",
      "Epoch 1180/2000\n",
      "train Loss: 1.0751\n",
      "val Loss: 20.0201\n",
      "\n",
      "Epoch 1190/2000\n",
      "train Loss: 0.3359\n",
      "val Loss: 24.0001\n",
      "\n",
      "Epoch 1200/2000\n",
      "train Loss: 0.2928\n",
      "val Loss: 24.5173\n",
      "\n",
      "Epoch 1210/2000\n",
      "train Loss: 0.5327\n",
      "val Loss: 35.6156\n",
      "\n",
      "Epoch 1220/2000\n",
      "train Loss: 1.2748\n",
      "val Loss: 23.1306\n",
      "\n",
      "Epoch 1230/2000\n",
      "train Loss: 1.6634\n",
      "val Loss: 14.7097\n",
      "\n",
      "Epoch 1240/2000\n",
      "train Loss: 1.1154\n",
      "val Loss: 19.8767\n",
      "\n",
      "Epoch 1250/2000\n",
      "train Loss: 0.3109\n",
      "val Loss: 19.4008\n",
      "\n",
      "Epoch 1260/2000\n",
      "train Loss: 0.9894\n",
      "val Loss: 36.0430\n",
      "\n",
      "Epoch 1270/2000\n",
      "train Loss: 1.3921\n",
      "val Loss: 35.0631\n",
      "\n",
      "Epoch 1280/2000\n",
      "train Loss: 0.5755\n",
      "val Loss: 17.3144\n",
      "\n",
      "Epoch 1290/2000\n",
      "train Loss: 0.3293\n",
      "val Loss: 19.1066\n",
      "\n",
      "Epoch 1300/2000\n",
      "train Loss: 0.6770\n",
      "val Loss: 32.6333\n",
      "\n",
      "Epoch 1310/2000\n",
      "train Loss: 0.2441\n",
      "val Loss: 28.2046\n",
      "\n",
      "Epoch 1320/2000\n",
      "train Loss: 1.3475\n",
      "val Loss: 17.8313\n",
      "\n",
      "Epoch 1330/2000\n",
      "train Loss: 0.6347\n",
      "val Loss: 22.6469\n",
      "\n",
      "Epoch 1340/2000\n",
      "train Loss: 0.7289\n",
      "val Loss: 21.6190\n",
      "\n",
      "Epoch 1350/2000\n",
      "train Loss: 0.6319\n",
      "val Loss: 19.8802\n",
      "\n",
      "Epoch 1360/2000\n",
      "train Loss: 0.2021\n",
      "val Loss: 19.2744\n",
      "\n",
      "Epoch 1370/2000\n",
      "train Loss: 0.2569\n",
      "val Loss: 29.2663\n",
      "\n",
      "Epoch 1380/2000\n",
      "train Loss: 1.1819\n",
      "val Loss: 14.6066\n",
      "\n",
      "Epoch 1390/2000\n",
      "train Loss: 0.5769\n",
      "val Loss: 17.9595\n",
      "\n",
      "Epoch 1400/2000\n",
      "train Loss: 2.4075\n",
      "val Loss: 23.4102\n",
      "\n",
      "Epoch 1410/2000\n",
      "train Loss: 0.2287\n",
      "val Loss: 22.8875\n",
      "\n",
      "Epoch 1420/2000\n",
      "train Loss: 0.7286\n",
      "val Loss: 26.9925\n",
      "\n",
      "Epoch 1430/2000\n",
      "train Loss: 0.9182\n",
      "val Loss: 38.8901\n",
      "\n",
      "Epoch 1440/2000\n",
      "train Loss: 0.3971\n",
      "val Loss: 21.6718\n",
      "\n",
      "Epoch 1450/2000\n",
      "train Loss: 0.9149\n",
      "val Loss: 27.7572\n",
      "\n",
      "Epoch 1460/2000\n",
      "train Loss: 0.7083\n",
      "val Loss: 23.9639\n",
      "\n",
      "Epoch 1470/2000\n",
      "train Loss: 0.4058\n",
      "val Loss: 23.1649\n",
      "\n",
      "Epoch 1480/2000\n",
      "train Loss: 0.5348\n",
      "val Loss: 26.2004\n",
      "\n",
      "Epoch 1490/2000\n",
      "train Loss: 0.8923\n",
      "val Loss: 20.5358\n",
      "\n",
      "Epoch 1500/2000\n",
      "train Loss: 0.5255\n",
      "val Loss: 22.8999\n",
      "\n",
      "Epoch 1510/2000\n",
      "train Loss: 0.3821\n",
      "val Loss: 24.4481\n",
      "\n",
      "Epoch 1520/2000\n",
      "train Loss: 0.5234\n",
      "val Loss: 24.5896\n",
      "\n",
      "Epoch 1530/2000\n",
      "train Loss: 0.7018\n",
      "val Loss: 24.0606\n",
      "\n",
      "Epoch 1540/2000\n",
      "train Loss: 0.2190\n",
      "val Loss: 32.6259\n",
      "\n",
      "Epoch 1550/2000\n",
      "train Loss: 0.7205\n",
      "val Loss: 21.9248\n",
      "\n",
      "Epoch 1560/2000\n",
      "train Loss: 0.3953\n",
      "val Loss: 26.2363\n",
      "\n",
      "Epoch 1570/2000\n",
      "train Loss: 0.2729\n",
      "val Loss: 24.3651\n",
      "\n",
      "Epoch 1580/2000\n",
      "train Loss: 0.3692\n",
      "val Loss: 22.9713\n",
      "\n",
      "Epoch 1590/2000\n",
      "train Loss: 0.9114\n",
      "val Loss: 46.1514\n",
      "\n",
      "Epoch 1600/2000\n",
      "train Loss: 0.6149\n",
      "val Loss: 32.4917\n",
      "\n",
      "Epoch 1610/2000\n",
      "train Loss: 0.4707\n",
      "val Loss: 25.6216\n",
      "\n",
      "Epoch 1620/2000\n",
      "train Loss: 0.2453\n",
      "val Loss: 20.6412\n",
      "\n",
      "Epoch 1630/2000\n",
      "train Loss: 0.4547\n",
      "val Loss: 25.0234\n",
      "\n",
      "Epoch 1640/2000\n",
      "train Loss: 0.3778\n",
      "val Loss: 20.6732\n",
      "\n",
      "Epoch 1650/2000\n",
      "train Loss: 0.5437\n",
      "val Loss: 33.8730\n",
      "\n",
      "Epoch 1660/2000\n",
      "train Loss: 0.5775\n",
      "val Loss: 33.7587\n",
      "\n",
      "Epoch 1670/2000\n",
      "train Loss: 0.5709\n",
      "val Loss: 19.8539\n",
      "\n",
      "Epoch 1680/2000\n",
      "train Loss: 0.3266\n",
      "val Loss: 31.9964\n",
      "\n",
      "Epoch 1690/2000\n",
      "train Loss: 0.2431\n",
      "val Loss: 20.6754\n",
      "\n",
      "Epoch 1700/2000\n",
      "train Loss: 0.5231\n",
      "val Loss: 20.4387\n",
      "\n",
      "Epoch 1710/2000\n",
      "train Loss: 0.3358\n",
      "val Loss: 32.5582\n",
      "\n",
      "Epoch 1720/2000\n",
      "train Loss: 1.5377\n",
      "val Loss: 20.0175\n",
      "\n",
      "Epoch 1730/2000\n",
      "train Loss: 0.2573\n",
      "val Loss: 19.5803\n",
      "\n",
      "Epoch 1740/2000\n",
      "train Loss: 1.0346\n",
      "val Loss: 25.3763\n",
      "\n",
      "Epoch 1750/2000\n",
      "train Loss: 0.4174\n",
      "val Loss: 15.1198\n",
      "\n",
      "Epoch 1760/2000\n",
      "train Loss: 0.7048\n",
      "val Loss: 19.8289\n",
      "\n",
      "Epoch 1770/2000\n",
      "train Loss: 0.8317\n",
      "val Loss: 25.0878\n",
      "\n",
      "Epoch 1780/2000\n",
      "train Loss: 0.2813\n",
      "val Loss: 21.8033\n",
      "\n",
      "Epoch 1790/2000\n",
      "train Loss: 0.4063\n",
      "val Loss: 15.7610\n",
      "\n",
      "Epoch 1800/2000\n",
      "train Loss: 0.2698\n",
      "val Loss: 23.8012\n",
      "\n",
      "Epoch 1810/2000\n",
      "train Loss: 0.1531\n",
      "val Loss: 21.2689\n",
      "\n",
      "Epoch 1820/2000\n",
      "train Loss: 0.2566\n",
      "val Loss: 19.9403\n",
      "\n",
      "Epoch 1830/2000\n",
      "train Loss: 0.1635\n",
      "val Loss: 15.2151\n",
      "\n",
      "Epoch 1840/2000\n",
      "train Loss: 0.3725\n",
      "val Loss: 24.0861\n",
      "\n",
      "Epoch 1850/2000\n",
      "train Loss: 0.3647\n",
      "val Loss: 24.4607\n",
      "\n",
      "Epoch 1860/2000\n",
      "train Loss: 0.3356\n",
      "val Loss: 19.1341\n",
      "\n",
      "Epoch 1870/2000\n",
      "train Loss: 0.1821\n",
      "val Loss: 25.3650\n",
      "\n",
      "Epoch 1880/2000\n",
      "train Loss: 0.7484\n",
      "val Loss: 21.4827\n",
      "\n",
      "Epoch 1890/2000\n",
      "train Loss: 0.4951\n",
      "val Loss: 17.6182\n",
      "\n",
      "Epoch 1900/2000\n",
      "train Loss: 0.2096\n",
      "val Loss: 17.9680\n",
      "\n",
      "Epoch 1910/2000\n",
      "train Loss: 1.2107\n",
      "val Loss: 30.9486\n",
      "\n",
      "Epoch 1920/2000\n",
      "train Loss: 0.5391\n",
      "val Loss: 18.5603\n",
      "\n",
      "Epoch 1930/2000\n",
      "train Loss: 0.3733\n",
      "val Loss: 22.6786\n",
      "\n",
      "Epoch 1940/2000\n",
      "train Loss: 0.3640\n",
      "val Loss: 20.8974\n",
      "\n",
      "Epoch 1950/2000\n",
      "train Loss: 1.7364\n",
      "val Loss: 18.1302\n",
      "\n",
      "Epoch 1960/2000\n",
      "train Loss: 0.7967\n",
      "val Loss: 31.3553\n",
      "\n",
      "Epoch 1970/2000\n",
      "train Loss: 0.2623\n",
      "val Loss: 16.6883\n",
      "\n",
      "Epoch 1980/2000\n",
      "train Loss: 0.2501\n",
      "val Loss: 26.8771\n",
      "\n",
      "Epoch 1990/2000\n",
      "train Loss: 0.4293\n",
      "val Loss: 17.9569\n",
      "\n",
      "Epoch 2000/2000\n",
      "train Loss: 0.4251\n",
      "val Loss: 17.3091\n",
      "\n",
      "Training complete in 1m 32s\n",
      "Best val Loss: 11.810436\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 12.21904 and R2: -21.2688\n",
      "test RMSE: 3.4956\n"
     ]
    }
   ],
   "source": [
    "# Case 4. LSTM_FCNs (w/o data representation)\n",
    "config = config4\n",
    "data_reg = mr.Regression(config, train_data, test_data, use_representation=True)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bab3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_x =pd.read_csv('./data/train_new_energy.csv').values\n",
    "test_x = pd.read_csv('./data/test_new_energy.csv').values\n",
    "\n",
    "train_y = pd.read_csv('./data/train_new_energy_y.csv').values\n",
    "test_y = pd.read_csv('./data/test_new_energy_y.csv').values\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "261459e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/2000\n",
      "train Loss: 230.8990\n",
      "val Loss: 195.0663\n",
      "\n",
      "Epoch 10/2000\n",
      "train Loss: 204.2068\n",
      "val Loss: 172.1549\n",
      "\n",
      "Epoch 20/2000\n",
      "train Loss: 179.6896\n",
      "val Loss: 149.7107\n",
      "\n",
      "Epoch 30/2000\n",
      "train Loss: 157.1175\n",
      "val Loss: 130.3498\n",
      "\n",
      "Epoch 40/2000\n",
      "train Loss: 133.8857\n",
      "val Loss: 111.6359\n",
      "\n",
      "Epoch 50/2000\n",
      "train Loss: 112.1209\n",
      "val Loss: 92.1628\n",
      "\n",
      "Epoch 60/2000\n",
      "train Loss: 92.9869\n",
      "val Loss: 74.8337\n",
      "\n",
      "Epoch 70/2000\n",
      "train Loss: 77.6394\n",
      "val Loss: 60.4213\n",
      "\n",
      "Epoch 80/2000\n",
      "train Loss: 63.5292\n",
      "val Loss: 48.4655\n",
      "\n",
      "Epoch 90/2000\n",
      "train Loss: 51.1169\n",
      "val Loss: 38.8648\n",
      "\n",
      "Epoch 100/2000\n",
      "train Loss: 43.2211\n",
      "val Loss: 31.4259\n",
      "\n",
      "Epoch 110/2000\n",
      "train Loss: 37.9837\n",
      "val Loss: 26.0214\n",
      "\n",
      "Epoch 120/2000\n",
      "train Loss: 32.3637\n",
      "val Loss: 22.1450\n",
      "\n",
      "Epoch 130/2000\n",
      "train Loss: 30.0149\n",
      "val Loss: 19.6046\n",
      "\n",
      "Epoch 140/2000\n",
      "train Loss: 27.2543\n",
      "val Loss: 17.9141\n",
      "\n",
      "Epoch 150/2000\n",
      "train Loss: 26.0799\n",
      "val Loss: 16.9205\n",
      "\n",
      "Epoch 160/2000\n",
      "train Loss: 24.7485\n",
      "val Loss: 16.4321\n",
      "\n",
      "Epoch 170/2000\n",
      "train Loss: 24.7557\n",
      "val Loss: 16.1334\n",
      "\n",
      "Epoch 180/2000\n",
      "train Loss: 23.5373\n",
      "val Loss: 15.9705\n",
      "\n",
      "Epoch 190/2000\n",
      "train Loss: 25.2640\n",
      "val Loss: 15.9052\n",
      "\n",
      "Epoch 200/2000\n",
      "train Loss: 23.6859\n",
      "val Loss: 15.8759\n",
      "\n",
      "Epoch 210/2000\n",
      "train Loss: 24.0738\n",
      "val Loss: 15.8543\n",
      "\n",
      "Epoch 220/2000\n",
      "train Loss: 23.3056\n",
      "val Loss: 15.8496\n",
      "\n",
      "Epoch 230/2000\n",
      "train Loss: 23.8772\n",
      "val Loss: 15.8483\n",
      "\n",
      "Epoch 240/2000\n",
      "train Loss: 24.3231\n",
      "val Loss: 15.8369\n",
      "\n",
      "Epoch 250/2000\n",
      "train Loss: 24.5013\n",
      "val Loss: 15.8247\n",
      "\n",
      "Epoch 260/2000\n",
      "train Loss: 23.4901\n",
      "val Loss: 15.8183\n",
      "\n",
      "Epoch 270/2000\n",
      "train Loss: 24.0606\n",
      "val Loss: 15.8053\n",
      "\n",
      "Epoch 280/2000\n",
      "train Loss: 24.2553\n",
      "val Loss: 15.8090\n",
      "\n",
      "Epoch 290/2000\n",
      "train Loss: 23.4537\n",
      "val Loss: 15.8180\n",
      "\n",
      "Epoch 300/2000\n",
      "train Loss: 23.5464\n",
      "val Loss: 15.8047\n",
      "\n",
      "Epoch 310/2000\n",
      "train Loss: 24.6318\n",
      "val Loss: 15.7936\n",
      "\n",
      "Epoch 320/2000\n",
      "train Loss: 23.3785\n",
      "val Loss: 15.7768\n",
      "\n",
      "Epoch 330/2000\n",
      "train Loss: 23.4403\n",
      "val Loss: 15.7787\n",
      "\n",
      "Epoch 340/2000\n",
      "train Loss: 23.3104\n",
      "val Loss: 15.7917\n",
      "\n",
      "Epoch 350/2000\n",
      "train Loss: 23.6145\n",
      "val Loss: 15.8050\n",
      "\n",
      "Epoch 360/2000\n",
      "train Loss: 22.7141\n",
      "val Loss: 15.7955\n",
      "\n",
      "Epoch 370/2000\n",
      "train Loss: 22.3339\n",
      "val Loss: 15.7757\n",
      "\n",
      "Epoch 380/2000\n",
      "train Loss: 23.5962\n",
      "val Loss: 15.7717\n",
      "\n",
      "Epoch 390/2000\n",
      "train Loss: 23.3901\n",
      "val Loss: 15.7683\n",
      "\n",
      "Epoch 400/2000\n",
      "train Loss: 23.6365\n",
      "val Loss: 15.7690\n",
      "\n",
      "Epoch 410/2000\n",
      "train Loss: 22.8191\n",
      "val Loss: 15.7450\n",
      "\n",
      "Epoch 420/2000\n",
      "train Loss: 23.3206\n",
      "val Loss: 15.7472\n",
      "\n",
      "Epoch 430/2000\n",
      "train Loss: 23.4086\n",
      "val Loss: 15.7522\n",
      "\n",
      "Epoch 440/2000\n",
      "train Loss: 24.4702\n",
      "val Loss: 15.7766\n",
      "\n",
      "Epoch 450/2000\n",
      "train Loss: 23.8646\n",
      "val Loss: 15.7443\n",
      "\n",
      "Epoch 460/2000\n",
      "train Loss: 22.9713\n",
      "val Loss: 15.6922\n",
      "\n",
      "Epoch 470/2000\n",
      "train Loss: 22.8071\n",
      "val Loss: 15.6734\n",
      "\n",
      "Epoch 480/2000\n",
      "train Loss: 22.8298\n",
      "val Loss: 15.6647\n",
      "\n",
      "Epoch 490/2000\n",
      "train Loss: 23.5340\n",
      "val Loss: 15.6291\n",
      "\n",
      "Epoch 500/2000\n",
      "train Loss: 23.2289\n",
      "val Loss: 15.6043\n",
      "\n",
      "Epoch 510/2000\n",
      "train Loss: 23.0859\n",
      "val Loss: 15.5969\n",
      "\n",
      "Epoch 520/2000\n",
      "train Loss: 22.5847\n",
      "val Loss: 15.5921\n",
      "\n",
      "Epoch 530/2000\n",
      "train Loss: 22.6388\n",
      "val Loss: 15.5959\n",
      "\n",
      "Epoch 540/2000\n",
      "train Loss: 22.3161\n",
      "val Loss: 15.6211\n",
      "\n",
      "Epoch 550/2000\n",
      "train Loss: 23.4062\n",
      "val Loss: 15.5883\n",
      "\n",
      "Epoch 560/2000\n",
      "train Loss: 22.3073\n",
      "val Loss: 15.5790\n",
      "\n",
      "Epoch 570/2000\n",
      "train Loss: 22.1782\n",
      "val Loss: 15.5323\n",
      "\n",
      "Epoch 580/2000\n",
      "train Loss: 22.7845\n",
      "val Loss: 15.5191\n",
      "\n",
      "Epoch 590/2000\n",
      "train Loss: 23.8486\n",
      "val Loss: 15.5283\n",
      "\n",
      "Epoch 600/2000\n",
      "train Loss: 21.8000\n",
      "val Loss: 15.4931\n",
      "\n",
      "Epoch 610/2000\n",
      "train Loss: 22.5177\n",
      "val Loss: 15.4958\n",
      "\n",
      "Epoch 620/2000\n",
      "train Loss: 21.3879\n",
      "val Loss: 15.4674\n",
      "\n",
      "Epoch 630/2000\n",
      "train Loss: 22.9445\n",
      "val Loss: 15.4126\n",
      "\n",
      "Epoch 640/2000\n",
      "train Loss: 22.5652\n",
      "val Loss: 15.3971\n",
      "\n",
      "Epoch 650/2000\n",
      "train Loss: 22.0584\n",
      "val Loss: 15.3909\n",
      "\n",
      "Epoch 660/2000\n",
      "train Loss: 22.6968\n",
      "val Loss: 15.4345\n",
      "\n",
      "Epoch 670/2000\n",
      "train Loss: 23.1258\n",
      "val Loss: 15.4475\n",
      "\n",
      "Epoch 680/2000\n",
      "train Loss: 21.8108\n",
      "val Loss: 15.3751\n",
      "\n",
      "Epoch 690/2000\n",
      "train Loss: 22.7483\n",
      "val Loss: 15.3266\n",
      "\n",
      "Epoch 700/2000\n",
      "train Loss: 21.9344\n",
      "val Loss: 15.3334\n",
      "\n",
      "Epoch 710/2000\n",
      "train Loss: 22.0869\n",
      "val Loss: 15.3101\n",
      "\n",
      "Epoch 720/2000\n",
      "train Loss: 22.2449\n",
      "val Loss: 15.2679\n",
      "\n",
      "Epoch 730/2000\n",
      "train Loss: 23.2258\n",
      "val Loss: 15.2553\n",
      "\n",
      "Epoch 740/2000\n",
      "train Loss: 21.0346\n",
      "val Loss: 15.2443\n",
      "\n",
      "Epoch 750/2000\n",
      "train Loss: 23.3516\n",
      "val Loss: 15.2254\n",
      "\n",
      "Epoch 760/2000\n",
      "train Loss: 22.0992\n",
      "val Loss: 15.2397\n",
      "\n",
      "Epoch 770/2000\n",
      "train Loss: 22.8247\n",
      "val Loss: 15.2381\n",
      "\n",
      "Epoch 780/2000\n",
      "train Loss: 22.3827\n",
      "val Loss: 15.2018\n",
      "\n",
      "Epoch 790/2000\n",
      "train Loss: 22.8504\n",
      "val Loss: 15.2129\n",
      "\n",
      "Epoch 800/2000\n",
      "train Loss: 23.3451\n",
      "val Loss: 15.1954\n",
      "\n",
      "Epoch 810/2000\n",
      "train Loss: 23.0873\n",
      "val Loss: 15.1730\n",
      "\n",
      "Epoch 820/2000\n",
      "train Loss: 22.3812\n",
      "val Loss: 15.1676\n",
      "\n",
      "Epoch 830/2000\n",
      "train Loss: 21.6098\n",
      "val Loss: 15.1825\n",
      "\n",
      "Epoch 840/2000\n",
      "train Loss: 22.3526\n",
      "val Loss: 15.1838\n",
      "\n",
      "Epoch 850/2000\n",
      "train Loss: 21.6331\n",
      "val Loss: 15.1162\n",
      "\n",
      "Epoch 860/2000\n",
      "train Loss: 21.5590\n",
      "val Loss: 15.0811\n",
      "\n",
      "Epoch 870/2000\n",
      "train Loss: 22.4990\n",
      "val Loss: 15.0268\n",
      "\n",
      "Epoch 880/2000\n",
      "train Loss: 21.9914\n",
      "val Loss: 15.0516\n",
      "\n",
      "Epoch 890/2000\n",
      "train Loss: 21.4670\n",
      "val Loss: 15.0507\n",
      "\n",
      "Epoch 900/2000\n",
      "train Loss: 22.4427\n",
      "val Loss: 14.9806\n",
      "\n",
      "Epoch 910/2000\n",
      "train Loss: 21.9125\n",
      "val Loss: 14.9813\n",
      "\n",
      "Epoch 920/2000\n",
      "train Loss: 21.3372\n",
      "val Loss: 15.0352\n",
      "\n",
      "Epoch 930/2000\n",
      "train Loss: 21.5440\n",
      "val Loss: 15.0569\n",
      "\n",
      "Epoch 940/2000\n",
      "train Loss: 21.8428\n",
      "val Loss: 15.0335\n",
      "\n",
      "Epoch 950/2000\n",
      "train Loss: 23.2608\n",
      "val Loss: 14.9571\n",
      "\n",
      "Epoch 960/2000\n",
      "train Loss: 22.2442\n",
      "val Loss: 14.9377\n",
      "\n",
      "Epoch 970/2000\n",
      "train Loss: 21.7761\n",
      "val Loss: 14.9343\n",
      "\n",
      "Epoch 980/2000\n",
      "train Loss: 22.8280\n",
      "val Loss: 14.9815\n",
      "\n",
      "Epoch 990/2000\n",
      "train Loss: 22.7927\n",
      "val Loss: 14.8852\n",
      "\n",
      "Epoch 1000/2000\n",
      "train Loss: 22.2549\n",
      "val Loss: 14.9215\n",
      "\n",
      "Epoch 1010/2000\n",
      "train Loss: 21.3756\n",
      "val Loss: 15.0456\n",
      "\n",
      "Epoch 1020/2000\n",
      "train Loss: 22.7831\n",
      "val Loss: 14.9061\n",
      "\n",
      "Epoch 1030/2000\n",
      "train Loss: 22.3961\n",
      "val Loss: 14.8713\n",
      "\n",
      "Epoch 1040/2000\n",
      "train Loss: 22.5807\n",
      "val Loss: 14.8935\n",
      "\n",
      "Epoch 1050/2000\n",
      "train Loss: 22.6889\n",
      "val Loss: 14.9070\n",
      "\n",
      "Epoch 1060/2000\n",
      "train Loss: 22.2802\n",
      "val Loss: 14.9006\n",
      "\n",
      "Epoch 1070/2000\n",
      "train Loss: 21.7746\n",
      "val Loss: 14.8813\n",
      "\n",
      "Epoch 1080/2000\n",
      "train Loss: 22.1694\n",
      "val Loss: 14.8625\n",
      "\n",
      "Epoch 1090/2000\n",
      "train Loss: 22.4528\n",
      "val Loss: 14.8443\n",
      "\n",
      "Epoch 1100/2000\n",
      "train Loss: 21.3237\n",
      "val Loss: 14.9094\n",
      "\n",
      "Epoch 1110/2000\n",
      "train Loss: 21.9481\n",
      "val Loss: 14.8691\n",
      "\n",
      "Epoch 1120/2000\n",
      "train Loss: 21.5484\n",
      "val Loss: 14.8459\n",
      "\n",
      "Epoch 1130/2000\n",
      "train Loss: 21.7212\n",
      "val Loss: 14.8578\n",
      "\n",
      "Epoch 1140/2000\n",
      "train Loss: 21.3475\n",
      "val Loss: 14.7587\n",
      "\n",
      "Epoch 1150/2000\n",
      "train Loss: 21.2338\n",
      "val Loss: 14.7506\n",
      "\n",
      "Epoch 1160/2000\n",
      "train Loss: 20.8283\n",
      "val Loss: 14.7969\n",
      "\n",
      "Epoch 1170/2000\n",
      "train Loss: 21.4902\n",
      "val Loss: 14.8090\n",
      "\n",
      "Epoch 1180/2000\n",
      "train Loss: 20.8936\n",
      "val Loss: 14.7692\n",
      "\n",
      "Epoch 1190/2000\n",
      "train Loss: 22.0429\n",
      "val Loss: 14.7088\n",
      "\n",
      "Epoch 1200/2000\n",
      "train Loss: 21.4793\n",
      "val Loss: 14.7314\n",
      "\n",
      "Epoch 1210/2000\n",
      "train Loss: 21.9622\n",
      "val Loss: 14.7341\n",
      "\n",
      "Epoch 1220/2000\n",
      "train Loss: 22.4627\n",
      "val Loss: 14.8058\n",
      "\n",
      "Epoch 1230/2000\n",
      "train Loss: 22.3519\n",
      "val Loss: 14.7701\n",
      "\n",
      "Epoch 1240/2000\n",
      "train Loss: 22.1855\n",
      "val Loss: 14.6917\n",
      "\n",
      "Epoch 1250/2000\n",
      "train Loss: 21.5782\n",
      "val Loss: 14.7011\n",
      "\n",
      "Epoch 1260/2000\n",
      "train Loss: 21.1632\n",
      "val Loss: 14.7487\n",
      "\n",
      "Epoch 1270/2000\n",
      "train Loss: 21.8423\n",
      "val Loss: 14.7860\n",
      "\n",
      "Epoch 1280/2000\n",
      "train Loss: 21.9492\n",
      "val Loss: 14.7714\n",
      "\n",
      "Epoch 1290/2000\n",
      "train Loss: 21.0338\n",
      "val Loss: 14.7272\n",
      "\n",
      "Epoch 1300/2000\n",
      "train Loss: 21.4367\n",
      "val Loss: 14.7480\n",
      "\n",
      "Epoch 1310/2000\n",
      "train Loss: 21.3159\n",
      "val Loss: 14.7413\n",
      "\n",
      "Epoch 1320/2000\n",
      "train Loss: 21.6443\n",
      "val Loss: 14.7215\n",
      "\n",
      "Epoch 1330/2000\n",
      "train Loss: 22.2716\n",
      "val Loss: 14.6527\n",
      "\n",
      "Epoch 1340/2000\n",
      "train Loss: 21.0092\n",
      "val Loss: 14.6876\n",
      "\n",
      "Epoch 1350/2000\n",
      "train Loss: 21.7543\n",
      "val Loss: 14.6117\n",
      "\n",
      "Epoch 1360/2000\n",
      "train Loss: 22.6207\n",
      "val Loss: 14.6473\n",
      "\n",
      "Epoch 1370/2000\n",
      "train Loss: 22.2159\n",
      "val Loss: 14.6814\n",
      "\n",
      "Epoch 1380/2000\n",
      "train Loss: 21.3760\n",
      "val Loss: 14.6876\n",
      "\n",
      "Epoch 1390/2000\n",
      "train Loss: 20.9528\n",
      "val Loss: 14.6569\n",
      "\n",
      "Epoch 1400/2000\n",
      "train Loss: 21.8405\n",
      "val Loss: 14.7278\n",
      "\n",
      "Epoch 1410/2000\n",
      "train Loss: 21.8707\n",
      "val Loss: 14.6725\n",
      "\n",
      "Epoch 1420/2000\n",
      "train Loss: 22.4013\n",
      "val Loss: 14.7155\n",
      "\n",
      "Epoch 1430/2000\n",
      "train Loss: 21.2633\n",
      "val Loss: 14.6753\n",
      "\n",
      "Epoch 1440/2000\n",
      "train Loss: 21.0551\n",
      "val Loss: 14.6121\n",
      "\n",
      "Epoch 1450/2000\n",
      "train Loss: 20.7932\n",
      "val Loss: 14.6341\n",
      "\n",
      "Epoch 1460/2000\n",
      "train Loss: 20.8004\n",
      "val Loss: 14.6013\n",
      "\n",
      "Epoch 1470/2000\n",
      "train Loss: 21.8052\n",
      "val Loss: 14.5811\n",
      "\n",
      "Epoch 1480/2000\n",
      "train Loss: 22.4152\n",
      "val Loss: 14.7079\n",
      "\n",
      "Epoch 1490/2000\n",
      "train Loss: 20.7168\n",
      "val Loss: 14.6074\n",
      "\n",
      "Epoch 1500/2000\n",
      "train Loss: 21.5419\n",
      "val Loss: 14.5677\n",
      "\n",
      "Epoch 1510/2000\n",
      "train Loss: 20.6375\n",
      "val Loss: 14.7163\n",
      "\n",
      "Epoch 1520/2000\n",
      "train Loss: 21.1382\n",
      "val Loss: 14.5735\n",
      "\n",
      "Epoch 1530/2000\n",
      "train Loss: 21.6904\n",
      "val Loss: 14.5864\n",
      "\n",
      "Epoch 1540/2000\n",
      "train Loss: 21.3834\n",
      "val Loss: 14.7222\n",
      "\n",
      "Epoch 1550/2000\n",
      "train Loss: 21.4506\n",
      "val Loss: 14.6500\n",
      "\n",
      "Epoch 1560/2000\n",
      "train Loss: 21.0227\n",
      "val Loss: 14.6130\n",
      "\n",
      "Epoch 1570/2000\n",
      "train Loss: 21.4165\n",
      "val Loss: 14.6067\n",
      "\n",
      "Epoch 1580/2000\n",
      "train Loss: 21.4953\n",
      "val Loss: 14.6233\n",
      "\n",
      "Epoch 1590/2000\n",
      "train Loss: 21.8918\n",
      "val Loss: 14.5754\n",
      "\n",
      "Epoch 1600/2000\n",
      "train Loss: 21.3305\n",
      "val Loss: 14.5915\n",
      "\n",
      "Epoch 1610/2000\n",
      "train Loss: 21.9919\n",
      "val Loss: 14.6526\n",
      "\n",
      "Epoch 1620/2000\n",
      "train Loss: 22.1243\n",
      "val Loss: 14.6194\n",
      "\n",
      "Epoch 1630/2000\n",
      "train Loss: 22.1695\n",
      "val Loss: 14.6194\n",
      "\n",
      "Epoch 1640/2000\n",
      "train Loss: 21.6287\n",
      "val Loss: 14.4862\n",
      "\n",
      "Epoch 1650/2000\n",
      "train Loss: 21.2891\n",
      "val Loss: 14.5288\n",
      "\n",
      "Epoch 1660/2000\n",
      "train Loss: 22.0166\n",
      "val Loss: 14.5229\n",
      "\n",
      "Epoch 1670/2000\n",
      "train Loss: 21.1205\n",
      "val Loss: 14.6200\n",
      "\n",
      "Epoch 1680/2000\n",
      "train Loss: 21.7923\n",
      "val Loss: 14.4954\n",
      "\n",
      "Epoch 1690/2000\n",
      "train Loss: 21.0879\n",
      "val Loss: 14.5464\n",
      "\n",
      "Epoch 1700/2000\n",
      "train Loss: 22.3637\n",
      "val Loss: 14.5441\n",
      "\n",
      "Epoch 1710/2000\n",
      "train Loss: 22.0111\n",
      "val Loss: 14.5194\n",
      "\n",
      "Epoch 1720/2000\n",
      "train Loss: 21.1206\n",
      "val Loss: 14.5385\n",
      "\n",
      "Epoch 1730/2000\n",
      "train Loss: 21.5186\n",
      "val Loss: 14.5602\n",
      "\n",
      "Epoch 1740/2000\n",
      "train Loss: 21.7735\n",
      "val Loss: 14.5641\n",
      "\n",
      "Epoch 1750/2000\n",
      "train Loss: 21.5208\n",
      "val Loss: 14.5416\n",
      "\n",
      "Epoch 1760/2000\n",
      "train Loss: 21.5467\n",
      "val Loss: 14.4235\n",
      "\n",
      "Epoch 1770/2000\n",
      "train Loss: 21.0067\n",
      "val Loss: 14.5123\n",
      "\n",
      "Epoch 1780/2000\n",
      "train Loss: 21.5770\n",
      "val Loss: 14.5407\n",
      "\n",
      "Epoch 1790/2000\n",
      "train Loss: 22.0847\n",
      "val Loss: 14.5421\n",
      "\n",
      "Epoch 1800/2000\n",
      "train Loss: 21.3308\n",
      "val Loss: 14.4635\n",
      "\n",
      "Epoch 1810/2000\n",
      "train Loss: 20.9264\n",
      "val Loss: 14.4966\n",
      "\n",
      "Epoch 1820/2000\n",
      "train Loss: 22.6602\n",
      "val Loss: 14.4769\n",
      "\n",
      "Epoch 1830/2000\n",
      "train Loss: 21.7735\n",
      "val Loss: 14.5523\n",
      "\n",
      "Epoch 1840/2000\n",
      "train Loss: 20.4976\n",
      "val Loss: 14.5683\n",
      "\n",
      "Epoch 1850/2000\n",
      "train Loss: 22.4604\n",
      "val Loss: 14.5482\n",
      "\n",
      "Epoch 1860/2000\n",
      "train Loss: 20.9676\n",
      "val Loss: 14.6017\n",
      "\n",
      "Epoch 1870/2000\n",
      "train Loss: 21.4181\n",
      "val Loss: 14.5020\n",
      "\n",
      "Epoch 1880/2000\n",
      "train Loss: 21.9344\n",
      "val Loss: 14.4814\n",
      "\n",
      "Epoch 1890/2000\n",
      "train Loss: 21.7515\n",
      "val Loss: 14.5474\n",
      "\n",
      "Epoch 1900/2000\n",
      "train Loss: 21.1857\n",
      "val Loss: 14.6232\n",
      "\n",
      "Epoch 1910/2000\n",
      "train Loss: 21.0789\n",
      "val Loss: 14.6149\n",
      "\n",
      "Epoch 1920/2000\n",
      "train Loss: 22.4059\n",
      "val Loss: 14.4618\n",
      "\n",
      "Epoch 1930/2000\n",
      "train Loss: 21.3152\n",
      "val Loss: 14.5228\n",
      "\n",
      "Epoch 1940/2000\n",
      "train Loss: 21.6445\n",
      "val Loss: 14.4684\n",
      "\n",
      "Epoch 1950/2000\n",
      "train Loss: 21.3155\n",
      "val Loss: 14.5416\n",
      "\n",
      "Epoch 1960/2000\n",
      "train Loss: 21.3947\n",
      "val Loss: 14.5067\n",
      "\n",
      "Epoch 1970/2000\n",
      "train Loss: 22.1739\n",
      "val Loss: 14.4825\n",
      "\n",
      "Epoch 1980/2000\n",
      "train Loss: 22.6241\n",
      "val Loss: 14.5039\n",
      "\n",
      "Epoch 1990/2000\n",
      "train Loss: 21.0502\n",
      "val Loss: 14.4882\n",
      "\n",
      "Epoch 2000/2000\n",
      "train Loss: 21.8181\n",
      "val Loss: 14.4686\n",
      "\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 14.411633\n",
      "\n",
      "Start testing data\n",
      "\n",
      "test Loss: 12.62731 and R2: -13.58275\n",
      "test RMSE: 3.5535\n"
     ]
    }
   ],
   "source": [
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "\n",
    "# raw time seires data for regression\n",
    "config = config5\n",
    "data_reg = mr.Regression(config, train_data, test_data, use_representation = True)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "y_true, pred, mse, r2 = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측\n",
    "print(f'test Loss: {np.round(mse,5)} and R2: {np.round(r2,5)}')\n",
    "print(f'test RMSE: {np.round(np.sqrt(mse), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39838361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7e6565a69c64523dea2d3b31d6ed9f8445dc9714e18e3f5d2b2bc6eff30a54c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
