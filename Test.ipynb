{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import main_regression as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config1 = {\n",
    "        'model': 'LSTM', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 500,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 2. GRU model (w/o data representation)\n",
    "config2 = {\n",
    "        'model': 'GRU', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 1000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 3. CNN_1D model (w/o data representation)\n",
    "config3 = {\n",
    "        'model': 'CNN_1D', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/cnn_1d.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'seq_len': 144,  # 데이터의 시간 길이, int\n",
    "            'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "            'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "            'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "            'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 1000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 4. LSTM_FCNs model (w/o data representation)\n",
    "config4 = {\n",
    "        'model': 'LSTM_FCNs', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm_fcn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 24,  # 데이터의 변수 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "            'lstm_drop_out': 0.1, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "            'fc_drop_out': 0.1, # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 1000, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config5 = {\n",
    "        'model': 'FC', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/fc.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 64,  # 데이터의 변수 개수(representation 차원), int\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bias': True, # bias 사용 여부, bool(default: True)\n",
    "            'num_epochs': 1000, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 16,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 24, 144)\n",
      "(95,)\n",
      "(42, 24, 144)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "# raw time series data\n",
    "train_x = pickle.load(open('./data/x_train.pkl', 'rb'))\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "test_x = pickle.load(open('./data/x_test.pkl', 'rb'))\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (95, 24, 144)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (95,)\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (42, 24, 144)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/500\n",
      "train Loss: 223.7674\n",
      "val Loss: 190.3345\n",
      "\n",
      "Epoch 10/500\n",
      "train Loss: 210.2965\n",
      "val Loss: 177.4592\n",
      "\n",
      "Epoch 20/500\n",
      "train Loss: 180.4303\n",
      "val Loss: 148.4286\n",
      "\n",
      "Epoch 30/500\n",
      "train Loss: 144.4305\n",
      "val Loss: 116.1962\n",
      "\n",
      "Epoch 40/500\n",
      "train Loss: 119.0877\n",
      "val Loss: 93.6555\n",
      "\n",
      "Epoch 50/500\n",
      "train Loss: 99.2963\n",
      "val Loss: 76.1784\n",
      "\n",
      "Epoch 60/500\n",
      "train Loss: 83.4011\n",
      "val Loss: 62.2586\n",
      "\n",
      "Epoch 70/500\n",
      "train Loss: 70.4260\n",
      "val Loss: 51.1112\n",
      "\n",
      "Epoch 80/500\n",
      "train Loss: 60.1143\n",
      "val Loss: 42.4102\n",
      "\n",
      "Epoch 90/500\n",
      "train Loss: 51.2951\n",
      "val Loss: 35.1722\n",
      "\n",
      "Epoch 100/500\n",
      "train Loss: 44.4562\n",
      "val Loss: 29.6943\n",
      "\n",
      "Epoch 110/500\n",
      "train Loss: 39.0166\n",
      "val Loss: 25.4268\n",
      "\n",
      "Epoch 120/500\n",
      "train Loss: 34.6994\n",
      "val Loss: 22.1687\n",
      "\n",
      "Epoch 130/500\n",
      "train Loss: 31.2190\n",
      "val Loss: 19.6624\n",
      "\n",
      "Epoch 140/500\n",
      "train Loss: 28.4767\n",
      "val Loss: 17.7805\n",
      "\n",
      "Epoch 150/500\n",
      "train Loss: 26.2840\n",
      "val Loss: 16.3688\n",
      "\n",
      "Epoch 160/500\n",
      "train Loss: 24.4931\n",
      "val Loss: 15.3279\n",
      "\n",
      "Epoch 170/500\n",
      "train Loss: 23.1821\n",
      "val Loss: 14.6373\n",
      "\n",
      "Epoch 180/500\n",
      "train Loss: 22.1717\n",
      "val Loss: 14.1857\n",
      "\n",
      "Epoch 190/500\n",
      "train Loss: 21.4109\n",
      "val Loss: 13.9166\n",
      "\n",
      "Epoch 200/500\n",
      "train Loss: 20.8486\n",
      "val Loss: 13.7774\n",
      "\n",
      "Epoch 210/500\n",
      "train Loss: 20.4399\n",
      "val Loss: 13.7297\n",
      "\n",
      "Epoch 220/500\n",
      "train Loss: 20.1232\n",
      "val Loss: 13.7449\n",
      "\n",
      "Epoch 230/500\n",
      "train Loss: 19.8889\n",
      "val Loss: 13.8015\n",
      "\n",
      "Epoch 240/500\n",
      "train Loss: 19.7354\n",
      "val Loss: 13.8815\n",
      "\n",
      "Epoch 250/500\n",
      "train Loss: 19.6240\n",
      "val Loss: 13.9715\n",
      "\n",
      "Epoch 260/500\n",
      "train Loss: 19.5392\n",
      "val Loss: 14.0684\n",
      "\n",
      "Epoch 270/500\n",
      "train Loss: 19.4897\n",
      "val Loss: 14.1504\n",
      "\n",
      "Epoch 280/500\n",
      "train Loss: 19.4536\n",
      "val Loss: 14.2407\n",
      "\n",
      "Epoch 290/500\n",
      "train Loss: 19.4249\n",
      "val Loss: 14.3066\n",
      "\n",
      "Epoch 300/500\n",
      "train Loss: 19.3940\n",
      "val Loss: 14.2827\n",
      "\n",
      "Epoch 310/500\n",
      "train Loss: 19.3764\n",
      "val Loss: 14.3400\n",
      "\n",
      "Epoch 320/500\n",
      "train Loss: 19.3600\n",
      "val Loss: 14.3630\n",
      "\n",
      "Epoch 330/500\n",
      "train Loss: 19.3467\n",
      "val Loss: 14.3559\n",
      "\n",
      "Epoch 340/500\n",
      "train Loss: 19.3367\n",
      "val Loss: 14.3761\n",
      "\n",
      "Epoch 350/500\n",
      "train Loss: 19.3206\n",
      "val Loss: 14.3691\n",
      "\n",
      "Epoch 360/500\n",
      "train Loss: 19.3048\n",
      "val Loss: 14.3787\n",
      "\n",
      "Epoch 370/500\n",
      "train Loss: 19.2993\n",
      "val Loss: 14.4056\n",
      "\n",
      "Epoch 380/500\n",
      "train Loss: 19.2955\n",
      "val Loss: 14.4463\n",
      "\n",
      "Epoch 390/500\n",
      "train Loss: 19.2928\n",
      "val Loss: 14.4490\n",
      "\n",
      "Epoch 400/500\n",
      "train Loss: 19.2906\n",
      "val Loss: 14.4803\n",
      "\n",
      "Epoch 410/500\n",
      "train Loss: 19.2840\n",
      "val Loss: 14.4709\n",
      "\n",
      "Epoch 420/500\n",
      "train Loss: 19.2830\n",
      "val Loss: 14.4980\n",
      "\n",
      "Epoch 430/500\n",
      "train Loss: 19.2810\n",
      "val Loss: 14.4903\n",
      "\n",
      "Epoch 440/500\n",
      "train Loss: 19.2776\n",
      "val Loss: 14.4874\n",
      "\n",
      "Epoch 450/500\n",
      "train Loss: 19.2742\n",
      "val Loss: 14.4849\n",
      "\n",
      "Epoch 460/500\n",
      "train Loss: 19.2723\n",
      "val Loss: 14.4800\n",
      "\n",
      "Epoch 470/500\n",
      "train Loss: 19.2703\n",
      "val Loss: 14.4822\n",
      "\n",
      "Epoch 480/500\n",
      "train Loss: 19.2543\n",
      "val Loss: 14.4581\n",
      "\n",
      "Epoch 490/500\n",
      "train Loss: 19.2452\n",
      "val Loss: 14.3727\n",
      "\n",
      "Epoch 500/500\n",
      "train Loss: 19.1760\n",
      "val Loss: 14.3377\n",
      "\n",
      "Training complete in 0m 26s\n",
      "Best val MSE: 13.728384\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config = config1\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 12.008537292480469, MAE = 2.677595853805542\n",
      "** Dimension of result for test dataset = (42,)\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'** Dimension of result for test dataset = {pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 229.5786\n",
      "val Loss: 192.9325\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 187.6285\n",
      "val Loss: 154.8381\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 143.4505\n",
      "val Loss: 114.8124\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 112.7122\n",
      "val Loss: 87.7767\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 90.7212\n",
      "val Loss: 68.4279\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 73.8049\n",
      "val Loss: 53.8836\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 61.0374\n",
      "val Loss: 43.0878\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 51.1302\n",
      "val Loss: 35.0064\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 43.6003\n",
      "val Loss: 28.9658\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 37.8107\n",
      "val Loss: 24.4860\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 33.3531\n",
      "val Loss: 21.1678\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 29.9561\n",
      "val Loss: 18.7819\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 27.3214\n",
      "val Loss: 17.0261\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 25.3250\n",
      "val Loss: 15.7960\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 23.7646\n",
      "val Loss: 14.9319\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 22.5800\n",
      "val Loss: 14.3595\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 21.6923\n",
      "val Loss: 14.0099\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 21.0411\n",
      "val Loss: 13.8171\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 20.5489\n",
      "val Loss: 13.7387\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 20.2067\n",
      "val Loss: 13.7382\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 19.9548\n",
      "val Loss: 13.7862\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 19.7731\n",
      "val Loss: 13.8595\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 19.6491\n",
      "val Loss: 13.9483\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 19.5585\n",
      "val Loss: 14.0475\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 19.4947\n",
      "val Loss: 14.1464\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 19.4554\n",
      "val Loss: 14.2334\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 19.4268\n",
      "val Loss: 14.3153\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 19.4088\n",
      "val Loss: 14.3844\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 19.3980\n",
      "val Loss: 14.4488\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 19.3890\n",
      "val Loss: 14.4894\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 19.3849\n",
      "val Loss: 14.5255\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 19.3793\n",
      "val Loss: 14.5584\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 19.3789\n",
      "val Loss: 14.5845\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 19.3771\n",
      "val Loss: 14.6036\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 19.3761\n",
      "val Loss: 14.6228\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 19.3747\n",
      "val Loss: 14.6548\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 19.3744\n",
      "val Loss: 14.6550\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 19.3740\n",
      "val Loss: 14.6593\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 19.3725\n",
      "val Loss: 14.6590\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 19.3721\n",
      "val Loss: 14.6594\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 19.3737\n",
      "val Loss: 14.6526\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 19.3629\n",
      "val Loss: 14.6645\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 19.3620\n",
      "val Loss: 14.6700\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 19.3630\n",
      "val Loss: 14.6667\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 19.3617\n",
      "val Loss: 14.6768\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 19.3593\n",
      "val Loss: 14.6830\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 19.3561\n",
      "val Loss: 14.6873\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 19.3523\n",
      "val Loss: 14.6830\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 19.3535\n",
      "val Loss: 14.7118\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 19.3484\n",
      "val Loss: 14.7114\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 19.3454\n",
      "val Loss: 14.7024\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 19.3442\n",
      "val Loss: 14.6707\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 19.3401\n",
      "val Loss: 14.6844\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 19.3360\n",
      "val Loss: 14.6972\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 19.3311\n",
      "val Loss: 14.6753\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 19.3346\n",
      "val Loss: 14.6401\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 19.3216\n",
      "val Loss: 14.6587\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 19.3204\n",
      "val Loss: 14.6673\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 19.3123\n",
      "val Loss: 14.6873\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 19.3100\n",
      "val Loss: 14.6776\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 19.3051\n",
      "val Loss: 14.6844\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 19.2994\n",
      "val Loss: 14.6820\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 19.2823\n",
      "val Loss: 14.5786\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 19.2603\n",
      "val Loss: 14.6034\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 19.2532\n",
      "val Loss: 14.6240\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 19.2455\n",
      "val Loss: 14.6117\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 19.2356\n",
      "val Loss: 14.6413\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 19.2257\n",
      "val Loss: 14.6243\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 19.1874\n",
      "val Loss: 14.5539\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 19.1688\n",
      "val Loss: 14.5931\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 19.1436\n",
      "val Loss: 14.5635\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 19.1095\n",
      "val Loss: 14.5217\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 19.0704\n",
      "val Loss: 14.4356\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 19.0072\n",
      "val Loss: 14.4022\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 18.9341\n",
      "val Loss: 14.3873\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 18.8936\n",
      "val Loss: 14.3051\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 18.7648\n",
      "val Loss: 14.2464\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 18.6765\n",
      "val Loss: 14.1478\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 18.5651\n",
      "val Loss: 14.0525\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 18.4561\n",
      "val Loss: 13.9261\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 18.2783\n",
      "val Loss: 13.9040\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 18.1269\n",
      "val Loss: 13.6986\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 17.9188\n",
      "val Loss: 13.7083\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 17.7068\n",
      "val Loss: 13.5096\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 17.3451\n",
      "val Loss: 13.3916\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 16.9761\n",
      "val Loss: 13.1793\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 16.6612\n",
      "val Loss: 13.1933\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 15.7078\n",
      "val Loss: 12.8598\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 14.4690\n",
      "val Loss: 12.8347\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 13.4400\n",
      "val Loss: 13.2678\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 12.1378\n",
      "val Loss: 15.3833\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 13.4778\n",
      "val Loss: 17.4130\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 11.9317\n",
      "val Loss: 18.8497\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 10.3575\n",
      "val Loss: 19.2934\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 9.4204\n",
      "val Loss: 18.0398\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 9.6484\n",
      "val Loss: 20.1539\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 8.8769\n",
      "val Loss: 21.6865\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 8.9462\n",
      "val Loss: 19.3714\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 9.9926\n",
      "val Loss: 15.3655\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 9.3807\n",
      "val Loss: 16.3493\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 8.6940\n",
      "val Loss: 19.0645\n",
      "\n",
      "Training complete in 0m 51s\n",
      "Best val MSE: 12.738603\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 2. GRU (w/o data representation)\n",
    "config = config2\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 12.39903736114502, MAE = 2.7875874042510986\n",
      "** Dimension of result for test dataset = (42,)\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'** Dimension of result for test dataset = {pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 60.8839\n",
      "val Loss: 27.5115\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 31.1583\n",
      "val Loss: 14.5206\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 28.6889\n",
      "val Loss: 14.4604\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 24.8267\n",
      "val Loss: 14.4987\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 23.4859\n",
      "val Loss: 16.2135\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 23.8315\n",
      "val Loss: 15.7655\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 23.1293\n",
      "val Loss: 14.6851\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 21.5668\n",
      "val Loss: 16.1134\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 19.5737\n",
      "val Loss: 15.6010\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 21.7401\n",
      "val Loss: 15.7602\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 16.7819\n",
      "val Loss: 14.8757\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 22.4276\n",
      "val Loss: 14.9625\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 18.6341\n",
      "val Loss: 16.6184\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 16.5971\n",
      "val Loss: 15.7741\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 16.8002\n",
      "val Loss: 15.0178\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 16.2238\n",
      "val Loss: 15.1718\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 19.2100\n",
      "val Loss: 16.9177\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 17.5385\n",
      "val Loss: 15.6264\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 16.9248\n",
      "val Loss: 19.0536\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 14.5602\n",
      "val Loss: 18.0125\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 14.3802\n",
      "val Loss: 19.1726\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 15.9374\n",
      "val Loss: 18.0640\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 14.4845\n",
      "val Loss: 18.5949\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 15.1856\n",
      "val Loss: 18.6776\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 13.7618\n",
      "val Loss: 18.6788\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 14.5841\n",
      "val Loss: 19.8789\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 15.2880\n",
      "val Loss: 18.6622\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 12.6791\n",
      "val Loss: 19.6830\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 10.8146\n",
      "val Loss: 21.2577\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 14.2977\n",
      "val Loss: 20.5005\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 12.0948\n",
      "val Loss: 21.5256\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 12.0730\n",
      "val Loss: 23.0153\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 12.1404\n",
      "val Loss: 21.9141\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 12.6741\n",
      "val Loss: 21.4750\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 12.6053\n",
      "val Loss: 20.8682\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 12.7975\n",
      "val Loss: 21.4844\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 11.3872\n",
      "val Loss: 23.6158\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 11.6615\n",
      "val Loss: 22.8805\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 9.8679\n",
      "val Loss: 22.1238\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 11.1152\n",
      "val Loss: 22.8745\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 10.5203\n",
      "val Loss: 24.8470\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 9.9538\n",
      "val Loss: 22.4230\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 10.5135\n",
      "val Loss: 23.3133\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 9.8719\n",
      "val Loss: 23.3440\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 10.3371\n",
      "val Loss: 23.3966\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 11.6302\n",
      "val Loss: 23.5558\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 11.3979\n",
      "val Loss: 23.6974\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 10.4446\n",
      "val Loss: 23.7201\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 10.2250\n",
      "val Loss: 24.9777\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 9.4727\n",
      "val Loss: 23.9480\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 9.7058\n",
      "val Loss: 23.8721\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 8.4700\n",
      "val Loss: 24.9866\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 9.5399\n",
      "val Loss: 26.5613\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 8.8728\n",
      "val Loss: 25.1769\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 9.2878\n",
      "val Loss: 24.9635\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 9.2609\n",
      "val Loss: 26.2466\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 9.7167\n",
      "val Loss: 26.1517\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 9.8838\n",
      "val Loss: 26.0290\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 8.9930\n",
      "val Loss: 24.0279\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 8.5062\n",
      "val Loss: 26.4788\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 8.0704\n",
      "val Loss: 25.8931\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 9.0530\n",
      "val Loss: 27.4930\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 8.0036\n",
      "val Loss: 25.2214\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 7.7212\n",
      "val Loss: 26.6302\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 8.2616\n",
      "val Loss: 25.9837\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 8.2156\n",
      "val Loss: 25.3722\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 7.1469\n",
      "val Loss: 26.6610\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 7.0298\n",
      "val Loss: 26.0559\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 8.1096\n",
      "val Loss: 27.3170\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 7.4705\n",
      "val Loss: 26.4775\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 8.2477\n",
      "val Loss: 25.9580\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 6.7866\n",
      "val Loss: 25.7399\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 6.6858\n",
      "val Loss: 27.1011\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 6.5889\n",
      "val Loss: 27.0568\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 5.7417\n",
      "val Loss: 27.7238\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 6.8280\n",
      "val Loss: 29.0383\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 6.8395\n",
      "val Loss: 27.2879\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 6.6134\n",
      "val Loss: 27.6235\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 6.6218\n",
      "val Loss: 27.8368\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 7.3673\n",
      "val Loss: 27.2564\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 5.8600\n",
      "val Loss: 28.3577\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 5.1961\n",
      "val Loss: 27.8653\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 6.1380\n",
      "val Loss: 28.2894\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 5.2768\n",
      "val Loss: 28.9432\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 5.5772\n",
      "val Loss: 29.2938\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 5.8959\n",
      "val Loss: 28.5235\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 6.2335\n",
      "val Loss: 28.6011\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 5.1609\n",
      "val Loss: 28.3365\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 5.6527\n",
      "val Loss: 29.8765\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 4.3577\n",
      "val Loss: 28.7867\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 5.1688\n",
      "val Loss: 28.8228\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 7.0091\n",
      "val Loss: 30.7393\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 4.9222\n",
      "val Loss: 30.1878\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 4.5299\n",
      "val Loss: 29.6038\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 5.1222\n",
      "val Loss: 29.7113\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 4.9074\n",
      "val Loss: 30.6126\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 4.4308\n",
      "val Loss: 30.3759\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 4.6572\n",
      "val Loss: 31.5142\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 5.1688\n",
      "val Loss: 30.5167\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 4.6393\n",
      "val Loss: 31.4397\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 4.4799\n",
      "val Loss: 31.3509\n",
      "\n",
      "Training complete in 0m 10s\n",
      "Best val MSE: 14.414772\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 3. CNN_1D (w/o data representation)\n",
    "config = config3\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 12.7020263671875, MAE = 2.78977370262146\n",
      "** Dimension of result for test dataset = (42,)\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'** Dimension of result for test dataset = {pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 231.9811\n",
      "val Loss: 199.4222\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 218.2609\n",
      "val Loss: 187.5882\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 182.4408\n",
      "val Loss: 150.6197\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 149.2396\n",
      "val Loss: 120.0923\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 125.8984\n",
      "val Loss: 98.7046\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 110.8559\n",
      "val Loss: 86.8262\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 99.6817\n",
      "val Loss: 75.1330\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 90.9861\n",
      "val Loss: 68.0125\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 83.4943\n",
      "val Loss: 62.3995\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 77.0016\n",
      "val Loss: 55.9558\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 71.2742\n",
      "val Loss: 46.7425\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 65.7693\n",
      "val Loss: 49.2796\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 60.8785\n",
      "val Loss: 44.9925\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 56.7275\n",
      "val Loss: 42.4288\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 52.5220\n",
      "val Loss: 38.6910\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 49.1903\n",
      "val Loss: 39.2420\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 45.5760\n",
      "val Loss: 28.1904\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 42.0699\n",
      "val Loss: 22.8079\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 39.4091\n",
      "val Loss: 29.6494\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 36.7437\n",
      "val Loss: 28.8682\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 34.1769\n",
      "val Loss: 13.3484\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 32.1565\n",
      "val Loss: 24.0910\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 29.8493\n",
      "val Loss: 20.9241\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 27.9718\n",
      "val Loss: 15.5878\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 26.2989\n",
      "val Loss: 20.0343\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 24.5072\n",
      "val Loss: 17.3051\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 23.1655\n",
      "val Loss: 19.5065\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 22.5288\n",
      "val Loss: 19.3897\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 20.7331\n",
      "val Loss: 15.8503\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 19.5438\n",
      "val Loss: 14.5140\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 18.7392\n",
      "val Loss: 14.4249\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 17.4416\n",
      "val Loss: 12.3438\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 16.5218\n",
      "val Loss: 12.1223\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 15.8304\n",
      "val Loss: 14.0352\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 14.6872\n",
      "val Loss: 15.3801\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 14.3469\n",
      "val Loss: 18.2794\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 13.6462\n",
      "val Loss: 15.0625\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 13.4785\n",
      "val Loss: 15.5010\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 13.3153\n",
      "val Loss: 14.2253\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 12.1354\n",
      "val Loss: 13.4708\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 11.1741\n",
      "val Loss: 14.7465\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 11.9297\n",
      "val Loss: 15.9224\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 10.2330\n",
      "val Loss: 14.5513\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 9.8536\n",
      "val Loss: 15.7476\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 9.5260\n",
      "val Loss: 20.6052\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 9.7452\n",
      "val Loss: 15.8115\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 9.0954\n",
      "val Loss: 16.2540\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 8.6966\n",
      "val Loss: 17.4851\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 8.5988\n",
      "val Loss: 15.7251\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 8.8248\n",
      "val Loss: 68.8729\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 7.7251\n",
      "val Loss: 24.9530\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 7.3642\n",
      "val Loss: 19.2924\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 7.9801\n",
      "val Loss: 16.9398\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 7.3072\n",
      "val Loss: 19.4225\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 6.9061\n",
      "val Loss: 37.2419\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 6.2780\n",
      "val Loss: 17.6681\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 6.2544\n",
      "val Loss: 20.4639\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 5.8521\n",
      "val Loss: 16.8525\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 5.8329\n",
      "val Loss: 41.5931\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 6.5857\n",
      "val Loss: 17.1285\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 5.5484\n",
      "val Loss: 16.9378\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 4.8669\n",
      "val Loss: 20.4456\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 4.6737\n",
      "val Loss: 25.9629\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 4.5840\n",
      "val Loss: 135.6435\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 4.7586\n",
      "val Loss: 15.2452\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 5.5828\n",
      "val Loss: 21.3224\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 4.0324\n",
      "val Loss: 33.4899\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 3.8725\n",
      "val Loss: 23.8648\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 3.5370\n",
      "val Loss: 16.5307\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 4.5931\n",
      "val Loss: 42.5232\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 4.4438\n",
      "val Loss: 42.5731\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 3.2155\n",
      "val Loss: 44.4249\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 4.0175\n",
      "val Loss: 19.2454\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 2.9257\n",
      "val Loss: 27.5779\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 2.9760\n",
      "val Loss: 35.5961\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 2.6984\n",
      "val Loss: 38.8050\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 4.4966\n",
      "val Loss: 69.3957\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 2.3683\n",
      "val Loss: 18.0752\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 2.4497\n",
      "val Loss: 20.0336\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 2.7277\n",
      "val Loss: 16.6756\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 2.4269\n",
      "val Loss: 27.8724\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 2.5689\n",
      "val Loss: 37.4529\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 3.7485\n",
      "val Loss: 77.3948\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 1.6168\n",
      "val Loss: 22.4104\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 2.2500\n",
      "val Loss: 93.5971\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 2.5559\n",
      "val Loss: 35.4307\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 1.8710\n",
      "val Loss: 31.6151\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 2.0895\n",
      "val Loss: 26.2090\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 2.0614\n",
      "val Loss: 23.9358\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 1.8513\n",
      "val Loss: 26.2569\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 1.8048\n",
      "val Loss: 18.8061\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 1.7973\n",
      "val Loss: 24.3419\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 1.7354\n",
      "val Loss: 18.3339\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 2.1183\n",
      "val Loss: 34.7489\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 2.3785\n",
      "val Loss: 48.7616\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 2.2534\n",
      "val Loss: 21.2325\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 2.3576\n",
      "val Loss: 76.6163\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 1.7485\n",
      "val Loss: 32.2435\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 2.1313\n",
      "val Loss: 23.5709\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 1.6741\n",
      "val Loss: 16.7389\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 1.3719\n",
      "val Loss: 19.9650\n",
      "\n",
      "Training complete in 0m 48s\n",
      "Best val MSE: 11.966396\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 4. LSTM_FCNs (w/o data representation)\n",
    "config = config4\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 14.740714073181152, MAE = 2.7893290519714355\n",
      "** Dimension of result for test dataset = (42,)\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'** Dimension of result for test dataset = {pred.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 64)\n",
      "(95,)\n",
      "(42, 64)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "# representation data\n",
    "train_x = pd.read_csv('./data/ts2vec_repr_train.csv')\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "\n",
    "test_x = pd.read_csv('./data/ts2vec_repr_test.csv')\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x representation_dims) = (95, 64)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (95, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x representation_dims) = (42, 64)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (42, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 193.5459\n",
      "val Loss: 161.8088\n",
      "\n",
      "Epoch 10/1000\n",
      "train Loss: 171.3630\n",
      "val Loss: 142.7268\n",
      "\n",
      "Epoch 20/1000\n",
      "train Loss: 145.5106\n",
      "val Loss: 119.7018\n",
      "\n",
      "Epoch 30/1000\n",
      "train Loss: 119.9123\n",
      "val Loss: 96.2363\n",
      "\n",
      "Epoch 40/1000\n",
      "train Loss: 96.9468\n",
      "val Loss: 74.5049\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 74.2771\n",
      "val Loss: 55.7413\n",
      "\n",
      "Epoch 60/1000\n",
      "train Loss: 55.8850\n",
      "val Loss: 40.4257\n",
      "\n",
      "Epoch 70/1000\n",
      "train Loss: 44.1047\n",
      "val Loss: 29.0102\n",
      "\n",
      "Epoch 80/1000\n",
      "train Loss: 36.7557\n",
      "val Loss: 21.2933\n",
      "\n",
      "Epoch 90/1000\n",
      "train Loss: 32.4831\n",
      "val Loss: 16.4628\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 25.8425\n",
      "val Loss: 13.7876\n",
      "\n",
      "Epoch 110/1000\n",
      "train Loss: 26.4942\n",
      "val Loss: 12.4102\n",
      "\n",
      "Epoch 120/1000\n",
      "train Loss: 27.1186\n",
      "val Loss: 11.7364\n",
      "\n",
      "Epoch 130/1000\n",
      "train Loss: 23.6492\n",
      "val Loss: 11.4486\n",
      "\n",
      "Epoch 140/1000\n",
      "train Loss: 22.5890\n",
      "val Loss: 11.3030\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 23.3388\n",
      "val Loss: 11.2462\n",
      "\n",
      "Epoch 160/1000\n",
      "train Loss: 22.5823\n",
      "val Loss: 11.2168\n",
      "\n",
      "Epoch 170/1000\n",
      "train Loss: 20.7423\n",
      "val Loss: 11.2109\n",
      "\n",
      "Epoch 180/1000\n",
      "train Loss: 24.3513\n",
      "val Loss: 11.2124\n",
      "\n",
      "Epoch 190/1000\n",
      "train Loss: 25.3222\n",
      "val Loss: 11.2203\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 24.2784\n",
      "val Loss: 11.2355\n",
      "\n",
      "Epoch 210/1000\n",
      "train Loss: 21.4444\n",
      "val Loss: 11.2679\n",
      "\n",
      "Epoch 220/1000\n",
      "train Loss: 21.4841\n",
      "val Loss: 11.2971\n",
      "\n",
      "Epoch 230/1000\n",
      "train Loss: 21.7156\n",
      "val Loss: 11.3281\n",
      "\n",
      "Epoch 240/1000\n",
      "train Loss: 24.5186\n",
      "val Loss: 11.3690\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 22.1925\n",
      "val Loss: 11.3946\n",
      "\n",
      "Epoch 260/1000\n",
      "train Loss: 21.9530\n",
      "val Loss: 11.4446\n",
      "\n",
      "Epoch 270/1000\n",
      "train Loss: 19.2384\n",
      "val Loss: 11.4723\n",
      "\n",
      "Epoch 280/1000\n",
      "train Loss: 20.9920\n",
      "val Loss: 11.5007\n",
      "\n",
      "Epoch 290/1000\n",
      "train Loss: 20.4758\n",
      "val Loss: 11.5444\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 21.6117\n",
      "val Loss: 11.5734\n",
      "\n",
      "Epoch 310/1000\n",
      "train Loss: 20.6736\n",
      "val Loss: 11.6224\n",
      "\n",
      "Epoch 320/1000\n",
      "train Loss: 20.0681\n",
      "val Loss: 11.6514\n",
      "\n",
      "Epoch 330/1000\n",
      "train Loss: 21.8842\n",
      "val Loss: 11.7114\n",
      "\n",
      "Epoch 340/1000\n",
      "train Loss: 21.3506\n",
      "val Loss: 11.7468\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 22.0252\n",
      "val Loss: 11.7465\n",
      "\n",
      "Epoch 360/1000\n",
      "train Loss: 20.0872\n",
      "val Loss: 11.7692\n",
      "\n",
      "Epoch 370/1000\n",
      "train Loss: 19.1646\n",
      "val Loss: 11.7781\n",
      "\n",
      "Epoch 380/1000\n",
      "train Loss: 18.7357\n",
      "val Loss: 11.8170\n",
      "\n",
      "Epoch 390/1000\n",
      "train Loss: 20.0242\n",
      "val Loss: 11.8383\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 20.3597\n",
      "val Loss: 11.8716\n",
      "\n",
      "Epoch 410/1000\n",
      "train Loss: 20.1201\n",
      "val Loss: 11.9076\n",
      "\n",
      "Epoch 420/1000\n",
      "train Loss: 18.6733\n",
      "val Loss: 11.9302\n",
      "\n",
      "Epoch 430/1000\n",
      "train Loss: 20.3287\n",
      "val Loss: 11.9661\n",
      "\n",
      "Epoch 440/1000\n",
      "train Loss: 19.8139\n",
      "val Loss: 12.0147\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 20.0182\n",
      "val Loss: 12.0434\n",
      "\n",
      "Epoch 460/1000\n",
      "train Loss: 20.1136\n",
      "val Loss: 12.0580\n",
      "\n",
      "Epoch 470/1000\n",
      "train Loss: 20.4335\n",
      "val Loss: 12.0879\n",
      "\n",
      "Epoch 480/1000\n",
      "train Loss: 20.0468\n",
      "val Loss: 12.1303\n",
      "\n",
      "Epoch 490/1000\n",
      "train Loss: 20.6122\n",
      "val Loss: 12.1304\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 17.0626\n",
      "val Loss: 12.1577\n",
      "\n",
      "Epoch 510/1000\n",
      "train Loss: 18.9397\n",
      "val Loss: 12.1995\n",
      "\n",
      "Epoch 520/1000\n",
      "train Loss: 20.8580\n",
      "val Loss: 12.1908\n",
      "\n",
      "Epoch 530/1000\n",
      "train Loss: 19.5814\n",
      "val Loss: 12.2433\n",
      "\n",
      "Epoch 540/1000\n",
      "train Loss: 17.2585\n",
      "val Loss: 12.2577\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 18.6360\n",
      "val Loss: 12.2770\n",
      "\n",
      "Epoch 560/1000\n",
      "train Loss: 18.4316\n",
      "val Loss: 12.2899\n",
      "\n",
      "Epoch 570/1000\n",
      "train Loss: 21.4556\n",
      "val Loss: 12.3261\n",
      "\n",
      "Epoch 580/1000\n",
      "train Loss: 18.9954\n",
      "val Loss: 12.3365\n",
      "\n",
      "Epoch 590/1000\n",
      "train Loss: 19.7426\n",
      "val Loss: 12.3524\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 17.2511\n",
      "val Loss: 12.3735\n",
      "\n",
      "Epoch 610/1000\n",
      "train Loss: 19.9276\n",
      "val Loss: 12.4442\n",
      "\n",
      "Epoch 620/1000\n",
      "train Loss: 19.0355\n",
      "val Loss: 12.4649\n",
      "\n",
      "Epoch 630/1000\n",
      "train Loss: 17.5727\n",
      "val Loss: 12.4531\n",
      "\n",
      "Epoch 640/1000\n",
      "train Loss: 17.8292\n",
      "val Loss: 12.4942\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 19.1652\n",
      "val Loss: 12.5175\n",
      "\n",
      "Epoch 660/1000\n",
      "train Loss: 18.1429\n",
      "val Loss: 12.5570\n",
      "\n",
      "Epoch 670/1000\n",
      "train Loss: 18.5095\n",
      "val Loss: 12.5741\n",
      "\n",
      "Epoch 680/1000\n",
      "train Loss: 17.8234\n",
      "val Loss: 12.5887\n",
      "\n",
      "Epoch 690/1000\n",
      "train Loss: 19.4324\n",
      "val Loss: 12.6415\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 17.8285\n",
      "val Loss: 12.6799\n",
      "\n",
      "Epoch 710/1000\n",
      "train Loss: 18.0780\n",
      "val Loss: 12.7042\n",
      "\n",
      "Epoch 720/1000\n",
      "train Loss: 17.3721\n",
      "val Loss: 12.7563\n",
      "\n",
      "Epoch 730/1000\n",
      "train Loss: 19.1602\n",
      "val Loss: 12.7571\n",
      "\n",
      "Epoch 740/1000\n",
      "train Loss: 18.4877\n",
      "val Loss: 12.7916\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 17.5344\n",
      "val Loss: 12.7951\n",
      "\n",
      "Epoch 760/1000\n",
      "train Loss: 17.9453\n",
      "val Loss: 12.8532\n",
      "\n",
      "Epoch 770/1000\n",
      "train Loss: 16.7497\n",
      "val Loss: 12.8592\n",
      "\n",
      "Epoch 780/1000\n",
      "train Loss: 17.7862\n",
      "val Loss: 12.8871\n",
      "\n",
      "Epoch 790/1000\n",
      "train Loss: 16.1391\n",
      "val Loss: 12.8926\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 18.2301\n",
      "val Loss: 12.9203\n",
      "\n",
      "Epoch 810/1000\n",
      "train Loss: 18.7739\n",
      "val Loss: 12.9285\n",
      "\n",
      "Epoch 820/1000\n",
      "train Loss: 16.9753\n",
      "val Loss: 12.9269\n",
      "\n",
      "Epoch 830/1000\n",
      "train Loss: 15.8264\n",
      "val Loss: 12.9704\n",
      "\n",
      "Epoch 840/1000\n",
      "train Loss: 17.3240\n",
      "val Loss: 12.9954\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 15.1730\n",
      "val Loss: 13.0290\n",
      "\n",
      "Epoch 860/1000\n",
      "train Loss: 18.2454\n",
      "val Loss: 13.0832\n",
      "\n",
      "Epoch 870/1000\n",
      "train Loss: 18.3011\n",
      "val Loss: 13.0854\n",
      "\n",
      "Epoch 880/1000\n",
      "train Loss: 17.0280\n",
      "val Loss: 13.0769\n",
      "\n",
      "Epoch 890/1000\n",
      "train Loss: 16.6138\n",
      "val Loss: 13.1302\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 15.7446\n",
      "val Loss: 13.1589\n",
      "\n",
      "Epoch 910/1000\n",
      "train Loss: 16.7248\n",
      "val Loss: 13.2018\n",
      "\n",
      "Epoch 920/1000\n",
      "train Loss: 17.3019\n",
      "val Loss: 13.1895\n",
      "\n",
      "Epoch 930/1000\n",
      "train Loss: 15.7404\n",
      "val Loss: 13.2330\n",
      "\n",
      "Epoch 940/1000\n",
      "train Loss: 15.2586\n",
      "val Loss: 13.2514\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 16.8030\n",
      "val Loss: 13.3270\n",
      "\n",
      "Epoch 960/1000\n",
      "train Loss: 14.3370\n",
      "val Loss: 13.3417\n",
      "\n",
      "Epoch 970/1000\n",
      "train Loss: 16.1109\n",
      "val Loss: 13.4132\n",
      "\n",
      "Epoch 980/1000\n",
      "train Loss: 14.2381\n",
      "val Loss: 13.3554\n",
      "\n",
      "Epoch 990/1000\n",
      "train Loss: 17.0088\n",
      "val Loss: 13.4837\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 17.8872\n",
      "val Loss: 13.4628\n",
      "\n",
      "Training complete in 0m 6s\n",
      "Best val MSE: 11.204296\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config = config5\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse, mae = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Performance of test dataset ==> MSE = 15.471257209777832, MAE = 3.090275287628174\n",
      "** Dimension of result for test dataset = (42,)\n"
     ]
    }
   ],
   "source": [
    "print(f'** Performance of test dataset ==> MSE = {mse}, MAE = {mae}')\n",
    "print(f'** Dimension of result for test dataset = {pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "iitp_time_serise",
   "language": "python",
   "name": "iitp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
